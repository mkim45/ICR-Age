{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing Libraries","metadata":{"execution":{"iopub.status.busy":"2023-08-03T02:00:53.347952Z","iopub.execute_input":"2023-08-03T02:00:53.348419Z","iopub.status.idle":"2023-08-03T02:01:12.077606Z","shell.execute_reply.started":"2023-08-03T02:00:53.348388Z","shell.execute_reply":"2023-08-03T02:01:12.076073Z"}}},{"cell_type":"code","source":"!pip install tabpfn --no-index --find-links=file:///kaggle/input/pip-packages-icr/pip-packages\n!mkdir -p /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n!cp /kaggle/input/pip-packages-icr/pip-packages/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:47:51.016249Z","iopub.execute_input":"2023-08-09T23:47:51.017506Z","iopub.status.idle":"2023-08-09T23:48:09.354813Z","shell.execute_reply.started":"2023-08-09T23:47:51.017446Z","shell.execute_reply":"2023-08-09T23:48:09.353557Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Looking in links: file:///kaggle/input/pip-packages-icr/pip-packages\nProcessing /kaggle/input/pip-packages-icr/pip-packages/tabpfn-0.1.9-py3-none-any.whl\nRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (1.23.5)\nRequirement already satisfied: pyyaml>=5.4.1 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (6.0)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (2.31.0)\nRequirement already satisfied: scikit-learn>=0.24.2 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (1.2.2)\nRequirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (2.0.0+cpu)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (2023.5.7)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->tabpfn) (1.11.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->tabpfn) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->tabpfn) (3.1.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->tabpfn) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9.0->tabpfn) (1.3.0)\nInstalling collected packages: tabpfn\nSuccessfully installed tabpfn-0.1.9\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\nimport numpy as np\nimport pandas as pd\nimport warnings\ndef ignore_warn(*args,**kwargs):\n    pass\nwarnings.warn = ignore_warn\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport optuna\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score, KFold, train_test_split\nfrom sklearn.metrics import f1_score\nimport xgboost as xgboost\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, HistGradientBoostingClassifier, BaggingClassifier, StackingClassifier, VotingClassifier, GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.experimental import enable_hist_gradient_boosting  \nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.impute import KNNImputer\nfrom tabpfn import TabPFNClassifier\nfrom sklearn.linear_model import LogisticRegression","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:09.357852Z","iopub.execute_input":"2023-08-09T23:48:09.358746Z","iopub.status.idle":"2023-08-09T23:48:16.499829Z","shell.execute_reply.started":"2023-08-09T23:48:09.358698Z","shell.execute_reply":"2023-08-09T23:48:16.498595Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\ntest = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\nfinal = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.501253Z","iopub.execute_input":"2023-08-09T23:48:16.502289Z","iopub.status.idle":"2023-08-09T23:48:16.555884Z","shell.execute_reply.started":"2023-08-09T23:48:16.502237Z","shell.execute_reply":"2023-08-09T23:48:16.554627Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\ntrain.loc[:, 'EJ'] = encoder.fit_transform(train.loc[:, 'EJ'])\ntest.loc[:, 'EJ'] = encoder.fit_transform(test.loc[:, 'EJ'])","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.558531Z","iopub.execute_input":"2023-08-09T23:48:16.559210Z","iopub.status.idle":"2023-08-09T23:48:16.570780Z","shell.execute_reply.started":"2023-08-09T23:48:16.559177Z","shell.execute_reply":"2023-08-09T23:48:16.569647Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"imputer = KNNImputer(n_neighbors = 10)\ntrain_no_id = train.drop(['Id'], axis = 1)\ntrain_no_id = imputer.fit_transform(train_no_id)\ntrain_no_id = pd.DataFrame(train_no_id, columns = train.drop(['Id'], axis = 1).columns)\ntrain = pd.concat([train['Id'], train_no_id], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.571910Z","iopub.execute_input":"2023-08-09T23:48:16.572201Z","iopub.status.idle":"2023-08-09T23:48:16.639810Z","shell.execute_reply.started":"2023-08-09T23:48:16.572176Z","shell.execute_reply":"2023-08-09T23:48:16.638200Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\nseed = 617\nzero, one = np.bincount(train.loc[:, 'Class'])\none_df = train.iloc[(train.loc[:, 'Class'] == 1).tolist(), :] \nzero_df = train.iloc[(train.loc[:, 'Class'] == 0).tolist(), :]\nzero_df = zero_df.sample(n=one, random_state=seed)\noversampled_df = pd.concat([train.iloc[(train.loc[:, 'Class'] == 0).tolist(), :], one_df, one_df, one_df, one_df])\noversampled_df = oversampled_df.sample(frac=1, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.648023Z","iopub.execute_input":"2023-08-09T23:48:16.652215Z","iopub.status.idle":"2023-08-09T23:48:16.694095Z","shell.execute_reply.started":"2023-08-09T23:48:16.652143Z","shell.execute_reply":"2023-08-09T23:48:16.692494Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\ndef balanced_log_loss(y_true, y_pred):\n    N_0 = np.sum(1 - y_true)\n    N_1 = np.sum(y_true)\n    w_0 = 1 / N_0\n    w_1 = 1 / N_1\n    p_1 = np.clip(y_pred[:, 1], 1e-15, 1-1e-15)\n    p_0 = 1 - p_1\n    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\n    log_loss_1 = -np.sum(y_true * np.log(p_1))\n    balanced_log_loss = (w_0 * log_loss_0 + w_1 * log_loss_1) / 2\n    return balanced_log_loss","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.701954Z","iopub.execute_input":"2023-08-09T23:48:16.706019Z","iopub.status.idle":"2023-08-09T23:48:16.720919Z","shell.execute_reply.started":"2023-08-09T23:48:16.705949Z","shell.execute_reply":"2023-08-09T23:48:16.719403Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\nn_folds = 10\ndef CV(model, data, loss_function):\n    skf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n    kfold = skf.split(data.iloc[:, 1:-1], data.iloc[:, -1])\n    losses = []\n    for (train_id, val_id) in kfold:\n        x_train = data.iloc[train_id, 1:-1]\n        y_train = data.iloc[train_id, -1]\n        x_val = data.iloc[val_id, 1:-1]\n        y_val = data.iloc[val_id, -1]\n        model.fit(x_train, y_train)\n        pred_val = model.predict_proba(x_val)\n        loss = loss_function(y_val, pred_val)\n        losses.append(loss)\n    return np.sum(losses) / n_folds","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.728586Z","iopub.execute_input":"2023-08-09T23:48:16.732881Z","iopub.status.idle":"2023-08-09T23:48:16.743359Z","shell.execute_reply.started":"2023-08-09T23:48:16.732819Z","shell.execute_reply":"2023-08-09T23:48:16.742115Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X_train = oversampled_df.drop(columns=['Class', 'Id'])\ny_train = oversampled_df['Class']","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.745195Z","iopub.execute_input":"2023-08-09T23:48:16.746057Z","iopub.status.idle":"2023-08-09T23:48:16.760449Z","shell.execute_reply.started":"2023-08-09T23:48:16.746014Z","shell.execute_reply":"2023-08-09T23:48:16.759224Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"markdown","source":"## Optuna Trial Exploration","metadata":{}},{"cell_type":"code","source":"def xgb(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),\n    }\n    model = xgb.XGBClassifier(**param, random_state = seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.765877Z","iopub.execute_input":"2023-08-09T23:48:16.766268Z","iopub.status.idle":"2023-08-09T23:48:16.775707Z","shell.execute_reply.started":"2023-08-09T23:48:16.766235Z","shell.execute_reply":"2023-08-09T23:48:16.774857Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def lgbm(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'num_leaves' : trial.suggest_int('num_leaves', 10, 50),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 50),\n    }\n    model = lgb.LGBMClassifier(**param, random_state = seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.777549Z","iopub.execute_input":"2023-08-09T23:48:16.777970Z","iopub.status.idle":"2023-08-09T23:48:16.794323Z","shell.execute_reply.started":"2023-08-09T23:48:16.777931Z","shell.execute_reply":"2023-08-09T23:48:16.793387Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def catboost(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 150, 10),\n        'reg_lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'colsample_bylevel': trial.suggest_categorical('colsample_bylevel', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'one_hot_max_size': trial.suggest_int('one_hot_max_size', 2, 10),\n    }\n    model = CatBoostClassifier(**param, random_seed=seed, verbose=False)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.795771Z","iopub.execute_input":"2023-08-09T23:48:16.796409Z","iopub.status.idle":"2023-08-09T23:48:16.809982Z","shell.execute_reply.started":"2023-08-09T23:48:16.796376Z","shell.execute_reply":"2023-08-09T23:48:16.809127Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def hgbc(trial):\n    param = {\n        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 15),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'max_iter': trial.suggest_int('max_iter', 50, 200, 10),\n    }\n    model = HistGradientBoostingClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.811621Z","iopub.execute_input":"2023-08-09T23:48:16.812349Z","iopub.status.idle":"2023-08-09T23:48:16.828917Z","shell.execute_reply.started":"2023-08-09T23:48:16.812291Z","shell.execute_reply":"2023-08-09T23:48:16.827794Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def bagged_dt(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 400, 600, 20),\n        'max_samples': trial.suggest_float('max_samples', 1e-2, 1.0),\n        'max_features': trial.suggest_float('max_features', 1e-2, 1.0),\n        'bootstrap': trial.suggest_categorical('bootstrap', [False, True]),\n        'bootstrap_features': trial.suggest_categorical('bootstrap_features', [False, True]),\n    }\n    model = BaggingClassifier(**param, base_estimator=DecisionTreeClassifier(), random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.830181Z","iopub.execute_input":"2023-08-09T23:48:16.831170Z","iopub.status.idle":"2023-08-09T23:48:16.843898Z","shell.execute_reply.started":"2023-08-09T23:48:16.831138Z","shell.execute_reply":"2023-08-09T23:48:16.842424Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def rf(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 300, 500, 20),\n        'max_depth': trial.suggest_int('max_depth', 5, 25),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'max_features': trial.suggest_int('max_features', 1, 56),\n        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n    }\n    model = RandomForestClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.845469Z","iopub.execute_input":"2023-08-09T23:48:16.846225Z","iopub.status.idle":"2023-08-09T23:48:16.857983Z","shell.execute_reply.started":"2023-08-09T23:48:16.846185Z","shell.execute_reply":"2023-08-09T23:48:16.856956Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def adaboost(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 400, 500, 20),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.0001, 1),\n        'base_estimator': DecisionTreeClassifier(max_depth=trial.suggest_int('max_depth', 1, 20)),\n    }\n    model = AdaBoostClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.859395Z","iopub.execute_input":"2023-08-09T23:48:16.860320Z","iopub.status.idle":"2023-08-09T23:48:16.875828Z","shell.execute_reply.started":"2023-08-09T23:48:16.860261Z","shell.execute_reply":"2023-08-09T23:48:16.874646Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def gradient(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 10, 500, 20),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.0001, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'subsample': trial.suggest_float('subsample', 0.3, 1.0),\n    }\n    model = GradientBoostingClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.877806Z","iopub.execute_input":"2023-08-09T23:48:16.878261Z","iopub.status.idle":"2023-08-09T23:48:16.891915Z","shell.execute_reply.started":"2023-08-09T23:48:16.878219Z","shell.execute_reply":"2023-08-09T23:48:16.891010Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def tabpfn(trial):\n    param = {\n        'N_ensemble_configurations': trial.suggest_int('N_ensemble_configurations', 20, 70),\n    }\n    model = TabPFNClassifier(**param)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.893549Z","iopub.execute_input":"2023-08-09T23:48:16.894654Z","iopub.status.idle":"2023-08-09T23:48:16.906506Z","shell.execute_reply.started":"2023-08-09T23:48:16.894618Z","shell.execute_reply":"2023-08-09T23:48:16.905534Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def catboost_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 150, 10),\n        'reg_lambda': trial.suggest_loguniform('lambda', 1e-3, 0.1),\n        'colsample_bylevel': trial.suggest_categorical('colsample_bylevel', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'one_hot_max_size': trial.suggest_int('one_hot_max_size', 2, 10),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=CatBoostClassifier(**param, random_state=seed, verbose=False)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.908111Z","iopub.execute_input":"2023-08-09T23:48:16.908832Z","iopub.status.idle":"2023-08-09T23:48:16.919357Z","shell.execute_reply.started":"2023-08-09T23:48:16.908791Z","shell.execute_reply":"2023-08-09T23:48:16.918550Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def xgb_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 0.1),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 0.1),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=xgboost.XGBClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.920936Z","iopub.execute_input":"2023-08-09T23:48:16.921647Z","iopub.status.idle":"2023-08-09T23:48:16.938333Z","shell.execute_reply.started":"2023-08-09T23:48:16.921607Z","shell.execute_reply":"2023-08-09T23:48:16.937441Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def hgbc_meta(trial):\n    param = {\n        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 15),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'max_iter': trial.suggest_int('max_iter', 50, 200, 10),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=HistGradientBoostingClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.939741Z","iopub.execute_input":"2023-08-09T23:48:16.940327Z","iopub.status.idle":"2023-08-09T23:48:16.952446Z","shell.execute_reply.started":"2023-08-09T23:48:16.940275Z","shell.execute_reply":"2023-08-09T23:48:16.951355Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def lgbm_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 0.1),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 0.1),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'num_leaves' : trial.suggest_int('num_leaves', 10, 50),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 50),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=lgb.LGBMClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.954016Z","iopub.execute_input":"2023-08-09T23:48:16.954609Z","iopub.status.idle":"2023-08-09T23:48:16.971917Z","shell.execute_reply.started":"2023-08-09T23:48:16.954579Z","shell.execute_reply":"2023-08-09T23:48:16.970757Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def logistic_meta(trial):\n    param = {\n        'C': trial.suggest_loguniform('C', 1e-4, 1e4),\n        'penalty': trial.suggest_categorical('penalty', [None, 'l1', 'l2', 'elasticnet']),\n        'solver': trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']),\n        'l1_ratio': trial.suggest_float('l1_ratio', 1e-3, 1)\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"tabpfn\", tab_lower_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model), (\"adaboost\", ada_model)],\n        final_estimator=LogisticRegression(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.973256Z","iopub.execute_input":"2023-08-09T23:48:16.973667Z","iopub.status.idle":"2023-08-09T23:48:16.985712Z","shell.execute_reply.started":"2023-08-09T23:48:16.973627Z","shell.execute_reply":"2023-08-09T23:48:16.984708Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#cv_scores = []\n#for i in range(1, 70):\n#    cv_scores.append(CV(TabPFNClassifier(N_ensemble_configurations=i).fit(X_train, y_train), oversampled_df, balanced_log_loss))\n#    print(\"Finished scoring iteration: \", i)\n#print(cv_scores)\n# tabpfn_cv_scores = [0.09816634530404814, 0.06528742315606546, 0.07164710694330415, 0.0638588867076252, 0.06678059459477922, \n#                     0.06248073905402122, 0.06022244222278583, 0.05686026255684793, 0.05689105574304978, 0.055132598406416614, \n#                     0.05647036841993689, 0.05590923914786228, 0.05717749825124045, 0.056481389014045424, 0.05585544466795472, \n#                     0.05429705547774719, 0.05411289464998228, 0.053594943435855504, 0.05330166286267148, 0.05248949135011284, \n#                     0.05360971138750451, 0.053185855277044544, 0.05442991634568051, 0.054041848842559824, 0.05442855850281584, \n#                     0.054167697496943834, 0.05464900294529094, 0.05452444890518441, 0.05537642870820436, 0.05530201264890257, \n#                     0.05508454012654403, 0.05454951688798497, 0.055158959487388484, 0.05487638328640315, 0.05475942057273066, \n#                     0.054363820012922115, 0.05444429556509187, 0.05417317343226857, 0.05412096729914397, 0.05351279626269752, \n#                     0.05340841118461925, 0.053096957471938544, 0.053109073061545865, 0.052836328953108344, 0.05318516573142357, \n#                     0.053126580472636464, 0.05360923926329571, 0.053408860579671494, 0.05393021365358299, 0.05382474507832467, \n#                     0.05371423691544534, 0.05321754224273796, 0.053625478068834165, 0.05351067456999581, 0.053520923141210576, \n#                     0.05313957104926818, 0.053584265552239566, 0.05343326935461631, 0.05377785617124854, 0.05370929324862032, \n#                     0.053595077061113806, 0.053302678221229506, 0.053333914849297705, 0.053023531220070495, 0.0529506407276686, \n#                     0.052713977186699276, 0.05300799494093289, 0.05295979717175845, 0.05318406292878591]","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:16.986879Z","iopub.execute_input":"2023-08-09T23:48:16.987684Z","iopub.status.idle":"2023-08-09T23:48:17.004816Z","shell.execute_reply.started":"2023-08-09T23:48:16.987645Z","shell.execute_reply":"2023-08-09T23:48:17.003582Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# start = time.time()\n\n# study1 = optuna.create_study(direction='minimize')\n# n_trials = 100\n# study1.optimize(logistic_meta, n_trials=n_trials)\n# print('Best trial:', study1.best_trial.params)\n# print('Best values:', study1.best_value)\n\n# end = time.time()\n# print('It has taken {:.5f} seconds to search for the best Hyperparameter'.format(end-start))","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:17.006216Z","iopub.execute_input":"2023-08-09T23:48:17.006844Z","iopub.status.idle":"2023-08-09T23:48:17.024016Z","shell.execute_reply.started":"2023-08-09T23:48:17.006802Z","shell.execute_reply":"2023-08-09T23:48:17.022894Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Creating Models","metadata":{}},{"cell_type":"code","source":"# CV(TabPFNClassifier(N_ensemble_configurations=24).fit(X_train, y_train), oversampled_df, balanced_log_loss)\n# # for each test performance on 1s and 0s","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:17.025430Z","iopub.execute_input":"2023-08-09T23:48:17.026017Z","iopub.status.idle":"2023-08-09T23:48:17.042105Z","shell.execute_reply.started":"2023-08-09T23:48:17.025986Z","shell.execute_reply":"2023-08-09T23:48:17.041133Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"#add way to do rule-based and adaptive ensembling\n#see what others did","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:17.043453Z","iopub.execute_input":"2023-08-09T23:48:17.043963Z","iopub.status.idle":"2023-08-09T23:48:17.056672Z","shell.execute_reply.started":"2023-08-09T23:48:17.043932Z","shell.execute_reply":"2023-08-09T23:48:17.055560Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"xgb_model = xgboost.XGBClassifier(n_estimators=200, reg_lambda=0.15325900166549988, reg_alpha=0.0044700650580230235, \n                              colsample_bytree=0.3, subsample=1.0, learning_rate=0.09975673376458177, \n                              max_depth=11, min_child_weight=2, random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:17.063908Z","iopub.execute_input":"2023-08-09T23:48:17.064632Z","iopub.status.idle":"2023-08-09T23:48:17.392779Z","shell.execute_reply.started":"2023-08-09T23:48:17.064585Z","shell.execute_reply":"2023-08-09T23:48:17.391818Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"lgbm_model = lgb.LGBMClassifier(n_estimators=200, reg_alpha=0.0016725623110267532, reg_lambda=0.0038043774323061946, \n                                 colsample_bytree=0.3, subsample=0.4, learning_rate=0.09367295744238123, max_depth=11, \n                                 num_leaves=50, min_child_samples=26, random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:17.398279Z","iopub.execute_input":"2023-08-09T23:48:17.399320Z","iopub.status.idle":"2023-08-09T23:48:18.520929Z","shell.execute_reply.started":"2023-08-09T23:48:17.399254Z","shell.execute_reply":"2023-08-09T23:48:18.519761Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"cat_model = CatBoostClassifier(n_estimators=70, reg_lambda=0.01606738047167, colsample_bylevel=0.3, \n                              subsample=0.7, learning_rate=0.0865881098465479, \n                              max_depth=9, one_hot_max_size=10, random_state=seed, verbose=False).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:18.522275Z","iopub.execute_input":"2023-08-09T23:48:18.522608Z","iopub.status.idle":"2023-08-09T23:48:20.827186Z","shell.execute_reply.started":"2023-08-09T23:48:18.522580Z","shell.execute_reply":"2023-08-09T23:48:20.826036Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"hgbc_model = HistGradientBoostingClassifier(max_iter=170, max_depth=4, min_samples_leaf=9,\n                                         learning_rate=0.17193627413211837, random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:20.828604Z","iopub.execute_input":"2023-08-09T23:48:20.828955Z","iopub.status.idle":"2023-08-09T23:48:21.475670Z","shell.execute_reply.started":"2023-08-09T23:48:20.828924Z","shell.execute_reply":"2023-08-09T23:48:21.474515Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"dt_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=500, max_samples=0.994711990802652,\n                           max_features=0.7844039008030275, bootstrap=False, bootstrap_features=True, random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:21.477250Z","iopub.execute_input":"2023-08-09T23:48:21.477721Z","iopub.status.idle":"2023-08-09T23:48:33.617780Z","shell.execute_reply.started":"2023-08-09T23:48:21.477678Z","shell.execute_reply":"2023-08-09T23:48:33.616721Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"rf_model = RandomForestClassifier(n_estimators=420, max_depth=13, min_samples_split=3, \n                                  min_samples_leaf=1, max_features=9, bootstrap=False, random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:33.619346Z","iopub.execute_input":"2023-08-09T23:48:33.620466Z","iopub.status.idle":"2023-08-09T23:48:36.150408Z","shell.execute_reply.started":"2023-08-09T23:48:33.620424Z","shell.execute_reply":"2023-08-09T23:48:36.149158Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"ada_model = AdaBoostClassifier(n_estimators=420, learning_rate=0.6794771047521856, \n                               base_estimator=DecisionTreeClassifier(max_depth=4), random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:36.152034Z","iopub.execute_input":"2023-08-09T23:48:36.152495Z","iopub.status.idle":"2023-08-09T23:48:44.160885Z","shell.execute_reply.started":"2023-08-09T23:48:36.152452Z","shell.execute_reply":"2023-08-09T23:48:44.159914Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"gradient_model = GradientBoostingClassifier(n_estimators=170, learning_rate=0.05893342084840253, max_depth=6, \n                                            min_samples_split=16, min_samples_leaf=11, subsample=0.9112739951878389, random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:44.162299Z","iopub.execute_input":"2023-08-09T23:48:44.162615Z","iopub.status.idle":"2023-08-09T23:48:47.424604Z","shell.execute_reply.started":"2023-08-09T23:48:44.162589Z","shell.execute_reply":"2023-08-09T23:48:47.423469Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"tab_lower_model = TabPFNClassifier(N_ensemble_configurations=20).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:47.426061Z","iopub.execute_input":"2023-08-09T23:48:47.426535Z","iopub.status.idle":"2023-08-09T23:48:50.420656Z","shell.execute_reply.started":"2023-08-09T23:48:47.426502Z","shell.execute_reply":"2023-08-09T23:48:50.419623Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Loading model that can be used for inference only\nUsing a Transformer with 25.82 M parameters\n","output_type":"stream"}]},{"cell_type":"code","source":"tab_upper_model = TabPFNClassifier(N_ensemble_configurations=66).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:50.422083Z","iopub.execute_input":"2023-08-09T23:48:50.422416Z","iopub.status.idle":"2023-08-09T23:48:53.270563Z","shell.execute_reply.started":"2023-08-09T23:48:50.422387Z","shell.execute_reply":"2023-08-09T23:48:53.269561Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Loading model that can be used for inference only\nUsing a Transformer with 25.82 M parameters\n","output_type":"stream"}]},{"cell_type":"code","source":"stacking_cat_model = CatBoostClassifier(n_estimators=150, reg_lambda=0.05055956136270572, colsample_bylevel=0.6, \n                                        subsample=0.5, learning_rate=0.08699165501504001, max_depth=7, \n                                        one_hot_max_size=8, random_state=seed, verbose=False).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:53.272375Z","iopub.execute_input":"2023-08-09T23:48:53.272813Z","iopub.status.idle":"2023-08-09T23:48:55.680582Z","shell.execute_reply.started":"2023-08-09T23:48:53.272768Z","shell.execute_reply":"2023-08-09T23:48:55.679602Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"stacking_xgb_model = xgboost.XGBClassifier(n_estimators=160, reg_lambda=0.030554982480056614, alpha=0.022993963306149747, \n                                           colsample_bytree=0.4, subsample=0.6, learning_rate=0.08378145372235492, \n                                           max_depth=17, min_child_weight=1, random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:55.682078Z","iopub.execute_input":"2023-08-09T23:48:55.682763Z","iopub.status.idle":"2023-08-09T23:48:56.165017Z","shell.execute_reply.started":"2023-08-09T23:48:55.682720Z","shell.execute_reply":"2023-08-09T23:48:56.163800Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"stacking_lgbm_model = lgb.LGBMClassifier(n_estimators=130, reg_alpha=0.017987440901161444, reg_lambda=0.0010110144342120994, \n                                colsample_bytree=0.8, subsample=0.5, learning_rate=0.08786840365732179, \n                                max_depth=5, num_leaves=10, min_child_samples=48, random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:56.166736Z","iopub.execute_input":"2023-08-09T23:48:56.167320Z","iopub.status.idle":"2023-08-09T23:48:56.519286Z","shell.execute_reply.started":"2023-08-09T23:48:56.167221Z","shell.execute_reply":"2023-08-09T23:48:56.518347Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"stacking_hgbc_model = HistGradientBoostingClassifier(learning_rate=0.9112141545526848, max_depth=5, min_samples_leaf=18, \n                                                     max_iter=160, random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:56.520645Z","iopub.execute_input":"2023-08-09T23:48:56.520955Z","iopub.status.idle":"2023-08-09T23:48:56.820502Z","shell.execute_reply.started":"2023-08-09T23:48:56.520928Z","shell.execute_reply":"2023-08-09T23:48:56.819365Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"## Testing Models","metadata":{}},{"cell_type":"code","source":"n_folds = 10\ndef CV_plus(model, data, loss_function):\n    skf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n    kfold = skf.split(data.iloc[:, 1:-1], data.iloc[:, -1])\n    losses = []\n    num_predictions_lt_01 = []\n    num_predictions_gt_09 = []\n    num_predictions_lt_02 = []\n    num_predictions_gt_08 = []\n    total_predictions = []\n    num_wrong_class1_predictions = []\n    num_wrong_class0_predictions = []\n    \n    for (train_id, val_id) in kfold:\n        x_train = data.iloc[train_id, 1:-1]\n        y_train = data.iloc[train_id, -1]\n        x_val = data.iloc[val_id, 1:-1]\n        y_val = data.iloc[val_id, -1]\n        model.fit(x_train, y_train)\n        pred_val = model.predict_proba(x_val)\n        pred_val_one = model.predict_proba(x_val)[:, 1]\n        loss = loss_function(y_val, pred_val)\n        losses.append(loss)\n        num_predictions_lt_01.append(np.sum((pred_val_one < 0.1)))\n        num_predictions_gt_09.append(np.sum((pred_val_one > 0.9)))\n        num_predictions_lt_02.append(np.sum((pred_val_one < 0.2)))\n        num_predictions_gt_08.append(np.sum((pred_val_one > 0.8)))\n        num_wrong_class1_predictions.append(np.sum(((y_val == 1) & (pred_val_one < 0.5))))\n        num_wrong_class0_predictions.append(np.sum(((y_val == 0) & (pred_val_one > 0.5))))\n        total_predictions.append(len(pred_val))\n    \n    avg_log_loss = np.sum(losses)\n    \n    return avg_log_loss, num_predictions_lt_01, num_predictions_gt_09, num_wrong_class1_predictions, num_wrong_class0_predictions, num_predictions_lt_02, num_predictions_gt_08, total_predictions","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:56.822229Z","iopub.execute_input":"2023-08-09T23:48:56.822592Z","iopub.status.idle":"2023-08-09T23:48:56.835812Z","shell.execute_reply.started":"2023-08-09T23:48:56.822562Z","shell.execute_reply":"2023-08-09T23:48:56.834622Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# models = [xgb_model, lgbm_model, cat_model, hgbc_model, dt_model, \n#           rf_model, ada_model, gradient_model, tab_lower_model, \n#           tab_upper_model, stacking_cat_model, stacking_xgb_model, \n#           stacking_lgbm_model, stacking_hgbc_model]\n\n# results_df = pd.DataFrame(columns=['Model', 'Accuracy', 'CV Balanced-Log-Loss', 'Predictions < 0.1', 'Predictions < 0.2',\n#                                    'Predictions > 0.8', 'Predictions > 0.9', 'Class 0 Wrong', 'Class 1 Wrong', 'Total'])\n\n# for model in models:\n#     print(\"Working on model: \", str(model))\n#     avg_log_loss, avg_num_predictions_lt_01, avg_num_predictions_gt_09, avg_num_wrong_class1_predictions, avg_num_wrong_class0_predictions, avg_num_predictions_lt_02, avg_num_predictions_gt_08, total_predictions = CV_plus(model, oversampled_df, balanced_log_loss)\n#     accuracy = 1.0 - (np.sum(avg_num_wrong_class1_predictions) + np.sum(avg_num_wrong_class0_predictions))/ len(oversampled_df)\n#     results_df = results_df.append({'Model': str(model), 'Accuracy': accuracy,\n#                                     'CV Balanced-Log-Loss': avg_log_loss, 'Predictions < 0.1': np.sum(avg_num_predictions_lt_01), 'Predictions < 0.2': np.sum(avg_num_predictions_lt_02),\n#                                     'Predictions > 0.8': np.sum(avg_num_predictions_gt_08), 'Predictions > 0.9': np.sum(avg_num_predictions_gt_09), 'Class 0 Wrong': np.sum(avg_num_wrong_class0_predictions), \n#                                     'Class 1 Wrong': np.sum(avg_num_wrong_class1_predictions), 'Total': np.sum(total_predictions)}, ignore_index=True)\n\n# print(results_df)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:56.837215Z","iopub.execute_input":"2023-08-09T23:48:56.837572Z","iopub.status.idle":"2023-08-09T23:48:56.855957Z","shell.execute_reply.started":"2023-08-09T23:48:56.837544Z","shell.execute_reply":"2023-08-09T23:48:56.854962Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"model = StackingClassifier(\n        estimators=[(\"tabpfn\", tab_lower_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model), (\"adaboost\", ada_model)],\n        final_estimator=LogisticRegression(C=0.1, random_state=seed)\n    ).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:56.857536Z","iopub.execute_input":"2023-08-09T23:48:56.857861Z","iopub.status.idle":"2023-08-09T23:49:43.382338Z","shell.execute_reply.started":"2023-08-09T23:48:56.857834Z","shell.execute_reply":"2023-08-09T23:49:43.379610Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Loading model that can be used for inference only\nUsing a Transformer with 25.82 M parameters\nLoading model that can be used for inference only\nUsing a Transformer with 25.82 M parameters\nLoading model that can be used for inference only\nUsing a Transformer with 25.82 M parameters\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[44], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mStackingClassifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcatboost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtabpfn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtab_lower_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlgbm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlgbm_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxgboost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madaboost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mada_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m----> 5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py:660\u001b[0m, in \u001b[0;36mStackingClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    659\u001b[0m     y_encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[0;32m--> 660\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py:252\u001b[0m, in \u001b[0;36m_BaseStacking.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m         cv\u001b[38;5;241m.\u001b[39mrandom_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState()\n\u001b[1;32m    249\u001b[0m     fit_params \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    250\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m: sample_weight} \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     )\n\u001b[0;32m--> 252\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcross_val_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_estimators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack_method_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# Only not None or not 'drop' estimators will be used in transform.\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# Remove the None from the method as well.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    270\u001b[0m     meth\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (meth, est) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_, all_estimators)\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m ]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:986\u001b[0m, in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    985\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 986\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    993\u001b[0m inv_test_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    994\u001b[0m inv_test_indices[test_indices] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:1070\u001b[0m, in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m   1068\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m   1069\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(estimator, method)\n\u001b[0;32m-> 1070\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1072\u001b[0m encode \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1073\u001b[0m     method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecision_function\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_log_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1074\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m )\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encode:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:266\u001b[0m, in \u001b[0;36mTabPFNClassifier.predict_proba\u001b[0;34m(self, X, normalize_with_test, return_logits)\u001b[0m\n\u001b[1;32m    262\u001b[0m y_full \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_full, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    264\u001b[0m eval_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 266\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43minference_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpreprocess_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_preprocess_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmix\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mnormalize_with_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize_with_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mN_ensemble_configurations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN_ensemble_configurations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43msoftmax_temperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmulticlass_decoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulticlass_decoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mfeature_shift_decoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_shift_decoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdifferentiable_hps_as_style\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdifferentiable_hps_as_style\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mreturn_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mno_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mbatch_size_inference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m                                 \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mget_params_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m prediction_, y_ \u001b[38;5;241m=\u001b[39m prediction\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m), y_full\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()[eval_pos:]\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction_\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad \u001b[38;5;28;01melse\u001b[39;00m prediction_\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:517\u001b[0m, in \u001b[0;36mtransformer_predict\u001b[0;34m(model, eval_xs, eval_ys, eval_position, device, max_features, style, inference_mode, num_classes, extend_features, normalize_with_test, normalize_to_ranking, softmax_temperature, multiclass_decoder, preprocess_transform, categorical_feats, feature_shift_decoder, N_ensemble_configurations, batch_size_inference, differentiable_hps_as_style, average_logits, fp16_inference, normalize_with_sqrt, seed, no_grad, return_logits, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    515\u001b[0m                         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 517\u001b[0m     output_batch \u001b[38;5;241m=\u001b[39m \u001b[43mcheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoftmax_temperature_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39mfp16_inference):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:249\u001b[0m, in \u001b[0;36mcheckpoint\u001b[0;34m(function, use_reentrant, *args, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected keyword arguments: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(arg \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m kwargs))\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_reentrant:\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckpointFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _checkpoint_without_reentrant(\n\u001b[1;32m    252\u001b[0m         function,\n\u001b[1;32m    253\u001b[0m         preserve,\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    256\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:107\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[0;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[1;32m    104\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(\u001b[38;5;241m*\u001b[39mtensor_inputs)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 107\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mrun_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:353\u001b[0m, in \u001b[0;36mtransformer_predict.<locals>.predict\u001b[0;34m(eval_xs, eval_ys, used_style, softmax_temperature, return_logits)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m inference_mode_call:\n\u001b[1;32m    352\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 353\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43mused_style\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_xs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mused_style\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_xs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_ys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m            \u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_position\u001b[49m\u001b[43m)\u001b[49m[:, :, \u001b[38;5;241m0\u001b[39m:num_classes]\n\u001b[1;32m    357\u001b[0m     output \u001b[38;5;241m=\u001b[39m output[:, :, \u001b[38;5;241m0\u001b[39m:num_classes] \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(softmax_temperature)\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_logits:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tabpfn/transformer.py:141\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, src, src_mask, single_eval_pos)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(src)\n\u001b[0;32m--> 141\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(output)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output[single_eval_pos\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(style_src)\u001b[38;5;241m+\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_att_embeddings\u001b[38;5;241m.\u001b[39mnum_embeddings \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_att_embeddings \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m):]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tabpfn/transformer.py:227\u001b[0m, in \u001b[0;36mTransformerEncoderDiffInit.forward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    224\u001b[0m output \u001b[38;5;241m=\u001b[39m src\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 227\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tabpfn/layer.py:109\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    107\u001b[0m     single_eval_position \u001b[38;5;241m=\u001b[39m src_mask\n\u001b[1;32m    108\u001b[0m     src_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(src_[:single_eval_position], src_[:single_eval_position], src_[:single_eval_position])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 109\u001b[0m     src_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_\u001b[49m\u001b[43m[\u001b[49m\u001b[43msingle_eval_position\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43msingle_eval_position\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43msingle_eval_position\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    110\u001b[0m     src2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([src_left, src_right], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/activation.py:1189\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1175\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1176\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1186\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1187\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5313\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5311\u001b[0m attn_output_weights \u001b[38;5;241m=\u001b[39m attn_output_weights\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, tgt_len, src_len)\n\u001b[1;32m   5312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average_attn_weights:\n\u001b[0;32m-> 5313\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mattn_output_weights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batched:\n\u001b[1;32m   5316\u001b[0m     \u001b[38;5;66;03m# squeeze the output if input was unbatched\u001b[39;00m\n\u001b[1;32m   5317\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"def round_up_down(num):\n    return 1 if num >= 0.5 else 0","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:49:43.383704Z","iopub.status.idle":"2023-08-09T23:49:43.384328Z","shell.execute_reply.started":"2023-08-09T23:49:43.383999Z","shell.execute_reply":"2023-08-09T23:49:43.384028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final.iloc[:, 1], final.iloc[:, -1] = model.predict_proba(test.iloc[:, 1:])[:, 0], model.predict_proba(test.iloc[:, 1:])[:, 1]\nfinal.to_csv('submission.csv', index=False)\nsubmission = pd.read_csv('submission.csv')\nsubmission","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:49:43.386423Z","iopub.status.idle":"2023-08-09T23:49:43.387474Z","shell.execute_reply.started":"2023-08-09T23:49:43.387150Z","shell.execute_reply":"2023-08-09T23:49:43.387178Z"},"trusted":true},"execution_count":null,"outputs":[]}]}