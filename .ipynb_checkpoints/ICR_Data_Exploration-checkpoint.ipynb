{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f52acf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score,train_test_split, KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error,r2_score,roc_curve,auc,precision_recall_curve, accuracy_score, \\\n",
    "recall_score, precision_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import VotingRegressor, VotingClassifier, StackingRegressor, StackingClassifier, GradientBoostingRegressor,GradientBoostingClassifier, BaggingRegressor,BaggingClassifier,RandomForestRegressor,RandomForestClassifier,AdaBoostRegressor,AdaBoostClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import itertools as it\n",
    "import time as time\n",
    "import xgboost as xgb\n",
    "from pyearth import Earth\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_selection import RFE\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a679850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "greeks = pd.read_csv('greeks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad365d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to dummy variables\n",
    "train['EJ'] = train['EJ'].apply(lambda x: 0 if x == 'A' else 1)\n",
    "test['EJ'] = test['EJ'].apply(lambda x: 0 if x == 'A' else 1)\n",
    "\n",
    "#Separating train data for predictors and response\n",
    "X_train = train.drop('Class', axis = 1)\n",
    "y_train = train.loc[:, 'Class']\n",
    "\n",
    "#Dropping id column\n",
    "X_train = X_train.drop('Id', axis = 1)\n",
    "test = test.drop('Id', axis = 1)\n",
    "\n",
    "#Creating validation data set\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.10, stratify = y_train)\n",
    "\n",
    "#Scaling the train and test data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(test)\n",
    "#X_val_scaled = scaler.transform(X_val)\n",
    "X_train = pd.DataFrame(X_train_scaled)\n",
    "X_test = pd.DataFrame(X_test_scaled)\n",
    "#X_val = pd.DataFrame(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e6360271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SKIP!!!\n",
    "#Using for loop to iterate over potential values of n_neighbors for imputing missing values, using a \n",
    "#CatBoostRegressor() to get train MSE as the parameter to choose best value\n",
    "scores = []\n",
    "val_scores = []\n",
    "for i in range(1, 40):\n",
    "    imputer = KNNImputer(n_neighbors = i)\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    model_test = CatBoostClassifier(verbose = False)\n",
    "    model_test.fit(X_train_imputed, y_train)\n",
    "\n",
    "    true_labels = np.array(y_train)\n",
    "    predicted_probs = np.array(model_test.predict_proba(X_train_imputed))\n",
    "\n",
    "    class_weights = np.mean(true_labels) / np.bincount(true_labels)\n",
    "    logloss_per_class = log_loss(true_labels, predicted_probs, labels=[0, 1], normalize=False)\n",
    "    balanced_logloss = np.sum(logloss_per_class * class_weights)\n",
    "    scores.append(balanced_logloss)\n",
    "    true_labels = np.array(y_val)\n",
    "    predicted_probs = np.array(model_test.predict_proba(X_val))\n",
    "\n",
    "    class_weights = np.mean(true_labels) / np.bincount(true_labels)\n",
    "    logloss_per_class = log_loss(true_labels, predicted_probs, labels=[0, 1], normalize=False)\n",
    "    balanced_logloss = np.sum(logloss_per_class * class_weights)\n",
    "    \n",
    "    val_scores.append(balanced_logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1f03a849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff63ba0eba8>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(1, len(scores) + 1)\n",
    "plt.plot(x, scores, label = 'Train Scores')\n",
    "plt.plot(x, val_scores, label = 'Validation Scores')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0169a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors = 10)\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "#X_val_imputed = imputer.transform(X_val)\n",
    "X_train = pd.DataFrame(X_train_imputed)\n",
    "#X_val = pd.DataFrame(X_val_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dd11105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial data analysis\n",
    "#print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "80cfd847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are 0.08264023663397657 for train data and 0.9237965382605047 for validation data.\n"
     ]
    }
   ],
   "source": [
    "# With all performance\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "results = balanced_log_loss(X_train, y_train, X_val, y_val, model)\n",
    "print(f'The results are {results[0]} for train data and {results[1]} for validation data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ddcf87a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are 0.08294645924201895 for train data and 0.3432603163684188 for validation data.\n"
     ]
    }
   ],
   "source": [
    "# With 50 variables performance\n",
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, n_features_to_select=50)\n",
    "rfe.fit(X_train, y_train)\n",
    "results = balanced_log_loss(X_train, y_train, X_val, y_val, rfe)\n",
    "print(f'The results are {results[0]} for train data and {results[1]} for validation data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c41bf001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are 0.08005792163385073 for train data and 0.32501721659281196 for validation data.\n"
     ]
    }
   ],
   "source": [
    "# With 40 variables performance\n",
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, n_features_to_select=40)\n",
    "rfe.fit(X_train, y_train)\n",
    "results = balanced_log_loss(X_train, y_train, X_val, y_val, rfe)\n",
    "print(f'The results are {results[0]} for train data and {results[1]} for validation data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "056ba423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are 0.07577995942699271 for train data and 0.32218710570319986 for validation data.\n"
     ]
    }
   ],
   "source": [
    "# With 30 variables performance\n",
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, n_features_to_select=30)\n",
    "rfe.fit(X_train, y_train)\n",
    "results = balanced_log_loss(X_train, y_train, X_val, y_val, rfe)\n",
    "print(f'The results are {results[0]} for train data and {results[1]} for validation data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "12c41131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are 0.07242304973221542 for train data and 0.9020813926608242 for validation data.\n"
     ]
    }
   ],
   "source": [
    "# With 20 variables performance\n",
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, n_features_to_select=20)\n",
    "rfe.fit(X_train, y_train)\n",
    "results = balanced_log_loss(X_train, y_train, X_val, y_val, rfe)\n",
    "print(f'The results are {results[0]} for train data and {results[1]} for validation data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9fc367ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are 0.07508378540226826 for train data and 0.8997287742485649 for validation data.\n"
     ]
    }
   ],
   "source": [
    "# With 10 variables performance\n",
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, n_features_to_select=10)\n",
    "rfe.fit(X_train, y_train)\n",
    "results = balanced_log_loss(X_train, y_train, X_val, y_val, rfe)\n",
    "print(f'The results are {results[0]} for train data and {results[1]} for validation data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f00c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "# Convert to dictionary format\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6f58ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "def balanced_log_loss(y_true, y_pred):\n",
    "    nc = np.bincount(y_true)\n",
    "    return log_loss(y_true, y_pred, sample_weight = 1/nc[y_true], eps=1e-15)\n",
    "balanced_log_loss_scorer = make_scorer(balanced_log_loss, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f3da20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Optimal parameter values = {'subsample': 0.85, 'reg_lambda': 12.5, 'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.01, 'colsample_bylevel': 0.85}\n",
      "Optimal cross validation log loss =  0.20966284792630216\n",
      "Time taken =  30  minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "param_grid = {'max_depth': [5, 6, 7],\n",
    "              'learning_rate': [0.005, 0.01, 0.015],\n",
    "                'n_estimators': [500, 1000, 1500],\n",
    "                'subsample': [0.75, 0.8, 0.85],\n",
    "             'reg_lambda': [12.5, 15, 17.5],\n",
    "             'colsample_bylevel': [0.85, 0.9, 0.95]}\n",
    "\n",
    "cv = KFold(n_splits = 5,shuffle = True, random_state = 1)\n",
    "optimal_params = RandomizedSearchCV(estimator = CatBoostClassifier(random_state = 1, verbose = False),                                                       \n",
    "                             param_distributions = param_grid, n_iter = 200,\n",
    "                             verbose = 1,random_state = 1,\n",
    "                             n_jobs = -1,\n",
    "                             cv = cv, scoring = 'neg_log_loss')\n",
    "optimal_params.fit(X_train, y_train, early_stopping_rounds = 10)\n",
    "print(\"Optimal parameter values =\", optimal_params.best_params_)\n",
    "print(\"Optimal cross validation log loss = \", -optimal_params.best_score_)\n",
    "print(\"Time taken = \", round((time.time() - start_time)/60), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e01b6df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "[1]\ttraining's binary_logloss: 0.437654\tvalid_1's binary_logloss: 0.454625\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's binary_logloss: 0.415778\tvalid_1's binary_logloss: 0.444635\n",
      "[3]\ttraining's binary_logloss: 0.395593\tvalid_1's binary_logloss: 0.429176\n",
      "[4]\ttraining's binary_logloss: 0.375881\tvalid_1's binary_logloss: 0.417854\n",
      "[5]\ttraining's binary_logloss: 0.358435\tvalid_1's binary_logloss: 0.407158\n",
      "[6]\ttraining's binary_logloss: 0.344053\tvalid_1's binary_logloss: 0.399663\n",
      "[7]\ttraining's binary_logloss: 0.329533\tvalid_1's binary_logloss: 0.389934\n",
      "[8]\ttraining's binary_logloss: 0.316791\tvalid_1's binary_logloss: 0.383477\n",
      "[9]\ttraining's binary_logloss: 0.30475\tvalid_1's binary_logloss: 0.373238\n",
      "[10]\ttraining's binary_logloss: 0.294032\tvalid_1's binary_logloss: 0.368151\n",
      "[11]\ttraining's binary_logloss: 0.28407\tvalid_1's binary_logloss: 0.364983\n",
      "[12]\ttraining's binary_logloss: 0.274131\tvalid_1's binary_logloss: 0.360124\n",
      "[13]\ttraining's binary_logloss: 0.264577\tvalid_1's binary_logloss: 0.354537\n",
      "[14]\ttraining's binary_logloss: 0.255146\tvalid_1's binary_logloss: 0.35255\n",
      "[15]\ttraining's binary_logloss: 0.247036\tvalid_1's binary_logloss: 0.347161\n",
      "[16]\ttraining's binary_logloss: 0.239087\tvalid_1's binary_logloss: 0.34234\n",
      "[17]\ttraining's binary_logloss: 0.232099\tvalid_1's binary_logloss: 0.336983\n",
      "[18]\ttraining's binary_logloss: 0.225414\tvalid_1's binary_logloss: 0.331106\n",
      "[19]\ttraining's binary_logloss: 0.219264\tvalid_1's binary_logloss: 0.32832\n",
      "[20]\ttraining's binary_logloss: 0.213349\tvalid_1's binary_logloss: 0.326494\n",
      "[21]\ttraining's binary_logloss: 0.207516\tvalid_1's binary_logloss: 0.324859\n",
      "[22]\ttraining's binary_logloss: 0.20181\tvalid_1's binary_logloss: 0.321622\n",
      "[23]\ttraining's binary_logloss: 0.196707\tvalid_1's binary_logloss: 0.318282\n",
      "[24]\ttraining's binary_logloss: 0.191367\tvalid_1's binary_logloss: 0.313706\n",
      "[25]\ttraining's binary_logloss: 0.186679\tvalid_1's binary_logloss: 0.308626\n",
      "[26]\ttraining's binary_logloss: 0.18179\tvalid_1's binary_logloss: 0.305485\n",
      "[27]\ttraining's binary_logloss: 0.177359\tvalid_1's binary_logloss: 0.304602\n",
      "[28]\ttraining's binary_logloss: 0.172991\tvalid_1's binary_logloss: 0.30232\n",
      "[29]\ttraining's binary_logloss: 0.168844\tvalid_1's binary_logloss: 0.302363\n",
      "[30]\ttraining's binary_logloss: 0.165059\tvalid_1's binary_logloss: 0.299303\n",
      "[31]\ttraining's binary_logloss: 0.161241\tvalid_1's binary_logloss: 0.295883\n",
      "[32]\ttraining's binary_logloss: 0.157714\tvalid_1's binary_logloss: 0.292194\n",
      "[33]\ttraining's binary_logloss: 0.154472\tvalid_1's binary_logloss: 0.290264\n",
      "[34]\ttraining's binary_logloss: 0.150847\tvalid_1's binary_logloss: 0.286445\n",
      "[35]\ttraining's binary_logloss: 0.147603\tvalid_1's binary_logloss: 0.28809\n",
      "[36]\ttraining's binary_logloss: 0.144774\tvalid_1's binary_logloss: 0.286364\n",
      "[37]\ttraining's binary_logloss: 0.141539\tvalid_1's binary_logloss: 0.283197\n",
      "[38]\ttraining's binary_logloss: 0.138378\tvalid_1's binary_logloss: 0.282582\n",
      "[39]\ttraining's binary_logloss: 0.13551\tvalid_1's binary_logloss: 0.279999\n",
      "[40]\ttraining's binary_logloss: 0.132546\tvalid_1's binary_logloss: 0.279111\n",
      "[41]\ttraining's binary_logloss: 0.129938\tvalid_1's binary_logloss: 0.277407\n",
      "[42]\ttraining's binary_logloss: 0.127547\tvalid_1's binary_logloss: 0.274181\n",
      "[43]\ttraining's binary_logloss: 0.124922\tvalid_1's binary_logloss: 0.273885\n",
      "[44]\ttraining's binary_logloss: 0.122694\tvalid_1's binary_logloss: 0.272813\n",
      "[45]\ttraining's binary_logloss: 0.120287\tvalid_1's binary_logloss: 0.270826\n",
      "[46]\ttraining's binary_logloss: 0.11807\tvalid_1's binary_logloss: 0.270395\n",
      "[47]\ttraining's binary_logloss: 0.115692\tvalid_1's binary_logloss: 0.269973\n",
      "[48]\ttraining's binary_logloss: 0.113603\tvalid_1's binary_logloss: 0.269124\n",
      "[49]\ttraining's binary_logloss: 0.111565\tvalid_1's binary_logloss: 0.26844\n",
      "[50]\ttraining's binary_logloss: 0.109638\tvalid_1's binary_logloss: 0.265411\n",
      "[51]\ttraining's binary_logloss: 0.107857\tvalid_1's binary_logloss: 0.264026\n",
      "[52]\ttraining's binary_logloss: 0.105919\tvalid_1's binary_logloss: 0.26311\n",
      "[53]\ttraining's binary_logloss: 0.10419\tvalid_1's binary_logloss: 0.263646\n",
      "[54]\ttraining's binary_logloss: 0.102325\tvalid_1's binary_logloss: 0.26305\n",
      "[55]\ttraining's binary_logloss: 0.1005\tvalid_1's binary_logloss: 0.2601\n",
      "[56]\ttraining's binary_logloss: 0.0988653\tvalid_1's binary_logloss: 0.258737\n",
      "[57]\ttraining's binary_logloss: 0.0971558\tvalid_1's binary_logloss: 0.258428\n",
      "[58]\ttraining's binary_logloss: 0.0955852\tvalid_1's binary_logloss: 0.257919\n",
      "[59]\ttraining's binary_logloss: 0.0940278\tvalid_1's binary_logloss: 0.255905\n",
      "[60]\ttraining's binary_logloss: 0.092524\tvalid_1's binary_logloss: 0.25402\n",
      "[61]\ttraining's binary_logloss: 0.091001\tvalid_1's binary_logloss: 0.25318\n",
      "[62]\ttraining's binary_logloss: 0.0895776\tvalid_1's binary_logloss: 0.253549\n",
      "[63]\ttraining's binary_logloss: 0.0880486\tvalid_1's binary_logloss: 0.252202\n",
      "[64]\ttraining's binary_logloss: 0.0867866\tvalid_1's binary_logloss: 0.253083\n",
      "[65]\ttraining's binary_logloss: 0.0853611\tvalid_1's binary_logloss: 0.253617\n",
      "[66]\ttraining's binary_logloss: 0.0839678\tvalid_1's binary_logloss: 0.251419\n",
      "[67]\ttraining's binary_logloss: 0.0825792\tvalid_1's binary_logloss: 0.249125\n",
      "[68]\ttraining's binary_logloss: 0.0813726\tvalid_1's binary_logloss: 0.247524\n",
      "[69]\ttraining's binary_logloss: 0.0802526\tvalid_1's binary_logloss: 0.245695\n",
      "[70]\ttraining's binary_logloss: 0.0791345\tvalid_1's binary_logloss: 0.247131\n",
      "[71]\ttraining's binary_logloss: 0.0779446\tvalid_1's binary_logloss: 0.247748\n",
      "[72]\ttraining's binary_logloss: 0.0768864\tvalid_1's binary_logloss: 0.247184\n",
      "[73]\ttraining's binary_logloss: 0.0757014\tvalid_1's binary_logloss: 0.246086\n",
      "[74]\ttraining's binary_logloss: 0.0745568\tvalid_1's binary_logloss: 0.245691\n",
      "[75]\ttraining's binary_logloss: 0.0735452\tvalid_1's binary_logloss: 0.245146\n",
      "[76]\ttraining's binary_logloss: 0.0725025\tvalid_1's binary_logloss: 0.242945\n",
      "[77]\ttraining's binary_logloss: 0.0715605\tvalid_1's binary_logloss: 0.240711\n",
      "[78]\ttraining's binary_logloss: 0.0705266\tvalid_1's binary_logloss: 0.23986\n",
      "[79]\ttraining's binary_logloss: 0.0696397\tvalid_1's binary_logloss: 0.239171\n",
      "[80]\ttraining's binary_logloss: 0.0686676\tvalid_1's binary_logloss: 0.23909\n",
      "[81]\ttraining's binary_logloss: 0.0678858\tvalid_1's binary_logloss: 0.24013\n",
      "[82]\ttraining's binary_logloss: 0.0669842\tvalid_1's binary_logloss: 0.23906\n",
      "[83]\ttraining's binary_logloss: 0.0661084\tvalid_1's binary_logloss: 0.237379\n",
      "[84]\ttraining's binary_logloss: 0.0651708\tvalid_1's binary_logloss: 0.237478\n",
      "[85]\ttraining's binary_logloss: 0.0642676\tvalid_1's binary_logloss: 0.2372\n",
      "[86]\ttraining's binary_logloss: 0.0633927\tvalid_1's binary_logloss: 0.236348\n",
      "[87]\ttraining's binary_logloss: 0.0626167\tvalid_1's binary_logloss: 0.235183\n",
      "[88]\ttraining's binary_logloss: 0.061821\tvalid_1's binary_logloss: 0.235165\n",
      "[89]\ttraining's binary_logloss: 0.061043\tvalid_1's binary_logloss: 0.2345\n",
      "[90]\ttraining's binary_logloss: 0.0603132\tvalid_1's binary_logloss: 0.233087\n",
      "[91]\ttraining's binary_logloss: 0.0594986\tvalid_1's binary_logloss: 0.23211\n",
      "[92]\ttraining's binary_logloss: 0.0587677\tvalid_1's binary_logloss: 0.232452\n",
      "[93]\ttraining's binary_logloss: 0.0579796\tvalid_1's binary_logloss: 0.232272\n",
      "[94]\ttraining's binary_logloss: 0.0572946\tvalid_1's binary_logloss: 0.232141\n",
      "[95]\ttraining's binary_logloss: 0.0565876\tvalid_1's binary_logloss: 0.231155\n",
      "[96]\ttraining's binary_logloss: 0.0559275\tvalid_1's binary_logloss: 0.229409\n",
      "[97]\ttraining's binary_logloss: 0.0552697\tvalid_1's binary_logloss: 0.229923\n",
      "[98]\ttraining's binary_logloss: 0.05457\tvalid_1's binary_logloss: 0.230712\n",
      "[99]\ttraining's binary_logloss: 0.0539447\tvalid_1's binary_logloss: 0.230408\n",
      "[100]\ttraining's binary_logloss: 0.0533176\tvalid_1's binary_logloss: 0.229594\n",
      "[101]\ttraining's binary_logloss: 0.0527061\tvalid_1's binary_logloss: 0.229378\n",
      "[102]\ttraining's binary_logloss: 0.0521202\tvalid_1's binary_logloss: 0.229379\n",
      "[103]\ttraining's binary_logloss: 0.0515614\tvalid_1's binary_logloss: 0.229896\n",
      "[104]\ttraining's binary_logloss: 0.0509901\tvalid_1's binary_logloss: 0.228449\n",
      "[105]\ttraining's binary_logloss: 0.0503956\tvalid_1's binary_logloss: 0.228484\n",
      "[106]\ttraining's binary_logloss: 0.0498688\tvalid_1's binary_logloss: 0.228396\n",
      "[107]\ttraining's binary_logloss: 0.0493989\tvalid_1's binary_logloss: 0.229196\n",
      "[108]\ttraining's binary_logloss: 0.0488718\tvalid_1's binary_logloss: 0.229176\n",
      "[109]\ttraining's binary_logloss: 0.0483587\tvalid_1's binary_logloss: 0.229055\n",
      "[110]\ttraining's binary_logloss: 0.0478581\tvalid_1's binary_logloss: 0.228984\n",
      "[111]\ttraining's binary_logloss: 0.0473492\tvalid_1's binary_logloss: 0.229744\n",
      "[112]\ttraining's binary_logloss: 0.0468471\tvalid_1's binary_logloss: 0.229013\n",
      "[113]\ttraining's binary_logloss: 0.0463794\tvalid_1's binary_logloss: 0.227556\n",
      "[114]\ttraining's binary_logloss: 0.0458043\tvalid_1's binary_logloss: 0.228085\n",
      "[115]\ttraining's binary_logloss: 0.0453019\tvalid_1's binary_logloss: 0.226892\n",
      "[116]\ttraining's binary_logloss: 0.044838\tvalid_1's binary_logloss: 0.226306\n",
      "[117]\ttraining's binary_logloss: 0.04435\tvalid_1's binary_logloss: 0.226841\n",
      "[118]\ttraining's binary_logloss: 0.0439167\tvalid_1's binary_logloss: 0.226681\n",
      "[119]\ttraining's binary_logloss: 0.0434551\tvalid_1's binary_logloss: 0.226362\n",
      "[120]\ttraining's binary_logloss: 0.0430149\tvalid_1's binary_logloss: 0.226119\n",
      "[121]\ttraining's binary_logloss: 0.0425623\tvalid_1's binary_logloss: 0.225597\n",
      "[122]\ttraining's binary_logloss: 0.0421265\tvalid_1's binary_logloss: 0.225209\n",
      "[123]\ttraining's binary_logloss: 0.0417285\tvalid_1's binary_logloss: 0.225017\n",
      "[124]\ttraining's binary_logloss: 0.041314\tvalid_1's binary_logloss: 0.224789\n",
      "[125]\ttraining's binary_logloss: 0.0409365\tvalid_1's binary_logloss: 0.224651\n",
      "[126]\ttraining's binary_logloss: 0.0405362\tvalid_1's binary_logloss: 0.224412\n",
      "[127]\ttraining's binary_logloss: 0.0402107\tvalid_1's binary_logloss: 0.224885\n",
      "[128]\ttraining's binary_logloss: 0.0397753\tvalid_1's binary_logloss: 0.224649\n",
      "[129]\ttraining's binary_logloss: 0.0394073\tvalid_1's binary_logloss: 0.224589\n",
      "[130]\ttraining's binary_logloss: 0.0390701\tvalid_1's binary_logloss: 0.224317\n",
      "[131]\ttraining's binary_logloss: 0.0387124\tvalid_1's binary_logloss: 0.224448\n",
      "[132]\ttraining's binary_logloss: 0.0383713\tvalid_1's binary_logloss: 0.223943\n",
      "[133]\ttraining's binary_logloss: 0.0380236\tvalid_1's binary_logloss: 0.223154\n",
      "[134]\ttraining's binary_logloss: 0.037672\tvalid_1's binary_logloss: 0.223188\n",
      "[135]\ttraining's binary_logloss: 0.0373105\tvalid_1's binary_logloss: 0.223547\n",
      "[136]\ttraining's binary_logloss: 0.0369888\tvalid_1's binary_logloss: 0.223376\n",
      "[137]\ttraining's binary_logloss: 0.0367097\tvalid_1's binary_logloss: 0.223581\n",
      "[138]\ttraining's binary_logloss: 0.0363905\tvalid_1's binary_logloss: 0.22291\n",
      "[139]\ttraining's binary_logloss: 0.0360631\tvalid_1's binary_logloss: 0.223259\n",
      "[140]\ttraining's binary_logloss: 0.0357546\tvalid_1's binary_logloss: 0.222916\n",
      "[141]\ttraining's binary_logloss: 0.0354014\tvalid_1's binary_logloss: 0.222801\n",
      "[142]\ttraining's binary_logloss: 0.0350979\tvalid_1's binary_logloss: 0.222993\n",
      "[143]\ttraining's binary_logloss: 0.0347963\tvalid_1's binary_logloss: 0.223038\n",
      "[144]\ttraining's binary_logloss: 0.0345314\tvalid_1's binary_logloss: 0.222253\n",
      "[145]\ttraining's binary_logloss: 0.0342018\tvalid_1's binary_logloss: 0.222234\n",
      "[146]\ttraining's binary_logloss: 0.0339031\tvalid_1's binary_logloss: 0.222684\n",
      "[147]\ttraining's binary_logloss: 0.0336516\tvalid_1's binary_logloss: 0.223463\n",
      "[148]\ttraining's binary_logloss: 0.0333803\tvalid_1's binary_logloss: 0.222734\n",
      "[149]\ttraining's binary_logloss: 0.0330974\tvalid_1's binary_logloss: 0.222979\n",
      "[150]\ttraining's binary_logloss: 0.0328237\tvalid_1's binary_logloss: 0.223023\n",
      "[151]\ttraining's binary_logloss: 0.0325483\tvalid_1's binary_logloss: 0.222831\n",
      "[152]\ttraining's binary_logloss: 0.0323209\tvalid_1's binary_logloss: 0.223373\n",
      "[153]\ttraining's binary_logloss: 0.0320594\tvalid_1's binary_logloss: 0.222312\n",
      "[154]\ttraining's binary_logloss: 0.0317982\tvalid_1's binary_logloss: 0.22224\n",
      "[155]\ttraining's binary_logloss: 0.0315548\tvalid_1's binary_logloss: 0.221882\n",
      "[156]\ttraining's binary_logloss: 0.0312989\tvalid_1's binary_logloss: 0.222117\n",
      "[157]\ttraining's binary_logloss: 0.0310257\tvalid_1's binary_logloss: 0.222697\n",
      "[158]\ttraining's binary_logloss: 0.0307943\tvalid_1's binary_logloss: 0.222738\n",
      "[159]\ttraining's binary_logloss: 0.0305148\tvalid_1's binary_logloss: 0.222343\n",
      "[160]\ttraining's binary_logloss: 0.0302788\tvalid_1's binary_logloss: 0.222153\n",
      "[161]\ttraining's binary_logloss: 0.0300586\tvalid_1's binary_logloss: 0.222113\n",
      "[162]\ttraining's binary_logloss: 0.0298224\tvalid_1's binary_logloss: 0.222291\n",
      "[163]\ttraining's binary_logloss: 0.0295864\tvalid_1's binary_logloss: 0.221667\n",
      "[164]\ttraining's binary_logloss: 0.0293547\tvalid_1's binary_logloss: 0.221944\n",
      "[165]\ttraining's binary_logloss: 0.0291581\tvalid_1's binary_logloss: 0.221516\n",
      "[166]\ttraining's binary_logloss: 0.0289479\tvalid_1's binary_logloss: 0.221784\n",
      "[167]\ttraining's binary_logloss: 0.0287159\tvalid_1's binary_logloss: 0.221667\n",
      "[168]\ttraining's binary_logloss: 0.0285229\tvalid_1's binary_logloss: 0.222355\n",
      "[169]\ttraining's binary_logloss: 0.0283014\tvalid_1's binary_logloss: 0.222878\n",
      "[170]\ttraining's binary_logloss: 0.0280885\tvalid_1's binary_logloss: 0.223\n",
      "[171]\ttraining's binary_logloss: 0.0278752\tvalid_1's binary_logloss: 0.22321\n",
      "[172]\ttraining's binary_logloss: 0.0276815\tvalid_1's binary_logloss: 0.222441\n",
      "[173]\ttraining's binary_logloss: 0.0274864\tvalid_1's binary_logloss: 0.22223\n",
      "[174]\ttraining's binary_logloss: 0.0272862\tvalid_1's binary_logloss: 0.22244\n",
      "[175]\ttraining's binary_logloss: 0.0271018\tvalid_1's binary_logloss: 0.222049\n",
      "Early stopping, best iteration is:\n",
      "[165]\ttraining's binary_logloss: 0.0291581\tvalid_1's binary_logloss: 0.221516\n",
      "Optimal parameter values = {'subsample': 1.0, 'reg_lambda': 10, 'reg_alpha': 0, 'num_leaves': 20, 'n_estimators': 500, 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 0.75}\n",
      "Optimal cross validation log loss =  0.20625023316725916\n",
      "Time taken =  0  minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "param_grid = {'max_depth': [4, 6, 8],\n",
    "              'num_leaves': [20, 31, 40],\n",
    "              'learning_rate': [0.01, 0.05, 0.1],\n",
    "               'reg_lambda':[0, 10, 100],\n",
    "                'n_estimators':[100, 500, 1000],\n",
    "                'reg_alpha': [0, 10, 100],\n",
    "                'subsample': [0.5, 0.75, 1.0],\n",
    "                'colsample_bytree': [0.5, 0.75, 1.0]}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "optimal_params_2 = RandomizedSearchCV(estimator=LGBMClassifier(random_state=1),                                                       \n",
    "                             param_distributions = param_grid, n_iter = 200,\n",
    "                             verbose = 1,\n",
    "                             n_jobs=-1,\n",
    "                             cv = cv, scoring = 'neg_log_loss')\n",
    "optimal_params_2.fit(X_train, y_train, early_stopping_rounds = 10, eval_metric='logloss', eval_set=[(X_train, y_train), (X_val, y_val)])\n",
    "print(\"Optimal parameter values =\", optimal_params_2.best_params_)\n",
    "print(\"Optimal cross validation log loss = \", -optimal_params.best_score_)\n",
    "print(\"Time taken = \", round((time.time()-start_time)/60), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "80d7a711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n",
      "Best Parameters:  {'bootstrap': False, 'max_depth': 14, 'max_features': 9, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 500}\n",
      "Best Score:  4.776333884808826\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': [500],\n",
    "          'max_features': list(range(7, 12)),\n",
    "          'max_depth': [14, 15, 16],\n",
    "          'min_samples_split': [1, 2, 3],\n",
    "          'min_samples_leaf': [1, 2, 3],\n",
    "          'bootstrap': [True, False]}\n",
    "\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "rf_regressor_grid = GridSearchCV(RandomForestClassifier(random_state=1, n_jobs=-1), \n",
    "                                      param_grid =params, cv=cv, n_jobs=-1, verbose=1, scoring=balanced_log_loss_scorer)\n",
    "rf_regressor_grid.fit(X_train, y_train)\n",
    "print('Best Parameters: ', rf_regressor_grid.best_params_)\n",
    "print('Best Score: ', -rf_regressor_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fedbab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Parameters:  {'bootstrap': False, 'bootstrap_features': True, 'max_features': 0.5, 'max_samples': 1.0, 'n_estimators': 400}\n",
      "Best Score:  0.23710099474971216\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': [400],\n",
    "    'max_samples': [0.5, 0.75, 1.0],\n",
    "    'max_features': [0.5, 0.75, 1.0],\n",
    "    'bootstrap': [True, False],\n",
    "    'bootstrap_features': [True, False]\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "bagging_regressor_grid = GridSearchCV(\n",
    "    BaggingClassifier(),\n",
    "    param_grid = params,\n",
    "    cv = cv,\n",
    "    scoring = 'neg_log_loss',\n",
    "    n_jobs = -1,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "bagging_regressor_grid.fit(X_train, y_train)\n",
    "print('Best Parameters: ', bagging_regressor_grid.best_params_)\n",
    "print('Best Score: ', -bagging_regressor_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36492bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best: 0.199700 using {'base_estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 1.0, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier(random_state=1)\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100,200,500]\n",
    "grid['learning_rate'] = [0.0001, 0.001, 0.01,0.1, 1.0]\n",
    "grid['base_estimator'] = [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2), \n",
    "                          DecisionTreeClassifier(max_depth=3),DecisionTreeClassifier(max_depth=4)]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, \n",
    "                          verbose = True, scoring = 'neg_log_loss')\n",
    "\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (-grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f1268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning the random forest parameters\n",
    "start_time = time.time()\n",
    "oob_score = {}\n",
    "\n",
    "i=0\n",
    "for pr in range(1,5):\n",
    "    model = StackingClassifier(estimators=[('ada',grid_result),('rf',rf_regressor_grid),('lgbm',optimal_params_2),('catboost',optimal_params),('dt', bagging_regressor_grid)],\n",
    "                                   final_estimator=RandomForestClassifier(n_estimators=500, max_features=pr,\n",
    "                                    random_state=1,oob_score=True),n_jobs=-1,\n",
    "                                   cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=1)).fit(X_train, y_train)\n",
    "    y_pred_probs = model.predict_proba(X_val)\n",
    "    neg_log_loss = log_loss(y_val, y_pred_probs)\n",
    "    oob_score[pr] = neg_log_loss\n",
    "    \n",
    "end_time = time.time()\n",
    "print(\"time taken = \", (end_time-start_time)/60, \" minutes\")\n",
    "print(\"max accuracy = \", np.max(list(oob_score.values())))\n",
    "print(\"Best value of max_features= \", np.argmax(list(oob_score.values()))+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa71959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
