{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f52acf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score,train_test_split, KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error,r2_score,roc_curve,auc,precision_recall_curve, accuracy_score, \\\n",
    "recall_score, precision_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import VotingRegressor, VotingClassifier, StackingRegressor, StackingClassifier, GradientBoostingRegressor,GradientBoostingClassifier, BaggingRegressor,BaggingClassifier,RandomForestRegressor,RandomForestClassifier,AdaBoostRegressor,AdaBoostClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import itertools as it\n",
    "import time as time\n",
    "import xgboost as xgb\n",
    "from pyearth import Earth\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_selection import RFE\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a679850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "greeks = pd.read_csv('greeks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "576405a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to dummy variables\n",
    "train['EJ'] = train['EJ'].apply(lambda x: 0 if x == 'A' else 1)\n",
    "test['EJ'] = test['EJ'].apply(lambda x: 0 if x == 'A' else 1)\n",
    "\n",
    "#Separating train data for predictors and response\n",
    "X_train = train.drop('Class', axis = 1)\n",
    "y_train = train.loc[:, 'Class']\n",
    "\n",
    "#Dropping id column\n",
    "X_train = X_train.drop('Id', axis = 1)\n",
    "test = test.drop('Id', axis = 1)\n",
    "\n",
    "#Creating validation data set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.10, stratify = y_train)\n",
    "\n",
    "#Scaling the train and test data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(test)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_train = pd.DataFrame(X_train_scaled)\n",
    "X_test = pd.DataFrame(X_test_scaled)\n",
    "X_val = pd.DataFrame(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5b2d7e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SKIP!!!\n",
    "#Using for loop to iterate over potential values of n_neighbors for imputing missing values, using a \n",
    "#CatBoostRegressor() to get train MSE as the parameter to choose best value\n",
    "scores = []\n",
    "val_scores = []\n",
    "for i in range(1, 40):\n",
    "    imputer = KNNImputer(n_neighbors = i)\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    model_test = CatBoostClassifier(verbose = False)\n",
    "    model_test.fit(X_train_imputed, y_train)\n",
    "\n",
    "    true_labels = np.array(y_train)\n",
    "    predicted_probs = np.array(model_test.predict_proba(X_train_imputed))\n",
    "\n",
    "    class_weights = np.mean(true_labels) / np.bincount(true_labels)\n",
    "    logloss_per_class = log_loss(true_labels, predicted_probs, labels=[0, 1], normalize=False)\n",
    "    balanced_logloss = np.sum(logloss_per_class * class_weights)\n",
    "    scores.append(balanced_logloss)\n",
    "    true_labels = np.array(y_val)\n",
    "    predicted_probs = np.array(model_test.predict_proba(X_val))\n",
    "\n",
    "    class_weights = np.mean(true_labels) / np.bincount(true_labels)\n",
    "    logloss_per_class = log_loss(true_labels, predicted_probs, labels=[0, 1], normalize=False)\n",
    "    balanced_logloss = np.sum(logloss_per_class * class_weights)\n",
    "    \n",
    "    val_scores.append(balanced_logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "75fced00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff63ba0eba8>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(1, len(scores) + 1)\n",
    "plt.plot(x, scores, label = 'Train Scores')\n",
    "plt.plot(x, val_scores, label = 'Validation Scores')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "65836e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors = 10)\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_val_imputed = imputer.transform(X_val)\n",
    "X_train = pd.DataFrame(X_train_imputed)\n",
    "X_val = pd.DataFrame(X_val_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "90992635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial data analysis\n",
    "#print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "77a9e648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292    0\n",
       "450    0\n",
       "148    0\n",
       "559    1\n",
       "522    0\n",
       "      ..\n",
       "58     0\n",
       "178    0\n",
       "610    0\n",
       "233    0\n",
       "216    0\n",
       "Name: Class, Length: 555, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "37fd7881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_log_loss(X_train, y_train, X_val, y_val, model_test):\n",
    "    scores = []\n",
    "    true_labels = np.array(y_train)\n",
    "    predicted_probs = np.array(model_test.predict_proba(X_train))\n",
    "    class_weights = np.mean(true_labels) / np.bincount(true_labels)\n",
    "    logloss_per_class = log_loss(true_labels, predicted_probs, labels=[0, 1], normalize=False)\n",
    "    balanced_logloss = np.sum(logloss_per_class * class_weights)\n",
    "    scores.append(balanced_logloss)\n",
    "    true_labels = np.array(y_val)\n",
    "    predicted_probs = np.array(model_test.predict_proba(X_val))\n",
    "    class_weights = np.mean(true_labels) / np.bincount(true_labels)\n",
    "    logloss_per_class = log_loss(true_labels, predicted_probs, labels=[0, 1], normalize=False)\n",
    "    balanced_logloss = np.sum(logloss_per_class * class_weights)\n",
    "    scores.append(balanced_logloss)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3d6d2b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are 0.08264023663397657 for train data and 0.9237965382605047 for validation data.\n"
     ]
    }
   ],
   "source": [
    "# With all performance\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "results = balanced_log_loss(X_train, y_train, X_val, y_val, model)\n",
    "print(f'The results are {results[0]} for train data and {results[1]} for validation data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a8b1214e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are 0.08294645924201895 for train data and 0.3432603163684188 for validation data.\n"
     ]
    }
   ],
   "source": [
    "# With 50 variables performance\n",
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, n_features_to_select=50)\n",
    "rfe.fit(X_train, y_train)\n",
    "results = balanced_log_loss(X_train, y_train, X_val, y_val, rfe)\n",
    "print(f'The results are {results[0]} for train data and {results[1]} for validation data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4d6cb214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are 0.08005792163385073 for train data and 0.32501721659281196 for validation data.\n"
     ]
    }
   ],
   "source": [
    "# With 40 variables performance\n",
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, n_features_to_select=40)\n",
    "rfe.fit(X_train, y_train)\n",
    "results = balanced_log_loss(X_train, y_train, X_val, y_val, rfe)\n",
    "print(f'The results are {results[0]} for train data and {results[1]} for validation data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3742d5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are 0.07577995942699271 for train data and 0.32218710570319986 for validation data.\n"
     ]
    }
   ],
   "source": [
    "# With 30 variables performance\n",
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, n_features_to_select=30)\n",
    "rfe.fit(X_train, y_train)\n",
    "results = balanced_log_loss(X_train, y_train, X_val, y_val, rfe)\n",
    "print(f'The results are {results[0]} for train data and {results[1]} for validation data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f2b26941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are 0.07242304973221542 for train data and 0.9020813926608242 for validation data.\n"
     ]
    }
   ],
   "source": [
    "# With 20 variables performance\n",
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, n_features_to_select=20)\n",
    "rfe.fit(X_train, y_train)\n",
    "results = balanced_log_loss(X_train, y_train, X_val, y_val, rfe)\n",
    "print(f'The results are {results[0]} for train data and {results[1]} for validation data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fc07aa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are 0.07508378540226826 for train data and 0.8997287742485649 for validation data.\n"
     ]
    }
   ],
   "source": [
    "# With 10 variables performance\n",
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, n_features_to_select=10)\n",
    "rfe.fit(X_train, y_train)\n",
    "results = balanced_log_loss(X_train, y_train, X_val, y_val, rfe)\n",
    "print(f'The results are {results[0]} for train data and {results[1]} for validation data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ffed3688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Optimal parameter values = {'subsample': 1.0, 'reg_lambda': 10, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.2, 'colsample_bylevel': 0.75}\n",
      "Optimal cross validation log loss =  0.1851785439310943\n",
      "Time taken =  19  minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "param_grid = {'max_depth': [4, 6, 8],\n",
    "              'learning_rate': [0.01, 0.1, 0.2],\n",
    "               'reg_lambda': [0.1, 1, 100],\n",
    "                'n_estimators': [100, 500, 1000],\n",
    "                'subsample': [0.5, 0.75, 1.0],\n",
    "             'reg_lambda': [0, 10, 100],\n",
    "             'colsample_bylevel': [0.5, 0.75, 1.0]}\n",
    "\n",
    "cv = KFold(n_splits = 5,shuffle = True, random_state = 1)\n",
    "optimal_params = RandomizedSearchCV(estimator = CatBoostClassifier(random_state = 1, verbose = False),                                                       \n",
    "                             param_distributions = param_grid, n_iter = 200,\n",
    "                             verbose = 1,random_state = 1,\n",
    "                             n_jobs = -1,\n",
    "                             cv = cv, scoring = 'neg_log_loss')\n",
    "optimal_params.fit(X_train, y_train, early_stopping_rounds = 10)\n",
    "print(\"Optimal parameter values =\", optimal_params.best_params_)\n",
    "print(\"Optimal cross validation log loss = \", -optimal_params.best_score_)\n",
    "print(\"Time taken = \", round((time.time() - start_time)/60), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f3d6b5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "[1]\ttraining's binary_logloss: 0.43672\tvalid_1's binary_logloss: 0.44148\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's binary_logloss: 0.412502\tvalid_1's binary_logloss: 0.425692\n",
      "[3]\ttraining's binary_logloss: 0.391769\tvalid_1's binary_logloss: 0.409989\n",
      "[4]\ttraining's binary_logloss: 0.373577\tvalid_1's binary_logloss: 0.393872\n",
      "[5]\ttraining's binary_logloss: 0.356068\tvalid_1's binary_logloss: 0.380561\n",
      "[6]\ttraining's binary_logloss: 0.343455\tvalid_1's binary_logloss: 0.374834\n",
      "[7]\ttraining's binary_logloss: 0.328676\tvalid_1's binary_logloss: 0.363502\n",
      "[8]\ttraining's binary_logloss: 0.315712\tvalid_1's binary_logloss: 0.354828\n",
      "[9]\ttraining's binary_logloss: 0.303533\tvalid_1's binary_logloss: 0.347242\n",
      "[10]\ttraining's binary_logloss: 0.292548\tvalid_1's binary_logloss: 0.33537\n",
      "[11]\ttraining's binary_logloss: 0.282278\tvalid_1's binary_logloss: 0.328692\n",
      "[12]\ttraining's binary_logloss: 0.273901\tvalid_1's binary_logloss: 0.32295\n",
      "[13]\ttraining's binary_logloss: 0.264603\tvalid_1's binary_logloss: 0.314037\n",
      "[14]\ttraining's binary_logloss: 0.256372\tvalid_1's binary_logloss: 0.307476\n",
      "[15]\ttraining's binary_logloss: 0.247624\tvalid_1's binary_logloss: 0.301101\n",
      "[16]\ttraining's binary_logloss: 0.240277\tvalid_1's binary_logloss: 0.295566\n",
      "[17]\ttraining's binary_logloss: 0.233384\tvalid_1's binary_logloss: 0.292087\n",
      "[18]\ttraining's binary_logloss: 0.226142\tvalid_1's binary_logloss: 0.289734\n",
      "[19]\ttraining's binary_logloss: 0.219905\tvalid_1's binary_logloss: 0.286691\n",
      "[20]\ttraining's binary_logloss: 0.213239\tvalid_1's binary_logloss: 0.282234\n",
      "[21]\ttraining's binary_logloss: 0.206653\tvalid_1's binary_logloss: 0.276464\n",
      "[22]\ttraining's binary_logloss: 0.200538\tvalid_1's binary_logloss: 0.273876\n",
      "[23]\ttraining's binary_logloss: 0.195154\tvalid_1's binary_logloss: 0.272514\n",
      "[24]\ttraining's binary_logloss: 0.189476\tvalid_1's binary_logloss: 0.268586\n",
      "[25]\ttraining's binary_logloss: 0.185183\tvalid_1's binary_logloss: 0.264808\n",
      "[26]\ttraining's binary_logloss: 0.180449\tvalid_1's binary_logloss: 0.261061\n",
      "[27]\ttraining's binary_logloss: 0.175421\tvalid_1's binary_logloss: 0.258746\n",
      "[28]\ttraining's binary_logloss: 0.170987\tvalid_1's binary_logloss: 0.256723\n",
      "[29]\ttraining's binary_logloss: 0.166519\tvalid_1's binary_logloss: 0.253619\n",
      "[30]\ttraining's binary_logloss: 0.161942\tvalid_1's binary_logloss: 0.250736\n",
      "[31]\ttraining's binary_logloss: 0.157186\tvalid_1's binary_logloss: 0.248883\n",
      "[32]\ttraining's binary_logloss: 0.15364\tvalid_1's binary_logloss: 0.24505\n",
      "[33]\ttraining's binary_logloss: 0.149599\tvalid_1's binary_logloss: 0.242855\n",
      "[34]\ttraining's binary_logloss: 0.145499\tvalid_1's binary_logloss: 0.241861\n",
      "[35]\ttraining's binary_logloss: 0.142421\tvalid_1's binary_logloss: 0.240458\n",
      "[36]\ttraining's binary_logloss: 0.138842\tvalid_1's binary_logloss: 0.238842\n",
      "[37]\ttraining's binary_logloss: 0.135626\tvalid_1's binary_logloss: 0.236019\n",
      "[38]\ttraining's binary_logloss: 0.132706\tvalid_1's binary_logloss: 0.234081\n",
      "[39]\ttraining's binary_logloss: 0.129553\tvalid_1's binary_logloss: 0.232728\n",
      "[40]\ttraining's binary_logloss: 0.125853\tvalid_1's binary_logloss: 0.231634\n",
      "[41]\ttraining's binary_logloss: 0.123057\tvalid_1's binary_logloss: 0.230868\n",
      "[42]\ttraining's binary_logloss: 0.120286\tvalid_1's binary_logloss: 0.228869\n",
      "[43]\ttraining's binary_logloss: 0.117566\tvalid_1's binary_logloss: 0.227321\n",
      "[44]\ttraining's binary_logloss: 0.115111\tvalid_1's binary_logloss: 0.226862\n",
      "[45]\ttraining's binary_logloss: 0.113402\tvalid_1's binary_logloss: 0.225978\n",
      "[46]\ttraining's binary_logloss: 0.110969\tvalid_1's binary_logloss: 0.226854\n",
      "[47]\ttraining's binary_logloss: 0.108878\tvalid_1's binary_logloss: 0.224501\n",
      "[48]\ttraining's binary_logloss: 0.106209\tvalid_1's binary_logloss: 0.223906\n",
      "[49]\ttraining's binary_logloss: 0.104069\tvalid_1's binary_logloss: 0.225839\n",
      "[50]\ttraining's binary_logloss: 0.101975\tvalid_1's binary_logloss: 0.226774\n",
      "[51]\ttraining's binary_logloss: 0.0997312\tvalid_1's binary_logloss: 0.226637\n",
      "[52]\ttraining's binary_logloss: 0.0981176\tvalid_1's binary_logloss: 0.226605\n",
      "[53]\ttraining's binary_logloss: 0.0957357\tvalid_1's binary_logloss: 0.226646\n",
      "[54]\ttraining's binary_logloss: 0.0935831\tvalid_1's binary_logloss: 0.224933\n",
      "[55]\ttraining's binary_logloss: 0.0915968\tvalid_1's binary_logloss: 0.224997\n",
      "[56]\ttraining's binary_logloss: 0.0896337\tvalid_1's binary_logloss: 0.223678\n",
      "[57]\ttraining's binary_logloss: 0.0879613\tvalid_1's binary_logloss: 0.220649\n",
      "[58]\ttraining's binary_logloss: 0.085963\tvalid_1's binary_logloss: 0.22089\n",
      "[59]\ttraining's binary_logloss: 0.0839762\tvalid_1's binary_logloss: 0.219856\n",
      "[60]\ttraining's binary_logloss: 0.0829583\tvalid_1's binary_logloss: 0.219054\n",
      "[61]\ttraining's binary_logloss: 0.0809952\tvalid_1's binary_logloss: 0.220314\n",
      "[62]\ttraining's binary_logloss: 0.0795351\tvalid_1's binary_logloss: 0.219844\n",
      "[63]\ttraining's binary_logloss: 0.0778128\tvalid_1's binary_logloss: 0.221039\n",
      "[64]\ttraining's binary_logloss: 0.0762896\tvalid_1's binary_logloss: 0.219877\n",
      "[65]\ttraining's binary_logloss: 0.0747395\tvalid_1's binary_logloss: 0.220385\n",
      "[66]\ttraining's binary_logloss: 0.0732245\tvalid_1's binary_logloss: 0.221835\n",
      "[67]\ttraining's binary_logloss: 0.0719563\tvalid_1's binary_logloss: 0.222746\n",
      "[68]\ttraining's binary_logloss: 0.0707164\tvalid_1's binary_logloss: 0.221052\n",
      "[69]\ttraining's binary_logloss: 0.0692543\tvalid_1's binary_logloss: 0.221204\n",
      "[70]\ttraining's binary_logloss: 0.0682842\tvalid_1's binary_logloss: 0.221676\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's binary_logloss: 0.0829583\tvalid_1's binary_logloss: 0.219054\n",
      "Optimal parameter values = {'subsample': 0.5, 'reg_lambda': 0, 'reg_alpha': 0, 'num_leaves': 40, 'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.05, 'colsample_bytree': 0.75}\n",
      "Optimal cross validation log loss =  0.17993056364823096\n",
      "Time taken =  0  minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "param_grid = {'max_depth': [4, 6, 8],\n",
    "              'num_leaves': [20, 31, 40],\n",
    "              'learning_rate': [0.01, 0.05, 0.1],\n",
    "               'reg_lambda':[0, 10, 100],\n",
    "                'n_estimators':[100, 500, 1000],\n",
    "                'reg_alpha': [0, 10, 100],\n",
    "                'subsample': [0.5, 0.75, 1.0],\n",
    "                'colsample_bytree': [0.5, 0.75, 1.0]}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "optimal_params = RandomizedSearchCV(estimator=LGBMClassifier(random_state=1),                                                       \n",
    "                             param_distributions = param_grid, n_iter = 200,\n",
    "                             verbose = 1,\n",
    "                             n_jobs=-1,\n",
    "                             cv = cv, scoring = 'neg_log_loss')\n",
    "optimal_params.fit(X_train, y_train, early_stopping_rounds = 10, eval_metric='logloss', eval_set=[(X_train, y_train), (X_val, y_val)])\n",
    "print(\"Optimal parameter values =\", optimal_params.best_params_)\n",
    "print(\"Optimal cross validation log loss = \", -optimal_params.best_score_)\n",
    "print(\"Time taken = \", round((time.time()-start_time)/60), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "00859d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Best Parameters:  {'bootstrap': False, 'max_depth': 18, 'max_features': 11, 'n_estimators': 500}\n",
      "Best Score:  -0.2271324969611638\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': [500],\n",
    "          'max_features': list(range(1,18,2)),\n",
    "          'max_depth': [12,15,18],\n",
    "          'bootstrap': [True, False]}\n",
    "\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "rf_regressor_grid = GridSearchCV(RandomForestClassifier(random_state=1, n_jobs=-1), \n",
    "                                      param_grid =params, cv=cv, n_jobs=-1, verbose=1, scoring='neg_log_loss')\n",
    "rf_regressor_grid.fit(X_train, y_train)\n",
    "print('Best Parameters: ', rf_regressor_grid.best_params_)\n",
    "print('Best Score: ', -rf_regressor_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b44828",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': [400],\n",
    "    'max_samples': [0.5, 0.75, 1.0],\n",
    "    'max_features': [0.5, 0.75, 1.0],\n",
    "    'bootstrap': [True, False],\n",
    "    'bootstrap_features': [True, False]\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "bagging_regressor_grid = GridSearchCV(\n",
    "    BaggingClassifier(),\n",
    "    param_grid = params,\n",
    "    cv = cv,\n",
    "    scoring = 'neg_log_loss',\n",
    "    n_jobs = -1,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "bagging_regressor_grid.fit(X_train, y_train)\n",
    "print('Best Parameters: ', bagging_regressor_grid.best_params_)\n",
    "print('Best Score: ', -bagging_regressor_grid.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
