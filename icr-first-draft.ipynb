{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nimport numpy as np\nimport pandas as pd\nimport warnings\ndef ignore_warn(*args,**kwargs):\n    pass\nwarnings.warn = ignore_warn\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport optuna\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score, KFold, train_test_split\nfrom sklearn.metrics import f1_score\nimport xgboost as xgboost\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, HistGradientBoostingClassifier, BaggingClassifier, StackingClassifier, VotingClassifier, GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.experimental import enable_hist_gradient_boosting  \nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.impute import KNNImputer","metadata":{"execution":{"iopub.status.busy":"2023-07-28T07:38:48.094547Z","iopub.execute_input":"2023-07-28T07:38:48.095271Z","iopub.status.idle":"2023-07-28T07:38:52.589252Z","shell.execute_reply.started":"2023-07-28T07:38:48.095203Z","shell.execute_reply":"2023-07-28T07:38:52.587733Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\ntest = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\nfinal = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-28T07:38:52.591637Z","iopub.execute_input":"2023-07-28T07:38:52.592135Z","iopub.status.idle":"2023-07-28T07:38:52.653765Z","shell.execute_reply.started":"2023-07-28T07:38:52.592091Z","shell.execute_reply":"2023-07-28T07:38:52.652577Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\ntrain.loc[:, 'EJ'] = encoder.fit_transform(train.loc[:, 'EJ'])\ntest.loc[:, 'EJ'] = encoder.fit_transform(test.loc[:, 'EJ'])","metadata":{"execution":{"iopub.status.busy":"2023-07-28T07:38:52.655378Z","iopub.execute_input":"2023-07-28T07:38:52.655844Z","iopub.status.idle":"2023-07-28T07:38:52.668097Z","shell.execute_reply.started":"2023-07-28T07:38:52.655777Z","shell.execute_reply":"2023-07-28T07:38:52.667107Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"column_names = train.columns\nimputer = KNNImputer(n_neighbors = 10)\ntrain_no_id = imputer.fit_transform(train.drop(['Id'], axis = 1))\ntrain_no_id = pd.DataFrame(train_no_id)\ntrain = pd.concat([train['Id'], train_no_id], axis = 1)\ntrain.columns = column_names","metadata":{"execution":{"iopub.status.busy":"2023-07-28T07:38:52.670670Z","iopub.execute_input":"2023-07-28T07:38:52.671847Z","iopub.status.idle":"2023-07-28T07:38:52.736035Z","shell.execute_reply.started":"2023-07-28T07:38:52.671772Z","shell.execute_reply":"2023-07-28T07:38:52.734109Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#train.isna().sum().sort_values(ascending = False)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T07:38:52.738853Z","iopub.execute_input":"2023-07-28T07:38:52.739508Z","iopub.status.idle":"2023-07-28T07:38:52.746329Z","shell.execute_reply.started":"2023-07-28T07:38:52.739452Z","shell.execute_reply":"2023-07-28T07:38:52.744848Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\nseed = 617\nzero, one = np.bincount(train.loc[:, 'Class'])\none_df = train.iloc[(train.loc[:, 'Class'] == 1).tolist(), :] \nzero_df = train.iloc[(train.loc[:, 'Class'] == 0).tolist(), :]\nzero_df = zero_df.sample(n=one, random_state=seed)\noversampled_df = pd.concat([train.iloc[(train.loc[:, 'Class'] == 0).tolist(), :], one_df, one_df, one_df, one_df])\noversampled_df = oversampled_df.sample(frac=1, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T07:38:52.748648Z","iopub.execute_input":"2023-07-28T07:38:52.749692Z","iopub.status.idle":"2023-07-28T07:38:52.776556Z","shell.execute_reply.started":"2023-07-28T07:38:52.749608Z","shell.execute_reply":"2023-07-28T07:38:52.775235Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\ndef balanced_log_loss(y_true, y_pred):\n    N_0 = np.sum(1 - y_true)\n    N_1 = np.sum(y_true)\n    w_0 = 1 / N_0\n    w_1 = 1 / N_1\n    p_1 = np.clip(y_pred[:, 1], 1e-15, 1-1e-15)\n    p_0 = 1 - p_1\n    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\n    log_loss_1 = -np.sum(y_true * np.log(p_1))\n    balanced_log_loss = (w_0 * log_loss_0 + w_1 * log_loss_1) / 2\n    return balanced_log_loss","metadata":{"execution":{"iopub.status.busy":"2023-07-28T07:38:52.779498Z","iopub.execute_input":"2023-07-28T07:38:52.780507Z","iopub.status.idle":"2023-07-28T07:38:52.793133Z","shell.execute_reply.started":"2023-07-28T07:38:52.780448Z","shell.execute_reply":"2023-07-28T07:38:52.791414Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\nn_folds = 10\ndef CV(model, data, loss_function):\n    skf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n    kfold = skf.split(data.iloc[:, 1:-1], data.iloc[:, -1])\n    losses = []\n    for (train_id, val_id) in kfold:\n        x_train = data.iloc[train_id, 1:-1]\n        y_train = data.iloc[train_id, -1]\n        x_val = data.iloc[val_id, 1:-1]\n        y_val = data.iloc[val_id, -1]\n        model.fit(x_train, y_train)\n        pred_val = model.predict_proba(x_val)\n        loss = loss_function(y_val, pred_val)\n        losses.append(loss)\n    return np.sum(losses) / n_folds","metadata":{"execution":{"iopub.status.busy":"2023-07-28T07:38:52.795552Z","iopub.execute_input":"2023-07-28T07:38:52.796569Z","iopub.status.idle":"2023-07-28T07:38:52.824673Z","shell.execute_reply.started":"2023-07-28T07:38:52.796508Z","shell.execute_reply":"2023-07-28T07:38:52.822992Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_train = oversampled_df.drop(columns=['Class', 'Id'])\ny_train = oversampled_df['Class']","metadata":{"execution":{"iopub.status.busy":"2023-07-28T07:38:52.827207Z","iopub.execute_input":"2023-07-28T07:38:52.829862Z","iopub.status.idle":"2023-07-28T07:38:52.837171Z","shell.execute_reply.started":"2023-07-28T07:38:52.829784Z","shell.execute_reply":"2023-07-28T07:38:52.836235Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T07:38:52.842466Z","iopub.execute_input":"2023-07-28T07:38:52.842918Z","iopub.status.idle":"2023-07-28T07:38:52.851423Z","shell.execute_reply.started":"2023-07-28T07:38:52.842879Z","shell.execute_reply":"2023-07-28T07:38:52.849983Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def xgb(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),\n    }\n    model = xgb.XGBClassifier(**param, random_state = seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-28T07:38:52.854055Z","iopub.execute_input":"2023-07-28T07:38:52.854518Z","iopub.status.idle":"2023-07-28T07:38:52.866339Z","shell.execute_reply.started":"2023-07-28T07:38:52.854483Z","shell.execute_reply":"2023-07-28T07:38:52.865193Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def lgbm(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'num_leaves' : trial.suggest_int('num_leaves', 10, 50),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 50),\n    }\n    model = lgb.LGBMClassifier(**param, random_state = seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-28T07:38:52.868583Z","iopub.execute_input":"2023-07-28T07:38:52.869632Z","iopub.status.idle":"2023-07-28T07:38:52.889113Z","shell.execute_reply.started":"2023-07-28T07:38:52.869586Z","shell.execute_reply":"2023-07-28T07:38:52.887971Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def catboost(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 150, 10),\n        'reg_lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'colsample_bylevel': trial.suggest_categorical('colsample_bylevel', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'one_hot_max_size': trial.suggest_int('one_hot_max_size', 2, 10),\n    }\n    model = CatBoostClassifier(**param, random_seed=seed, verbose=False)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-28T07:38:52.891029Z","iopub.execute_input":"2023-07-28T07:38:52.892154Z","iopub.status.idle":"2023-07-28T07:38:52.903742Z","shell.execute_reply.started":"2023-07-28T07:38:52.892117Z","shell.execute_reply":"2023-07-28T07:38:52.902553Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def hgbc(trial):\n    param = {\n        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 15),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'max_iter': trial.suggest_int('max_iter', 50, 200, 10),\n    }\n    model = HistGradientBoostingClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-28T07:38:52.905424Z","iopub.execute_input":"2023-07-28T07:38:52.905814Z","iopub.status.idle":"2023-07-28T07:38:52.924011Z","shell.execute_reply.started":"2023-07-28T07:38:52.905762Z","shell.execute_reply":"2023-07-28T07:38:52.923046Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def bagged_dt(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 400, 600, 20),\n        'max_samples': trial.suggest_float('max_samples', 1e-2, 1.0),\n        'max_features': trial.suggest_float('max_features', 1e-2, 1.0),\n        'bootstrap': trial.suggest_categorical('bootstrap', [False, True]),\n        'bootstrap_features': trial.suggest_categorical('bootstrap_features', [False, True]),\n    }\n    model = BaggingClassifier(**param, base_estimator=DecisionTreeClassifier(), random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-28T07:38:52.925286Z","iopub.execute_input":"2023-07-28T07:38:52.925858Z","iopub.status.idle":"2023-07-28T07:38:52.939646Z","shell.execute_reply.started":"2023-07-28T07:38:52.925811Z","shell.execute_reply":"2023-07-28T07:38:52.938254Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def rf(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 300, 500, 20),\n        'max_depth': trial.suggest_int('max_depth', 5, 25),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'max_features': trial.suggest_int('max_features', 1, 56),\n        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n    }\n    model = RandomForestClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-28T07:38:52.941177Z","iopub.execute_input":"2023-07-28T07:38:52.941559Z","iopub.status.idle":"2023-07-28T07:38:52.955845Z","shell.execute_reply.started":"2023-07-28T07:38:52.941528Z","shell.execute_reply":"2023-07-28T07:38:52.954423Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def adaboost(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 400, 500, 20),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.0001, 1),\n        'base_estimator': DecisionTreeClassifier(max_depth=trial.suggest_int('max_depth', 1, 20)),\n    }\n    model = AdaBoostClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-28T07:38:52.957437Z","iopub.execute_input":"2023-07-28T07:38:52.957859Z","iopub.status.idle":"2023-07-28T07:38:52.974499Z","shell.execute_reply.started":"2023-07-28T07:38:52.957809Z","shell.execute_reply":"2023-07-28T07:38:52.973475Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def gradient(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 10, 500, 20),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.0001, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'subsample': trial.suggest_float('subsample', 0.3, 1.0),\n    }\n    model = GradientBoostingClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-28T07:38:52.976523Z","iopub.execute_input":"2023-07-28T07:38:52.977454Z","iopub.status.idle":"2023-07-28T07:38:52.987991Z","shell.execute_reply.started":"2023-07-28T07:38:52.977405Z","shell.execute_reply":"2023-07-28T07:38:52.987017Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n\nstudy1 = optuna.create_study(direction='minimize', study_name=\"AdaBoost\")\nn_trials = 75\nstudy1.optimize(adaboost, n_trials=n_trials)\nprint('Best trial:', study1.best_trial.params)\nprint('Best values:', study1.best_value)\n\nend = time.time()\nprint('It has taken {:.5f} seconds to search for the best Hyperparameter'.format(end-start))","metadata":{"execution":{"iopub.status.busy":"2023-07-28T07:38:52.989597Z","iopub.execute_input":"2023-07-28T07:38:52.990324Z","iopub.status.idle":"2023-07-28T09:01:41.766902Z","shell.execute_reply.started":"2023-07-28T07:38:52.990285Z","shell.execute_reply":"2023-07-28T09:01:41.765585Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"[I 2023-07-28 07:38:53,000] A new study created in memory with name: AdaBoost\n[I 2023-07-28 07:40:29,924] Trial 0 finished with value: 0.12412766851267856 and parameters: {'n_estimators': 440, 'learning_rate': 0.0005134400850710341, 'max_depth': 6}. Best is trial 0 with value: 0.12412766851267856.\n[I 2023-07-28 07:41:41,252] Trial 1 finished with value: 0.04494097738884217 and parameters: {'n_estimators': 400, 'learning_rate': 0.0049796026705010805, 'max_depth': 4}. Best is trial 1 with value: 0.04494097738884217.\n[I 2023-07-28 07:43:21,461] Trial 2 finished with value: 0.06996180056466039 and parameters: {'n_estimators': 440, 'learning_rate': 0.0008471061689195624, 'max_depth': 6}. Best is trial 1 with value: 0.04494097738884217.\n[I 2023-07-28 07:44:49,829] Trial 3 finished with value: 0.1604755731481959 and parameters: {'n_estimators': 500, 'learning_rate': 0.00047453873055817764, 'max_depth': 4}. Best is trial 1 with value: 0.04494097738884217.\n[I 2023-07-28 07:44:50,272] Trial 4 finished with value: 1.2948358971589904 and parameters: {'n_estimators': 500, 'learning_rate': 0.0077511351741611665, 'max_depth': 10}. Best is trial 1 with value: 0.04494097738884217.\n[I 2023-07-28 07:44:50,611] Trial 5 finished with value: 1.3285629599538031 and parameters: {'n_estimators': 460, 'learning_rate': 0.00033310323431110883, 'max_depth': 18}. Best is trial 1 with value: 0.04494097738884217.\n[I 2023-07-28 07:44:50,948] Trial 6 finished with value: 1.3285629599538031 and parameters: {'n_estimators': 500, 'learning_rate': 0.004354824639758327, 'max_depth': 17}. Best is trial 1 with value: 0.04494097738884217.\n[I 2023-07-28 07:44:51,281] Trial 7 finished with value: 1.3285629599538031 and parameters: {'n_estimators': 420, 'learning_rate': 0.0009128460200073399, 'max_depth': 18}. Best is trial 1 with value: 0.04494097738884217.\n[I 2023-07-28 07:44:51,608] Trial 8 finished with value: 1.3285629599538031 and parameters: {'n_estimators': 480, 'learning_rate': 0.29539924912857324, 'max_depth': 15}. Best is trial 1 with value: 0.04494097738884217.\n[I 2023-07-28 07:44:51,936] Trial 9 finished with value: 1.3285629599538031 and parameters: {'n_estimators': 400, 'learning_rate': 0.01488682237368582, 'max_depth': 20}. Best is trial 1 with value: 0.04494097738884217.\n[I 2023-07-28 07:45:20,242] Trial 10 finished with value: 0.6280283565807852 and parameters: {'n_estimators': 400, 'learning_rate': 0.06378122963149234, 'max_depth': 1}. Best is trial 1 with value: 0.04494097738884217.\n[I 2023-07-28 07:46:14,469] Trial 11 finished with value: 0.8950158803422157 and parameters: {'n_estimators': 440, 'learning_rate': 0.0018506970772031043, 'max_depth': 8}. Best is trial 1 with value: 0.04494097738884217.\n[I 2023-07-28 07:46:43,626] Trial 12 finished with value: 0.5476993458976886 and parameters: {'n_estimators': 420, 'learning_rate': 0.00011337756009344638, 'max_depth': 1}. Best is trial 1 with value: 0.04494097738884217.\n[I 2023-07-28 07:48:10,824] Trial 13 finished with value: 0.03786755766251719 and parameters: {'n_estimators': 420, 'learning_rate': 0.0022263554731697228, 'max_depth': 5}. Best is trial 13 with value: 0.03786755766251719.\n[I 2023-07-28 07:48:11,180] Trial 14 finished with value: 1.3285629599538031 and parameters: {'n_estimators': 420, 'learning_rate': 0.017566619630185378, 'max_depth': 12}. Best is trial 13 with value: 0.03786755766251719.\n[I 2023-07-28 07:49:22,692] Trial 15 finished with value: 0.07683863344841715 and parameters: {'n_estimators': 400, 'learning_rate': 0.00235798496208037, 'max_depth': 4}. Best is trial 13 with value: 0.03786755766251719.\n[I 2023-07-28 07:50:38,432] Trial 16 finished with value: 0.036362531444270936 and parameters: {'n_estimators': 420, 'learning_rate': 0.03074812290759127, 'max_depth': 4}. Best is trial 16 with value: 0.036362531444270936.\n[I 2023-07-28 07:50:38,922] Trial 17 finished with value: 1.3161600726792253 and parameters: {'n_estimators': 460, 'learning_rate': 0.04666734202259506, 'max_depth': 11}. Best is trial 16 with value: 0.036362531444270936.\n[I 2023-07-28 07:52:16,384] Trial 18 finished with value: 0.4187361008811122 and parameters: {'n_estimators': 420, 'learning_rate': 0.3230701124534552, 'max_depth': 8}. Best is trial 16 with value: 0.036362531444270936.\n[I 2023-07-28 07:53:17,226] Trial 19 finished with value: 0.2182937449090286 and parameters: {'n_estimators': 420, 'learning_rate': 0.03308504005584369, 'max_depth': 3}. Best is trial 16 with value: 0.036362531444270936.\n[I 2023-07-28 07:55:07,301] Trial 20 finished with value: 0.4450243783640551 and parameters: {'n_estimators': 460, 'learning_rate': 0.11694480549845948, 'max_depth': 7}. Best is trial 16 with value: 0.036362531444270936.\n[I 2023-07-28 07:56:05,368] Trial 21 finished with value: 0.22423572363591102 and parameters: {'n_estimators': 400, 'learning_rate': 0.006596235226993714, 'max_depth': 3}. Best is trial 16 with value: 0.036362531444270936.\n[I 2023-07-28 07:57:28,981] Trial 22 finished with value: 0.04238321622613565 and parameters: {'n_estimators': 400, 'learning_rate': 0.0036482636595469545, 'max_depth': 5}. Best is trial 16 with value: 0.036362531444270936.\n[I 2023-07-28 07:57:29,643] Trial 23 finished with value: 1.1974764942525722 and parameters: {'n_estimators': 420, 'learning_rate': 0.016126151021095114, 'max_depth': 9}. Best is trial 16 with value: 0.036362531444270936.\n[I 2023-07-28 07:57:30,011] Trial 24 finished with value: 1.3285629599538031 and parameters: {'n_estimators': 440, 'learning_rate': 0.002650104795869434, 'max_depth': 13}. Best is trial 16 with value: 0.036362531444270936.\n[I 2023-07-28 07:59:05,447] Trial 25 finished with value: 0.02822394711845489 and parameters: {'n_estimators': 400, 'learning_rate': 0.9337798838926828, 'max_depth': 6}. Best is trial 25 with value: 0.02822394711845489.\n[I 2023-07-28 07:59:51,664] Trial 26 finished with value: 0.471619903259567 and parameters: {'n_estimators': 420, 'learning_rate': 0.6830300080432902, 'max_depth': 2}. Best is trial 25 with value: 0.02822394711845489.\n[I 2023-07-28 08:01:37,217] Trial 27 finished with value: 0.024176696336498844 and parameters: {'n_estimators': 440, 'learning_rate': 0.9711600400178155, 'max_depth': 6}. Best is trial 27 with value: 0.024176696336498844.\n[I 2023-07-28 08:03:20,875] Trial 28 finished with value: 0.3334529019744204 and parameters: {'n_estimators': 440, 'learning_rate': 0.7688137386237478, 'max_depth': 7}. Best is trial 27 with value: 0.024176696336498844.\n[I 2023-07-28 08:05:05,662] Trial 29 finished with value: 0.025512701486048124 and parameters: {'n_estimators': 440, 'learning_rate': 0.8731163398024668, 'max_depth': 6}. Best is trial 27 with value: 0.024176696336498844.\n[I 2023-07-28 08:06:59,464] Trial 30 finished with value: 0.026456086186421923 and parameters: {'n_estimators': 480, 'learning_rate': 0.805003341409199, 'max_depth': 6}. Best is trial 27 with value: 0.024176696336498844.\n[I 2023-07-28 08:08:53,670] Trial 31 finished with value: 0.040186314280604776 and parameters: {'n_estimators': 480, 'learning_rate': 0.8565380209884986, 'max_depth': 6}. Best is trial 27 with value: 0.024176696336498844.\n[I 2023-07-28 08:10:31,153] Trial 32 finished with value: 0.5224980133302116 and parameters: {'n_estimators': 480, 'learning_rate': 0.3997711726844436, 'max_depth': 8}. Best is trial 27 with value: 0.024176696336498844.\n[I 2023-07-28 08:10:31,560] Trial 33 finished with value: 1.294490755223317 and parameters: {'n_estimators': 460, 'learning_rate': 0.20060781370831068, 'max_depth': 10}. Best is trial 27 with value: 0.024176696336498844.\n[I 2023-07-28 08:12:16,107] Trial 34 finished with value: 0.021288974571697428 and parameters: {'n_estimators': 440, 'learning_rate': 0.9645225573783289, 'max_depth': 6}. Best is trial 34 with value: 0.021288974571697428.\n[I 2023-07-28 08:14:02,598] Trial 35 finished with value: 0.4384766067742468 and parameters: {'n_estimators': 440, 'learning_rate': 0.44857319953222374, 'max_depth': 7}. Best is trial 34 with value: 0.021288974571697428.\n[I 2023-07-28 08:15:36,126] Trial 36 finished with value: 0.1271485712436961 and parameters: {'n_estimators': 440, 'learning_rate': 0.1922408248165587, 'max_depth': 5}. Best is trial 34 with value: 0.021288974571697428.\n[I 2023-07-28 08:16:19,367] Trial 37 finished with value: 1.2138219310919178 and parameters: {'n_estimators': 460, 'learning_rate': 0.5511588876096357, 'max_depth': 9}. Best is trial 34 with value: 0.021288974571697428.\n[I 2023-07-28 08:17:23,579] Trial 38 finished with value: 0.11429670002082978 and parameters: {'n_estimators': 440, 'learning_rate': 0.916918380115474, 'max_depth': 3}. Best is trial 34 with value: 0.021288974571697428.\n[I 2023-07-28 08:17:54,998] Trial 39 finished with value: 1.234360629079068 and parameters: {'n_estimators': 480, 'learning_rate': 0.490900865762785, 'max_depth': 9}. Best is trial 34 with value: 0.021288974571697428.\n[I 2023-07-28 08:19:45,681] Trial 40 finished with value: 0.14577748638170723 and parameters: {'n_estimators': 460, 'learning_rate': 0.2686041304464048, 'max_depth': 6}. Best is trial 34 with value: 0.021288974571697428.\n[I 2023-07-28 08:21:44,873] Trial 41 finished with value: 0.013437856824307015 and parameters: {'n_estimators': 500, 'learning_rate': 0.8430350533086901, 'max_depth': 6}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:23:30,273] Trial 42 finished with value: 0.04069806903289524 and parameters: {'n_estimators': 500, 'learning_rate': 0.553907399289232, 'max_depth': 5}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:25:26,445] Trial 43 finished with value: 0.31987270781553134 and parameters: {'n_estimators': 500, 'learning_rate': 0.949200645415397, 'max_depth': 7}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:26:53,345] Trial 44 finished with value: 0.022367564644286988 and parameters: {'n_estimators': 480, 'learning_rate': 0.514157925624502, 'max_depth': 4}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:27:48,597] Trial 45 finished with value: 0.477454033888112 and parameters: {'n_estimators': 500, 'learning_rate': 0.4153911573101959, 'max_depth': 2}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:29:08,366] Trial 46 finished with value: 0.06474510603917694 and parameters: {'n_estimators': 440, 'learning_rate': 0.15298075374842265, 'max_depth': 4}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:30:00,987] Trial 47 finished with value: 0.4780355345147938 and parameters: {'n_estimators': 480, 'learning_rate': 0.2921829520467511, 'max_depth': 2}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:31:33,756] Trial 48 finished with value: 0.04408863643055647 and parameters: {'n_estimators': 440, 'learning_rate': 0.5396417030168006, 'max_depth': 5}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:31:34,121] Trial 49 finished with value: 1.3285629599538031 and parameters: {'n_estimators': 500, 'learning_rate': 0.09198606006226215, 'max_depth': 14}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:31:52,031] Trial 50 finished with value: 1.2531235959379141 and parameters: {'n_estimators': 460, 'learning_rate': 0.2665199173534699, 'max_depth': 11}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:33:46,799] Trial 51 finished with value: 0.10536711715795355 and parameters: {'n_estimators': 480, 'learning_rate': 0.653450217235614, 'max_depth': 6}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:35:13,683] Trial 52 finished with value: 0.03358686248805483 and parameters: {'n_estimators': 480, 'learning_rate': 0.37915383153041143, 'max_depth': 4}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:36:53,224] Trial 53 finished with value: 0.4930847777106605 and parameters: {'n_estimators': 460, 'learning_rate': 0.6033136971515555, 'max_depth': 8}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:38:51,836] Trial 54 finished with value: 0.3208883822111088 and parameters: {'n_estimators': 500, 'learning_rate': 0.9365080036022289, 'max_depth': 7}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:40:25,410] Trial 55 finished with value: 0.029714392237280653 and parameters: {'n_estimators': 440, 'learning_rate': 0.6645185606764116, 'max_depth': 5}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:41:35,727] Trial 56 finished with value: 0.1450339429301525 and parameters: {'n_estimators': 480, 'learning_rate': 0.35654971682651776, 'max_depth': 3}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:42:56,143] Trial 57 finished with value: 0.016011046546376348 and parameters: {'n_estimators': 440, 'learning_rate': 0.9739048509430202, 'max_depth': 4}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:44:01,392] Trial 58 finished with value: 0.1410803836536817 and parameters: {'n_estimators': 440, 'learning_rate': 0.4361869572422263, 'max_depth': 3}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:44:32,831] Trial 59 finished with value: 0.6485450167889024 and parameters: {'n_estimators': 440, 'learning_rate': 0.25505856381920305, 'max_depth': 1}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:45:48,666] Trial 60 finished with value: 0.014445618823119625 and parameters: {'n_estimators': 420, 'learning_rate': 0.993234074840148, 'max_depth': 4}. Best is trial 41 with value: 0.013437856824307015.\n[I 2023-07-28 08:47:04,861] Trial 61 finished with value: 0.012167076802005669 and parameters: {'n_estimators': 420, 'learning_rate': 0.6794771047521856, 'max_depth': 4}. Best is trial 61 with value: 0.012167076802005669.\n[I 2023-07-28 08:48:20,824] Trial 62 finished with value: 0.02253807526046665 and parameters: {'n_estimators': 420, 'learning_rate': 0.6080662139158609, 'max_depth': 4}. Best is trial 61 with value: 0.012167076802005669.\n[I 2023-07-28 08:49:36,880] Trial 63 finished with value: 0.017502314599564965 and parameters: {'n_estimators': 420, 'learning_rate': 0.6052415178447684, 'max_depth': 4}. Best is trial 61 with value: 0.012167076802005669.\n[I 2023-07-28 08:50:22,889] Trial 64 finished with value: 0.47214113446266925 and parameters: {'n_estimators': 420, 'learning_rate': 0.34908227612308973, 'max_depth': 2}. Best is trial 61 with value: 0.012167076802005669.\n[I 2023-07-28 08:52:54,463] Trial 66 finished with value: 0.015059815395043735 and parameters: {'n_estimators': 420, 'learning_rate': 0.701189489556821, 'max_depth': 4}. Best is trial 61 with value: 0.012167076802005669.\n[I 2023-07-28 08:53:55,678] Trial 67 finished with value: 0.12554643110570807 and parameters: {'n_estimators': 420, 'learning_rate': 0.6694111405968295, 'max_depth': 3}. Best is trial 61 with value: 0.012167076802005669.\n[I 2023-07-28 08:54:41,865] Trial 68 finished with value: 0.48093543194001886 and parameters: {'n_estimators': 420, 'learning_rate': 0.22202700291562089, 'max_depth': 2}. Best is trial 61 with value: 0.012167076802005669.\n[I 2023-07-28 08:55:10,353] Trial 69 finished with value: 0.6489714322336572 and parameters: {'n_estimators': 400, 'learning_rate': 0.3364308909940041, 'max_depth': 1}. Best is trial 61 with value: 0.012167076802005669.\n[I 2023-07-28 08:56:26,519] Trial 70 finished with value: 0.07407476652421066 and parameters: {'n_estimators': 420, 'learning_rate': 0.1667153586170121, 'max_depth': 4}. Best is trial 61 with value: 0.012167076802005669.\n[I 2023-07-28 08:57:56,185] Trial 71 finished with value: 0.017207873448615095 and parameters: {'n_estimators': 420, 'learning_rate': 0.9934900775917953, 'max_depth': 5}. Best is trial 61 with value: 0.012167076802005669.\n[I 2023-07-28 08:59:25,684] Trial 72 finished with value: 0.02761496420421935 and parameters: {'n_estimators': 420, 'learning_rate': 0.7541060124376895, 'max_depth': 5}. Best is trial 61 with value: 0.012167076802005669.\n[I 2023-07-28 09:00:28,300] Trial 73 finished with value: 0.12666909559631306 and parameters: {'n_estimators': 420, 'learning_rate': 0.7129630955079626, 'max_depth': 3}. Best is trial 61 with value: 0.012167076802005669.\n[I 2023-07-28 09:01:41,760] Trial 74 finished with value: 0.0254991703356235 and parameters: {'n_estimators': 400, 'learning_rate': 0.48262924183862205, 'max_depth': 4}. Best is trial 61 with value: 0.012167076802005669.\n","output_type":"stream"},{"name":"stdout","text":"Best trial: {'n_estimators': 420, 'learning_rate': 0.6794771047521856, 'max_depth': 4}\nBest values: 0.012167076802005669\nIt has taken 4968.76250 seconds to search for the best Hyperparameter\n","output_type":"stream"}]},{"cell_type":"code","source":"xgb_model = xgboost.XGBClassifier(n_estimators=200, reg_lambda=0.15325900166549988, reg_alpha=0.0044700650580230235, \n                              colsample_bytree=0.3, subsample=1.0, learning_rate=0.09975673376458177, \n                              max_depth=11, min_child_weight=2, random_state=seed).fit(X_train, y_train)\nxgb = xgb_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:05:11.204627Z","iopub.execute_input":"2023-07-27T23:05:11.205513Z","iopub.status.idle":"2023-07-27T23:05:11.582329Z","shell.execute_reply.started":"2023-07-27T23:05:11.205479Z","shell.execute_reply":"2023-07-27T23:05:11.581374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm_model = lgb.LGBMClassifier(n_estimators=200, reg_alpha=0.0016725623110267532, reg_lambda=0.0038043774323061946, \n                                 colsample_bytree=0.3, subsample=0.4, learning_rate=0.09367295744238123, max_depth=11, \n                                 num_leaves=50, min_child_samples=26, random_state=seed).fit(X_train, y_train)\nlgbm = lgbm_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:05:11.583694Z","iopub.execute_input":"2023-07-27T23:05:11.584729Z","iopub.status.idle":"2023-07-27T23:05:12.799584Z","shell.execute_reply.started":"2023-07-27T23:05:11.584678Z","shell.execute_reply":"2023-07-27T23:05:12.798338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_model = CatBoostClassifier(n_estimators=70, reg_lambda=0.01606738047167, colsample_bylevel=0.3, \n                              subsample=0.7, learning_rate=0.0865881098465479, \n                              max_depth=9, one_hot_max_size=10, random_state=seed, verbose=False).fit(X_train, y_train)\ncat = cat_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:05:12.801018Z","iopub.execute_input":"2023-07-27T23:05:12.801424Z","iopub.status.idle":"2023-07-27T23:05:15.163991Z","shell.execute_reply.started":"2023-07-27T23:05:12.801393Z","shell.execute_reply":"2023-07-27T23:05:15.163055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hgbc_model = HistGradientBoostingClassifier(max_iter=170, max_depth=4, min_samples_leaf=9,\n                                         learning_rate=0.17193627413211837, random_state=seed).fit(X_train, y_train)\nhgbc = hgbc_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:05:15.165651Z","iopub.execute_input":"2023-07-27T23:05:15.166337Z","iopub.status.idle":"2023-07-27T23:05:15.765805Z","shell.execute_reply.started":"2023-07-27T23:05:15.166259Z","shell.execute_reply":"2023-07-27T23:05:15.764999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=500, max_samples=0.994711990802652,\n                           max_features=0.7844039008030275, bootstrap=False, bootstrap_features=True, random_state=seed).fit(X_train, y_train)\ndt = dt_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:05:15.767122Z","iopub.execute_input":"2023-07-27T23:05:15.767709Z","iopub.status.idle":"2023-07-27T23:05:27.428031Z","shell.execute_reply.started":"2023-07-27T23:05:15.767677Z","shell.execute_reply":"2023-07-27T23:05:27.426847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_model = RandomForestClassifier(n_estimators=420, max_depth=13, min_samples_split=3, \n                                  min_samples_leaf=1, max_features=9, bootstrap=False, random_state=seed).fit(X_train, y_train)\nrf = rf_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:05:27.429444Z","iopub.execute_input":"2023-07-27T23:05:27.429750Z","iopub.status.idle":"2023-07-27T23:05:29.893735Z","shell.execute_reply.started":"2023-07-27T23:05:27.429724Z","shell.execute_reply":"2023-07-27T23:05:29.892728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def catboost_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 150, 10),\n        'reg_lambda': trial.suggest_loguniform('lambda', 1e-3, 0.1),\n        'colsample_bylevel': trial.suggest_categorical('colsample_bylevel', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'one_hot_max_size': trial.suggest_int('one_hot_max_size', 2, 10),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=CatBoostClassifier(**param, random_state=seed, verbose=False)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:05:29.895181Z","iopub.execute_input":"2023-07-27T23:05:29.895656Z","iopub.status.idle":"2023-07-27T23:05:29.904745Z","shell.execute_reply.started":"2023-07-27T23:05:29.895618Z","shell.execute_reply":"2023-07-27T23:05:29.903390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def xgb_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 0.1),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 0.1),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=xgboost.XGBClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:05:29.906597Z","iopub.execute_input":"2023-07-27T23:05:29.907025Z","iopub.status.idle":"2023-07-27T23:05:29.923087Z","shell.execute_reply.started":"2023-07-27T23:05:29.906986Z","shell.execute_reply":"2023-07-27T23:05:29.922345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def hgbc_meta(trial):\n    param = {\n        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 15),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'max_iter': trial.suggest_int('max_iter', 50, 200, 10),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=HistGradientBoostingClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:05:29.929073Z","iopub.execute_input":"2023-07-27T23:05:29.929426Z","iopub.status.idle":"2023-07-27T23:05:29.938703Z","shell.execute_reply.started":"2023-07-27T23:05:29.929399Z","shell.execute_reply":"2023-07-27T23:05:29.937543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lgbm_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 0.1),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 0.1),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'num_leaves' : trial.suggest_int('num_leaves', 10, 50),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 50),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=lgb.LGBMClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:05:29.940438Z","iopub.execute_input":"2023-07-27T23:05:29.941249Z","iopub.status.idle":"2023-07-27T23:05:29.956364Z","shell.execute_reply.started":"2023-07-27T23:05:29.941205Z","shell.execute_reply":"2023-07-27T23:05:29.955587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacking_cat_model = CatBoostClassifier(n_estimators=150, reg_lambda=0.05055956136270572, colsample_bylevel=0.6, \n                                        subsample=0.5, learning_rate=0.08699165501504001, max_depth=7, \n                                        one_hot_max_size=8, random_state=seed, verbose=False).fit(X_train, y_train)\nstacking_cat = stacking_cat_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:05:29.957373Z","iopub.execute_input":"2023-07-27T23:05:29.958418Z","iopub.status.idle":"2023-07-27T23:05:32.368470Z","shell.execute_reply.started":"2023-07-27T23:05:29.958384Z","shell.execute_reply":"2023-07-27T23:05:32.367598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacking_xgb_model = xgboost.XGBClassifier(n_estimators=160, reg_lambda=0.030554982480056614, alpha=0.022993963306149747, \n                                           colsample_bytree=0.4, subsample=0.6, learning_rate=0.08378145372235492, \n                                           max_depth=17, min_child_weight=1, random_state=seed).fit(X_train, y_train)\nstacking_xgb = stacking_xgb_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:05:32.369517Z","iopub.execute_input":"2023-07-27T23:05:32.370037Z","iopub.status.idle":"2023-07-27T23:05:32.830046Z","shell.execute_reply.started":"2023-07-27T23:05:32.370005Z","shell.execute_reply":"2023-07-27T23:05:32.829231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacking_lgbm_model = lgb.LGBMClassifier(n_estimators=130, reg_alpha=0.017987440901161444, reg_lambda=0.0010110144342120994, \n                                colsample_bytree=0.8, subsample=0.5, learning_rate=0.08786840365732179, \n                                max_depth=5, num_leaves=10, min_child_samples=48, random_state=seed).fit(X_train, y_train)\nstacking_lgbm = stacking_lgbm_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:05:32.831093Z","iopub.execute_input":"2023-07-27T23:05:32.832203Z","iopub.status.idle":"2023-07-27T23:05:33.284423Z","shell.execute_reply.started":"2023-07-27T23:05:32.832168Z","shell.execute_reply":"2023-07-27T23:05:33.283407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacking_hgbc_model = HistGradientBoostingClassifier(learning_rate=0.9112141545526848, max_depth=5, min_samples_leaf=18, \n                                                     max_iter=160, random_state=seed).fit(X_train, y_train)\nstacking_hgbc = stacking_hgbc_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:05:33.286172Z","iopub.execute_input":"2023-07-27T23:05:33.287407Z","iopub.status.idle":"2023-07-27T23:05:33.579418Z","shell.execute_reply.started":"2023-07-27T23:05:33.287357Z","shell.execute_reply":"2023-07-27T23:05:33.578416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import get_scorer_names","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:05:33.580580Z","iopub.execute_input":"2023-07-27T23:05:33.581555Z","iopub.status.idle":"2023-07-27T23:05:33.587279Z","shell.execute_reply.started":"2023-07-27T23:05:33.581517Z","shell.execute_reply":"2023-07-27T23:05:33.585708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('CatBoostClassifier CV: ', CV(cat_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:05:33.588972Z","iopub.execute_input":"2023-07-27T23:05:33.589465Z","iopub.status.idle":"2023-07-27T23:05:56.516263Z","shell.execute_reply.started":"2023-07-27T23:05:33.589432Z","shell.execute_reply":"2023-07-27T23:05:56.514191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('XGB Classifier CV: ', CV(xgb_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:05:56.519045Z","iopub.execute_input":"2023-07-27T23:05:56.519519Z","iopub.status.idle":"2023-07-27T23:06:00.419491Z","shell.execute_reply.started":"2023-07-27T23:05:56.519476Z","shell.execute_reply":"2023-07-27T23:06:00.418169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('HGBC Classifier CV: ', CV(hgbc_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:06:00.421083Z","iopub.execute_input":"2023-07-27T23:06:00.421424Z","iopub.status.idle":"2023-07-27T23:06:06.035156Z","shell.execute_reply.started":"2023-07-27T23:06:00.421397Z","shell.execute_reply":"2023-07-27T23:06:06.033696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('LGBM Classifier CV: ', CV(lgbm_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:06:06.037065Z","iopub.execute_input":"2023-07-27T23:06:06.038271Z","iopub.status.idle":"2023-07-27T23:06:17.982246Z","shell.execute_reply.started":"2023-07-27T23:06:06.038198Z","shell.execute_reply":"2023-07-27T23:06:17.980865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('CatBoostClassifier Stacking CV: ', CV(stacking_cat_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:06:17.984329Z","iopub.execute_input":"2023-07-27T23:06:17.984762Z","iopub.status.idle":"2023-07-27T23:06:43.081655Z","shell.execute_reply.started":"2023-07-27T23:06:17.984730Z","shell.execute_reply":"2023-07-27T23:06:43.080224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('XGB Classifier Stacking CV: ', CV(stacking_xgb_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:06:43.085488Z","iopub.execute_input":"2023-07-27T23:06:43.085854Z","iopub.status.idle":"2023-07-27T23:06:47.339472Z","shell.execute_reply.started":"2023-07-27T23:06:43.085825Z","shell.execute_reply":"2023-07-27T23:06:47.338406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('LGBM Classifier Stacking CV: ', CV(stacking_lgbm_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:06:47.340879Z","iopub.execute_input":"2023-07-27T23:06:47.341212Z","iopub.status.idle":"2023-07-27T23:06:51.914903Z","shell.execute_reply.started":"2023-07-27T23:06:47.341183Z","shell.execute_reply":"2023-07-27T23:06:51.913038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('HGBC Classifier Stacking CV: ', CV(stacking_hgbc_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:06:51.916456Z","iopub.execute_input":"2023-07-27T23:06:51.916891Z","iopub.status.idle":"2023-07-27T23:06:54.523528Z","shell.execute_reply.started":"2023-07-27T23:06:51.916853Z","shell.execute_reply":"2023-07-27T23:06:54.522370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def round_up_down(num):\n    return 1 if num >= 0.5 else 0","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:06:54.525332Z","iopub.execute_input":"2023-07-27T23:06:54.525670Z","iopub.status.idle":"2023-07-27T23:06:54.530041Z","shell.execute_reply.started":"2023-07-27T23:06:54.525641Z","shell.execute_reply":"2023-07-27T23:06:54.529167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#final.iloc[:, 1], final.iloc[:, -1] = stacking_cat_model.predict_proba(test.iloc[:, 1:])[:, 0], stacking_cat_model.predict_proba(test.iloc[:, 1:])[:, 1]\nfinal.iloc[:, 1] = (lgbm[:, 0] + xgb[:, 0])/2\nfinal.iloc[:, -1] = (lgbm[:, 1] + xgb[:, 1])/2\nfinal.iloc[:, 1:] = final.iloc[:, 1:].applymap(round_up_down)\nfinal.to_csv('submission.csv', index=False)\nsubmission = pd.read_csv('submission.csv')\nsubmission","metadata":{"execution":{"iopub.status.busy":"2023-07-27T23:06:54.531371Z","iopub.execute_input":"2023-07-27T23:06:54.531938Z","iopub.status.idle":"2023-07-27T23:06:54.570534Z","shell.execute_reply.started":"2023-07-27T23:06:54.531902Z","shell.execute_reply":"2023-07-27T23:06:54.569113Z"},"trusted":true},"execution_count":null,"outputs":[]}]}