{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing Libraries","metadata":{"execution":{"iopub.status.busy":"2023-08-03T02:00:53.347952Z","iopub.execute_input":"2023-08-03T02:00:53.348419Z","iopub.status.idle":"2023-08-03T02:01:12.077606Z","shell.execute_reply.started":"2023-08-03T02:00:53.348388Z","shell.execute_reply":"2023-08-03T02:01:12.076073Z"}}},{"cell_type":"code","source":"!pip install tabpfn --no-index --find-links=file:///kaggle/input/pip-packages-icr/pip-packages\n!mkdir -p /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n!cp /kaggle/input/pip-packages-icr/pip-packages/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:31.334492Z","iopub.execute_input":"2023-08-03T05:56:31.334889Z","iopub.status.idle":"2023-08-03T05:56:49.348275Z","shell.execute_reply.started":"2023-08-03T05:56:31.334859Z","shell.execute_reply":"2023-08-03T05:56:49.346268Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Looking in links: file:///kaggle/input/pip-packages-icr/pip-packages\nProcessing /kaggle/input/pip-packages-icr/pip-packages/tabpfn-0.1.9-py3-none-any.whl\nRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (1.23.5)\nRequirement already satisfied: pyyaml>=5.4.1 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (6.0)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (2.31.0)\nRequirement already satisfied: scikit-learn>=0.24.2 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (1.2.2)\nRequirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (2.0.0+cpu)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (2023.5.7)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->tabpfn) (1.11.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->tabpfn) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->tabpfn) (3.1.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->tabpfn) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9.0->tabpfn) (1.3.0)\nInstalling collected packages: tabpfn\nSuccessfully installed tabpfn-0.1.9\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\nimport numpy as np\nimport pandas as pd\nimport warnings\ndef ignore_warn(*args,**kwargs):\n    pass\nwarnings.warn = ignore_warn\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport optuna\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score, KFold, train_test_split\nfrom sklearn.metrics import f1_score\nimport xgboost as xgboost\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, HistGradientBoostingClassifier, BaggingClassifier, StackingClassifier, VotingClassifier, GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.experimental import enable_hist_gradient_boosting  \nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.impute import KNNImputer\nfrom tabpfn import TabPFNClassifier","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:49.351158Z","iopub.execute_input":"2023-08-03T05:56:49.351666Z","iopub.status.idle":"2023-08-03T05:56:56.382742Z","shell.execute_reply.started":"2023-08-03T05:56:49.351613Z","shell.execute_reply":"2023-08-03T05:56:56.381568Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\ntest = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\nfinal = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.384364Z","iopub.execute_input":"2023-08-03T05:56:56.386237Z","iopub.status.idle":"2023-08-03T05:56:56.439277Z","shell.execute_reply.started":"2023-08-03T05:56:56.386191Z","shell.execute_reply":"2023-08-03T05:56:56.437992Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\ntrain.loc[:, 'EJ'] = encoder.fit_transform(train.loc[:, 'EJ'])\ntest.loc[:, 'EJ'] = encoder.fit_transform(test.loc[:, 'EJ'])","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.442733Z","iopub.execute_input":"2023-08-03T05:56:56.443158Z","iopub.status.idle":"2023-08-03T05:56:56.457511Z","shell.execute_reply.started":"2023-08-03T05:56:56.443125Z","shell.execute_reply":"2023-08-03T05:56:56.456253Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"imputer = KNNImputer(n_neighbors = 10)\ntrain_no_id = train.drop(['Id'], axis = 1)\ntrain_no_id = imputer.fit_transform(train_no_id)\ntrain_no_id = pd.DataFrame(train_no_id, columns = train.drop(['Id'], axis = 1).columns)\ntrain = pd.concat([train['Id'], train_no_id], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.459422Z","iopub.execute_input":"2023-08-03T05:56:56.460205Z","iopub.status.idle":"2023-08-03T05:56:56.523082Z","shell.execute_reply.started":"2023-08-03T05:56:56.460161Z","shell.execute_reply":"2023-08-03T05:56:56.521476Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\nseed = 617\nzero, one = np.bincount(train.loc[:, 'Class'])\none_df = train.iloc[(train.loc[:, 'Class'] == 1).tolist(), :] \nzero_df = train.iloc[(train.loc[:, 'Class'] == 0).tolist(), :]\nzero_df = zero_df.sample(n=one, random_state=seed)\noversampled_df = pd.concat([train.iloc[(train.loc[:, 'Class'] == 0).tolist(), :], one_df, one_df, one_df, one_df])\noversampled_df = oversampled_df.sample(frac=1, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.531878Z","iopub.execute_input":"2023-08-03T05:56:56.536088Z","iopub.status.idle":"2023-08-03T05:56:56.565412Z","shell.execute_reply.started":"2023-08-03T05:56:56.536021Z","shell.execute_reply":"2023-08-03T05:56:56.563739Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\ndef balanced_log_loss(y_true, y_pred):\n    N_0 = np.sum(1 - y_true)\n    N_1 = np.sum(y_true)\n    w_0 = 1 / N_0\n    w_1 = 1 / N_1\n    p_1 = np.clip(y_pred[:, 1], 1e-15, 1-1e-15)\n    p_0 = 1 - p_1\n    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\n    log_loss_1 = -np.sum(y_true * np.log(p_1))\n    balanced_log_loss = (w_0 * log_loss_0 + w_1 * log_loss_1) / 2\n    return balanced_log_loss","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.573380Z","iopub.execute_input":"2023-08-03T05:56:56.577720Z","iopub.status.idle":"2023-08-03T05:56:56.593891Z","shell.execute_reply.started":"2023-08-03T05:56:56.577646Z","shell.execute_reply":"2023-08-03T05:56:56.592216Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\nn_folds = 10\ndef CV(model, data, loss_function):\n    skf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n    kfold = skf.split(data.iloc[:, 1:-1], data.iloc[:, -1])\n    losses = []\n    for (train_id, val_id) in kfold:\n        x_train = data.iloc[train_id, 1:-1]\n        y_train = data.iloc[train_id, -1]\n        x_val = data.iloc[val_id, 1:-1]\n        y_val = data.iloc[val_id, -1]\n        model.fit(x_train, y_train)\n        pred_val = model.predict_proba(x_val)\n        loss = loss_function(y_val, pred_val)\n        losses.append(loss)\n    return np.sum(losses) / n_folds","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.602411Z","iopub.execute_input":"2023-08-03T05:56:56.607352Z","iopub.status.idle":"2023-08-03T05:56:56.621848Z","shell.execute_reply.started":"2023-08-03T05:56:56.607276Z","shell.execute_reply":"2023-08-03T05:56:56.620776Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_train = oversampled_df.drop(columns=['Class', 'Id'])\ny_train = oversampled_df['Class']","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.623911Z","iopub.execute_input":"2023-08-03T05:56:56.624487Z","iopub.status.idle":"2023-08-03T05:56:56.635612Z","shell.execute_reply.started":"2023-08-03T05:56:56.624419Z","shell.execute_reply":"2023-08-03T05:56:56.634524Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"markdown","source":"## Optuna Trial Exploration","metadata":{}},{"cell_type":"code","source":"def xgb(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),\n    }\n    model = xgb.XGBClassifier(**param, random_state = seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.641583Z","iopub.execute_input":"2023-08-03T05:56:56.642028Z","iopub.status.idle":"2023-08-03T05:56:56.652277Z","shell.execute_reply.started":"2023-08-03T05:56:56.641990Z","shell.execute_reply":"2023-08-03T05:56:56.650928Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def lgbm(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'num_leaves' : trial.suggest_int('num_leaves', 10, 50),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 50),\n    }\n    model = lgb.LGBMClassifier(**param, random_state = seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.653645Z","iopub.execute_input":"2023-08-03T05:56:56.654016Z","iopub.status.idle":"2023-08-03T05:56:56.664052Z","shell.execute_reply.started":"2023-08-03T05:56:56.653985Z","shell.execute_reply":"2023-08-03T05:56:56.663089Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def catboost(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 150, 10),\n        'reg_lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'colsample_bylevel': trial.suggest_categorical('colsample_bylevel', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'one_hot_max_size': trial.suggest_int('one_hot_max_size', 2, 10),\n    }\n    model = CatBoostClassifier(**param, random_seed=seed, verbose=False)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.665683Z","iopub.execute_input":"2023-08-03T05:56:56.666792Z","iopub.status.idle":"2023-08-03T05:56:56.677672Z","shell.execute_reply.started":"2023-08-03T05:56:56.666726Z","shell.execute_reply":"2023-08-03T05:56:56.676443Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def hgbc(trial):\n    param = {\n        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 15),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'max_iter': trial.suggest_int('max_iter', 50, 200, 10),\n    }\n    model = HistGradientBoostingClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.679518Z","iopub.execute_input":"2023-08-03T05:56:56.680156Z","iopub.status.idle":"2023-08-03T05:56:56.694152Z","shell.execute_reply.started":"2023-08-03T05:56:56.680116Z","shell.execute_reply":"2023-08-03T05:56:56.692920Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def bagged_dt(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 400, 600, 20),\n        'max_samples': trial.suggest_float('max_samples', 1e-2, 1.0),\n        'max_features': trial.suggest_float('max_features', 1e-2, 1.0),\n        'bootstrap': trial.suggest_categorical('bootstrap', [False, True]),\n        'bootstrap_features': trial.suggest_categorical('bootstrap_features', [False, True]),\n    }\n    model = BaggingClassifier(**param, base_estimator=DecisionTreeClassifier(), random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.695554Z","iopub.execute_input":"2023-08-03T05:56:56.696127Z","iopub.status.idle":"2023-08-03T05:56:56.707836Z","shell.execute_reply.started":"2023-08-03T05:56:56.696084Z","shell.execute_reply":"2023-08-03T05:56:56.706634Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def rf(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 300, 500, 20),\n        'max_depth': trial.suggest_int('max_depth', 5, 25),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'max_features': trial.suggest_int('max_features', 1, 56),\n        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n    }\n    model = RandomForestClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.709509Z","iopub.execute_input":"2023-08-03T05:56:56.710131Z","iopub.status.idle":"2023-08-03T05:56:56.722943Z","shell.execute_reply.started":"2023-08-03T05:56:56.710097Z","shell.execute_reply":"2023-08-03T05:56:56.721727Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def adaboost(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 400, 500, 20),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.0001, 1),\n        'base_estimator': DecisionTreeClassifier(max_depth=trial.suggest_int('max_depth', 1, 20)),\n    }\n    model = AdaBoostClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.724001Z","iopub.execute_input":"2023-08-03T05:56:56.724353Z","iopub.status.idle":"2023-08-03T05:56:56.742830Z","shell.execute_reply.started":"2023-08-03T05:56:56.724324Z","shell.execute_reply":"2023-08-03T05:56:56.741520Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def gradient(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 10, 500, 20),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.0001, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'subsample': trial.suggest_float('subsample', 0.3, 1.0),\n    }\n    model = GradientBoostingClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.744564Z","iopub.execute_input":"2023-08-03T05:56:56.744938Z","iopub.status.idle":"2023-08-03T05:56:56.756161Z","shell.execute_reply.started":"2023-08-03T05:56:56.744907Z","shell.execute_reply":"2023-08-03T05:56:56.755110Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def tabpfn(trial):\n    param = {\n        'N_ensemble_configurations': trial.suggest_int('N_ensemble_configurations', 20, 70),\n    }\n    model = TabPFNClassifier(**param)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.757911Z","iopub.execute_input":"2023-08-03T05:56:56.758361Z","iopub.status.idle":"2023-08-03T05:56:56.769393Z","shell.execute_reply.started":"2023-08-03T05:56:56.758321Z","shell.execute_reply":"2023-08-03T05:56:56.768431Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def catboost_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 150, 10),\n        'reg_lambda': trial.suggest_loguniform('lambda', 1e-3, 0.1),\n        'colsample_bylevel': trial.suggest_categorical('colsample_bylevel', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'one_hot_max_size': trial.suggest_int('one_hot_max_size', 2, 10),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=CatBoostClassifier(**param, random_state=seed, verbose=False)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.770489Z","iopub.execute_input":"2023-08-03T05:56:56.770834Z","iopub.status.idle":"2023-08-03T05:56:56.783707Z","shell.execute_reply.started":"2023-08-03T05:56:56.770804Z","shell.execute_reply":"2023-08-03T05:56:56.782747Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def xgb_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 0.1),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 0.1),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=xgboost.XGBClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.785349Z","iopub.execute_input":"2023-08-03T05:56:56.785667Z","iopub.status.idle":"2023-08-03T05:56:56.802206Z","shell.execute_reply.started":"2023-08-03T05:56:56.785641Z","shell.execute_reply":"2023-08-03T05:56:56.800708Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def hgbc_meta(trial):\n    param = {\n        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 15),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'max_iter': trial.suggest_int('max_iter', 50, 200, 10),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=HistGradientBoostingClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.803705Z","iopub.execute_input":"2023-08-03T05:56:56.804091Z","iopub.status.idle":"2023-08-03T05:56:56.817052Z","shell.execute_reply.started":"2023-08-03T05:56:56.804059Z","shell.execute_reply":"2023-08-03T05:56:56.815707Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def lgbm_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 0.1),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 0.1),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'num_leaves' : trial.suggest_int('num_leaves', 10, 50),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 50),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=lgb.LGBMClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.818617Z","iopub.execute_input":"2023-08-03T05:56:56.819176Z","iopub.status.idle":"2023-08-03T05:56:56.834506Z","shell.execute_reply.started":"2023-08-03T05:56:56.819136Z","shell.execute_reply":"2023-08-03T05:56:56.833280Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#cv_scores = []\n#for i in range(1, 70):\n#    cv_scores.append(CV(TabPFNClassifier(N_ensemble_configurations=i).fit(X_train, y_train), oversampled_df, balanced_log_loss))\n#    print(\"Finished scoring iteration: \", i)\n#print(cv_scores)\n# tabpfn_cv_scores = [0.09816634530404814, 0.06528742315606546, 0.07164710694330415, 0.0638588867076252, 0.06678059459477922, \n#                     0.06248073905402122, 0.06022244222278583, 0.05686026255684793, 0.05689105574304978, 0.055132598406416614, \n#                     0.05647036841993689, 0.05590923914786228, 0.05717749825124045, 0.056481389014045424, 0.05585544466795472, \n#                     0.05429705547774719, 0.05411289464998228, 0.053594943435855504, 0.05330166286267148, 0.05248949135011284, \n#                     0.05360971138750451, 0.053185855277044544, 0.05442991634568051, 0.054041848842559824, 0.05442855850281584, \n#                     0.054167697496943834, 0.05464900294529094, 0.05452444890518441, 0.05537642870820436, 0.05530201264890257, \n#                     0.05508454012654403, 0.05454951688798497, 0.055158959487388484, 0.05487638328640315, 0.05475942057273066, \n#                     0.054363820012922115, 0.05444429556509187, 0.05417317343226857, 0.05412096729914397, 0.05351279626269752, \n#                     0.05340841118461925, 0.053096957471938544, 0.053109073061545865, 0.052836328953108344, 0.05318516573142357, \n#                     0.053126580472636464, 0.05360923926329571, 0.053408860579671494, 0.05393021365358299, 0.05382474507832467, \n#                     0.05371423691544534, 0.05321754224273796, 0.053625478068834165, 0.05351067456999581, 0.053520923141210576, \n#                     0.05313957104926818, 0.053584265552239566, 0.05343326935461631, 0.05377785617124854, 0.05370929324862032, \n#                     0.053595077061113806, 0.053302678221229506, 0.053333914849297705, 0.053023531220070495, 0.0529506407276686, \n#                     0.052713977186699276, 0.05300799494093289, 0.05295979717175845, 0.05318406292878591]","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.837216Z","iopub.execute_input":"2023-08-03T05:56:56.837569Z","iopub.status.idle":"2023-08-03T05:56:56.847265Z","shell.execute_reply.started":"2023-08-03T05:56:56.837540Z","shell.execute_reply":"2023-08-03T05:56:56.846076Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# start = time.time()\n\n# study1 = optuna.create_study(direction='minimize')\n# n_trials = 75\n# study1.optimize(tabpfn, n_trials=n_trials)\n# print('Best trial:', study1.best_trial.params)\n# print('Best values:', study1.best_value)\n\n# end = time.time()\n# print('It has taken {:.5f} seconds to search for the best Hyperparameter'.format(end-start))","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.848950Z","iopub.execute_input":"2023-08-03T05:56:56.849430Z","iopub.status.idle":"2023-08-03T05:56:56.864369Z","shell.execute_reply.started":"2023-08-03T05:56:56.849385Z","shell.execute_reply":"2023-08-03T05:56:56.863198Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Creating Models","metadata":{}},{"cell_type":"code","source":"# CV(TabPFNClassifier(N_ensemble_configurations=24).fit(X_train, y_train), oversampled_df, balanced_log_loss)\n# # for each test performance on 1s and 0s","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.865774Z","iopub.execute_input":"2023-08-03T05:56:56.866151Z","iopub.status.idle":"2023-08-03T05:56:56.879848Z","shell.execute_reply.started":"2023-08-03T05:56:56.866121Z","shell.execute_reply":"2023-08-03T05:56:56.878732Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"#add way to do rule-based and adaptive ensembling\n#see what others did","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.881294Z","iopub.execute_input":"2023-08-03T05:56:56.881724Z","iopub.status.idle":"2023-08-03T05:56:56.891868Z","shell.execute_reply.started":"2023-08-03T05:56:56.881682Z","shell.execute_reply":"2023-08-03T05:56:56.890673Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"xgb_model = xgboost.XGBClassifier(n_estimators=200, reg_lambda=0.15325900166549988, reg_alpha=0.0044700650580230235, \n                              colsample_bytree=0.3, subsample=1.0, learning_rate=0.09975673376458177, \n                              max_depth=11, min_child_weight=2, random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:56.893786Z","iopub.execute_input":"2023-08-03T05:56:56.894307Z","iopub.status.idle":"2023-08-03T05:56:57.225054Z","shell.execute_reply.started":"2023-08-03T05:56:56.894260Z","shell.execute_reply":"2023-08-03T05:56:57.224103Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"lgbm_model = lgb.LGBMClassifier(n_estimators=200, reg_alpha=0.0016725623110267532, reg_lambda=0.0038043774323061946, \n                                 colsample_bytree=0.3, subsample=0.4, learning_rate=0.09367295744238123, max_depth=11, \n                                 num_leaves=50, min_child_samples=26, random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:57.234160Z","iopub.execute_input":"2023-08-03T05:56:57.237258Z","iopub.status.idle":"2023-08-03T05:56:58.353669Z","shell.execute_reply.started":"2023-08-03T05:56:57.237210Z","shell.execute_reply":"2023-08-03T05:56:58.352658Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"cat_model = CatBoostClassifier(n_estimators=70, reg_lambda=0.01606738047167, colsample_bylevel=0.3, \n                              subsample=0.7, learning_rate=0.0865881098465479, \n                              max_depth=9, one_hot_max_size=10, random_state=seed, verbose=False).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:56:58.355012Z","iopub.execute_input":"2023-08-03T05:56:58.355819Z","iopub.status.idle":"2023-08-03T05:57:00.625713Z","shell.execute_reply.started":"2023-08-03T05:56:58.355786Z","shell.execute_reply":"2023-08-03T05:57:00.624786Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"hgbc_model = HistGradientBoostingClassifier(max_iter=170, max_depth=4, min_samples_leaf=9,\n                                         learning_rate=0.17193627413211837, random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:57:00.627177Z","iopub.execute_input":"2023-08-03T05:57:00.628369Z","iopub.status.idle":"2023-08-03T05:57:01.275898Z","shell.execute_reply.started":"2023-08-03T05:57:00.628325Z","shell.execute_reply":"2023-08-03T05:57:01.274879Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"dt_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=500, max_samples=0.994711990802652,\n                           max_features=0.7844039008030275, bootstrap=False, bootstrap_features=True, random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:57:01.277265Z","iopub.execute_input":"2023-08-03T05:57:01.278414Z","iopub.status.idle":"2023-08-03T05:57:13.423880Z","shell.execute_reply.started":"2023-08-03T05:57:01.278372Z","shell.execute_reply":"2023-08-03T05:57:13.422807Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"rf_model = RandomForestClassifier(n_estimators=420, max_depth=13, min_samples_split=3, \n                                  min_samples_leaf=1, max_features=9, bootstrap=False, random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:57:13.425110Z","iopub.execute_input":"2023-08-03T05:57:13.425953Z","iopub.status.idle":"2023-08-03T05:57:15.948268Z","shell.execute_reply.started":"2023-08-03T05:57:13.425920Z","shell.execute_reply":"2023-08-03T05:57:15.947214Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"ada_model = AdaBoostClassifier(n_estimators=420, learning_rate=0.6794771047521856, \n                               base_estimator=DecisionTreeClassifier(max_depth=4), random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:57:15.949529Z","iopub.execute_input":"2023-08-03T05:57:15.950475Z","iopub.status.idle":"2023-08-03T05:57:24.061664Z","shell.execute_reply.started":"2023-08-03T05:57:15.950433Z","shell.execute_reply":"2023-08-03T05:57:24.060389Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"gradient_model = GradientBoostingClassifier(n_estimators=170, learning_rate=0.05893342084840253, max_depth=6, \n                                            min_samples_split=16, min_samples_leaf=11, subsample=0.9112739951878389, random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:57:24.063675Z","iopub.execute_input":"2023-08-03T05:57:24.064152Z","iopub.status.idle":"2023-08-03T05:57:27.337772Z","shell.execute_reply.started":"2023-08-03T05:57:24.064109Z","shell.execute_reply":"2023-08-03T05:57:27.336159Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"tab_lower_model = TabPFNClassifier(N_ensemble_configurations=20).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:57:27.339679Z","iopub.execute_input":"2023-08-03T05:57:27.340245Z","iopub.status.idle":"2023-08-03T05:57:30.385513Z","shell.execute_reply.started":"2023-08-03T05:57:27.340177Z","shell.execute_reply":"2023-08-03T05:57:30.384403Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Loading model that can be used for inference only\nUsing a Transformer with 25.82 M parameters\n","output_type":"stream"}]},{"cell_type":"code","source":"tab_upper_model = TabPFNClassifier(N_ensemble_configurations=66).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:57:30.387461Z","iopub.execute_input":"2023-08-03T05:57:30.387906Z","iopub.status.idle":"2023-08-03T05:57:33.302931Z","shell.execute_reply.started":"2023-08-03T05:57:30.387866Z","shell.execute_reply":"2023-08-03T05:57:33.301907Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Loading model that can be used for inference only\nUsing a Transformer with 25.82 M parameters\n","output_type":"stream"}]},{"cell_type":"code","source":"stacking_cat_model = CatBoostClassifier(n_estimators=150, reg_lambda=0.05055956136270572, colsample_bylevel=0.6, \n                                        subsample=0.5, learning_rate=0.08699165501504001, max_depth=7, \n                                        one_hot_max_size=8, random_state=seed, verbose=False).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:57:33.306428Z","iopub.execute_input":"2023-08-03T05:57:33.306801Z","iopub.status.idle":"2023-08-03T05:57:35.678543Z","shell.execute_reply.started":"2023-08-03T05:57:33.306771Z","shell.execute_reply":"2023-08-03T05:57:35.677405Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"stacking_xgb_model = xgboost.XGBClassifier(n_estimators=160, reg_lambda=0.030554982480056614, alpha=0.022993963306149747, \n                                           colsample_bytree=0.4, subsample=0.6, learning_rate=0.08378145372235492, \n                                           max_depth=17, min_child_weight=1, random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:57:35.680047Z","iopub.execute_input":"2023-08-03T05:57:35.680405Z","iopub.status.idle":"2023-08-03T05:57:36.163897Z","shell.execute_reply.started":"2023-08-03T05:57:35.680374Z","shell.execute_reply":"2023-08-03T05:57:36.162615Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"stacking_lgbm_model = lgb.LGBMClassifier(n_estimators=130, reg_alpha=0.017987440901161444, reg_lambda=0.0010110144342120994, \n                                colsample_bytree=0.8, subsample=0.5, learning_rate=0.08786840365732179, \n                                max_depth=5, num_leaves=10, min_child_samples=48, random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:57:36.165891Z","iopub.execute_input":"2023-08-03T05:57:36.166257Z","iopub.status.idle":"2023-08-03T05:57:36.563855Z","shell.execute_reply.started":"2023-08-03T05:57:36.166225Z","shell.execute_reply":"2023-08-03T05:57:36.562639Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"stacking_hgbc_model = HistGradientBoostingClassifier(learning_rate=0.9112141545526848, max_depth=5, min_samples_leaf=18, \n                                                     max_iter=160, random_state=seed).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T05:57:36.565305Z","iopub.execute_input":"2023-08-03T05:57:36.566244Z","iopub.status.idle":"2023-08-03T05:57:36.868419Z","shell.execute_reply.started":"2023-08-03T05:57:36.566211Z","shell.execute_reply":"2023-08-03T05:57:36.867157Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"## Testing Models","metadata":{}},{"cell_type":"code","source":"n_folds = 10\ndef CV_plus(model, data, loss_function):\n    skf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n    kfold = skf.split(data.iloc[:, 1:-1], data.iloc[:, -1])\n    losses = []\n    num_predictions_lt_01 = []\n    num_predictions_gt_09 = []\n    num_wrong_class1_predictions = []\n    num_wrong_class0_predictions = []\n    \n    for (train_id, val_id) in kfold:\n        x_train = data.iloc[train_id, 1:-1]\n        y_train = data.iloc[train_id, -1]\n        x_val = data.iloc[val_id, 1:-1]\n        y_val = data.iloc[val_id, -1]\n        model.fit(x_train, y_train)\n        pred_val = model.predict_proba(x_val)\n        pred_val_one = model.predict_proba(x_val)[:, 1]\n        loss = loss_function(y_val, pred_val)\n        losses.append(loss)\n        num_predictions_lt_01.append(np.sum((pred_val_one < 0.1)))\n        num_predictions_gt_09.append(np.sum((pred_val_one > 0.9)))\n        num_wrong_class1_predictions.append(np.sum(((y_val == 1) & (pred_val_one < 0.5))))\n        num_wrong_class0_predictions.append(np.sum(((y_val == 0) & (pred_val_one > 0.5))))\n    \n    avg_log_loss = np.sum(losses) / n_folds\n    avg_num_predictions_lt_01 = np.mean(num_predictions_lt_01)\n    avg_num_predictions_gt_09 = np.mean(num_predictions_gt_09)\n    avg_num_wrong_class1_predictions = np.mean(num_wrong_class1_predictions)\n    avg_num_wrong_class0_predictions = np.mean(num_wrong_class0_predictions)\n    \n    return avg_log_loss, avg_num_predictions_lt_01, avg_num_predictions_gt_09, avg_num_wrong_class1_predictions, avg_num_wrong_class0_predictions","metadata":{"execution":{"iopub.status.busy":"2023-08-03T06:44:29.023090Z","iopub.execute_input":"2023-08-03T06:44:29.023535Z","iopub.status.idle":"2023-08-03T06:44:29.037436Z","shell.execute_reply.started":"2023-08-03T06:44:29.023504Z","shell.execute_reply":"2023-08-03T06:44:29.035608Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"models = [xgb_model, lgbm_model, cat_model, hgbc_model, dt_model, \n          rf_model, ada_model, gradient_model, tab_lower_model, \n          tab_upper_model, stacking_cat_model, stacking_xgb_model, \n          stacking_lgbm_model, stacking_hgbc_model]\n\nresults_df = pd.DataFrame(columns=['Model', 'Accuracy', 'CV Balanced-Log-Loss', 'Predictions < 0.1', 'Predictions > 0.9', 'Class 0 Wrong', 'Class 1 Wrong'])\n\nfor model in models:\n    avg_log_loss, avg_num_predictions_lt_01, avg_num_predictions_gt_09, avg_num_wrong_class1_predictions, avg_num_wrong_class0_predictions = CV_plus(model, oversampled_df, balanced_log_loss)\n    accuracy = 1.0 - (avg_num_wrong_class1_predictions + avg_num_wrong_class0_predictions)/ len(oversampled_df)\n    results_df = results_df.append({'Model': str(model), 'Accuracy': accuracy,\n                                    'CV Balanced-Log-Loss': avg_log_loss, 'Predictions < 0.1': avg_num_predictions_lt_01, \n                                    'Predictions > 0.9': avg_num_predictions_gt_09, 'Class 0 Wrong': avg_num_wrong_class0_predictions, \n                                    'Class 1 Wrong': avg_num_wrong_class1_predictions}, ignore_index=True)\n\nprint(results_df)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T06:56:39.492363Z","iopub.execute_input":"2023-08-03T06:56:39.492856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"def round_up_down(num):\n    return 1 if num >= 0.5 else 0","metadata":{"execution":{"iopub.status.busy":"2023-07-28T21:33:46.701871Z","iopub.execute_input":"2023-07-28T21:33:46.702618Z","iopub.status.idle":"2023-07-28T21:33:46.710199Z","shell.execute_reply.started":"2023-07-28T21:33:46.702577Z","shell.execute_reply":"2023-07-28T21:33:46.709028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#final.iloc[:, 1], final.iloc[:, -1] = stacking_cat_model.predict_proba(test.iloc[:, 1:])[:, 0], stacking_cat_model.predict_proba(test.iloc[:, 1:])[:, 1]\nfinal.iloc[:, 1] = (lgbm[:, 0] + xgb[:, 0])/2\nfinal.iloc[:, -1] = (lgbm[:, 1] + xgb[:, 1])/2\nfinal.to_csv('submission.csv', index=False)\nsubmission = pd.read_csv('submission.csv')\nsubmission","metadata":{"execution":{"iopub.status.busy":"2023-07-28T21:33:46.711860Z","iopub.execute_input":"2023-07-28T21:33:46.712189Z","iopub.status.idle":"2023-07-28T21:33:46.740073Z","shell.execute_reply.started":"2023-07-28T21:33:46.712160Z","shell.execute_reply":"2023-07-28T21:33:46.738973Z"},"trusted":true},"execution_count":null,"outputs":[]}]}