{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nimport numpy as np\nimport pandas as pd\nimport warnings\ndef ignore_warn(*args,**kwargs):\n    pass\nwarnings.warn = ignore_warn\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport optuna\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score, KFold, train_test_split\nfrom sklearn.metrics import f1_score\nimport xgboost as xgboost\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, HistGradientBoostingClassifier, BaggingClassifier, StackingClassifier, VotingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.experimental import enable_hist_gradient_boosting  \nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.impute import KNNImputer","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:26.451185Z","iopub.execute_input":"2023-07-27T16:22:26.451609Z","iopub.status.idle":"2023-07-27T16:22:30.338872Z","shell.execute_reply.started":"2023-07-27T16:22:26.451576Z","shell.execute_reply":"2023-07-27T16:22:30.337577Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\ntest = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\nfinal = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.341364Z","iopub.execute_input":"2023-07-27T16:22:30.341742Z","iopub.status.idle":"2023-07-27T16:22:30.397262Z","shell.execute_reply.started":"2023-07-27T16:22:30.341708Z","shell.execute_reply":"2023-07-27T16:22:30.395913Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\ntrain.loc[:, 'EJ'] = encoder.fit_transform(train.loc[:, 'EJ'])\ntest.loc[:, 'EJ'] = encoder.fit_transform(test.loc[:, 'EJ'])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.399021Z","iopub.execute_input":"2023-07-27T16:22:30.399768Z","iopub.status.idle":"2023-07-27T16:22:30.414320Z","shell.execute_reply.started":"2023-07-27T16:22:30.399732Z","shell.execute_reply":"2023-07-27T16:22:30.412691Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"column_names = train.columns\nimputer = KNNImputer(n_neighbors = 10)\ntrain_no_id = imputer.fit_transform(train.drop(['Id'], axis = 1))\ntrain_no_id = pd.DataFrame(train_no_id)\ntrain = pd.concat([train['Id'], train_no_id], axis = 1)\ntrain.columns = column_names","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.417926Z","iopub.execute_input":"2023-07-27T16:22:30.418492Z","iopub.status.idle":"2023-07-27T16:22:30.486598Z","shell.execute_reply.started":"2023-07-27T16:22:30.418435Z","shell.execute_reply":"2023-07-27T16:22:30.484668Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#train.isna().sum().sort_values(ascending = False)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.488809Z","iopub.execute_input":"2023-07-27T16:22:30.489338Z","iopub.status.idle":"2023-07-27T16:22:30.506614Z","shell.execute_reply.started":"2023-07-27T16:22:30.489217Z","shell.execute_reply":"2023-07-27T16:22:30.498491Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\nseed = 617\nzero, one = np.bincount(train.loc[:, 'Class'])\none_df = train.iloc[(train.loc[:, 'Class'] == 1).tolist(), :] \nzero_df = train.iloc[(train.loc[:, 'Class'] == 0).tolist(), :]\nzero_df = zero_df.sample(n=one, random_state=seed)\noversampled_df = pd.concat([train.iloc[(train.loc[:, 'Class'] == 0).tolist(), :], one_df, one_df, one_df, one_df])\noversampled_df = oversampled_df.sample(frac=1, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.508578Z","iopub.execute_input":"2023-07-27T16:22:30.509195Z","iopub.status.idle":"2023-07-27T16:22:30.532060Z","shell.execute_reply.started":"2023-07-27T16:22:30.509131Z","shell.execute_reply":"2023-07-27T16:22:30.530387Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\ndef balanced_log_loss(y_true, y_pred):\n    N_0 = np.sum(1 - y_true)\n    N_1 = np.sum(y_true)\n    w_0 = 1 / N_0\n    w_1 = 1 / N_1\n    p_1 = np.clip(y_pred[:, 1], 1e-15, 1-1e-15)\n    p_0 = 1 - p_1\n    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\n    log_loss_1 = -np.sum(y_true * np.log(p_1))\n    balanced_log_loss = (w_0 * log_loss_0 + w_1 * log_loss_1) / 2\n    return balanced_log_loss","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.534128Z","iopub.execute_input":"2023-07-27T16:22:30.535029Z","iopub.status.idle":"2023-07-27T16:22:30.549707Z","shell.execute_reply.started":"2023-07-27T16:22:30.534985Z","shell.execute_reply":"2023-07-27T16:22:30.548130Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\nn_folds = 10\ndef CV(model, data, loss_function):\n    skf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n    kfold = skf.split(data.iloc[:, 1:-1], data.iloc[:, -1])\n    losses = []\n    for (train_id, val_id) in kfold:\n        x_train = data.iloc[train_id, 1:-1]\n        y_train = data.iloc[train_id, -1]\n        x_val = data.iloc[val_id, 1:-1]\n        y_val = data.iloc[val_id, -1]\n        model.fit(x_train, y_train)\n        pred_val = model.predict_proba(x_val)\n        loss = loss_function(y_val, pred_val)\n        losses.append(loss)\n    return np.sum(losses) / n_folds","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.551722Z","iopub.execute_input":"2023-07-27T16:22:30.553025Z","iopub.status.idle":"2023-07-27T16:22:30.568058Z","shell.execute_reply.started":"2023-07-27T16:22:30.552981Z","shell.execute_reply":"2023-07-27T16:22:30.566279Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_train = oversampled_df.drop(columns=['Class', 'Id'])\ny_train = oversampled_df['Class']","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.569904Z","iopub.execute_input":"2023-07-27T16:22:30.570693Z","iopub.status.idle":"2023-07-27T16:22:30.583119Z","shell.execute_reply.started":"2023-07-27T16:22:30.570650Z","shell.execute_reply":"2023-07-27T16:22:30.581887Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.587195Z","iopub.execute_input":"2023-07-27T16:22:30.587549Z","iopub.status.idle":"2023-07-27T16:22:30.597557Z","shell.execute_reply.started":"2023-07-27T16:22:30.587521Z","shell.execute_reply":"2023-07-27T16:22:30.596522Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def xgb(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),\n    }\n    model = xgb.XGBClassifier(**param, random_state = seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.599169Z","iopub.execute_input":"2023-07-27T16:22:30.601055Z","iopub.status.idle":"2023-07-27T16:22:30.617509Z","shell.execute_reply.started":"2023-07-27T16:22:30.601005Z","shell.execute_reply":"2023-07-27T16:22:30.616470Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def lgbm(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'num_leaves' : trial.suggest_int('num_leaves', 10, 50),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 50),\n    }\n    model = lgb.LGBMClassifier(**param, random_state = seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:31.665421Z","iopub.execute_input":"2023-07-27T16:22:31.666104Z","iopub.status.idle":"2023-07-27T16:22:31.674720Z","shell.execute_reply.started":"2023-07-27T16:22:31.666071Z","shell.execute_reply":"2023-07-27T16:22:31.673789Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def catboost(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 150, 10),\n        'reg_lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'colsample_bylevel': trial.suggest_categorical('colsample_bylevel', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'one_hot_max_size': trial.suggest_int('one_hot_max_size', 2, 10),\n    }\n    model = CatBoostClassifier(**param, random_seed=seed, verbose=False)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:31.790674Z","iopub.execute_input":"2023-07-27T16:22:31.791513Z","iopub.status.idle":"2023-07-27T16:22:31.800676Z","shell.execute_reply.started":"2023-07-27T16:22:31.791465Z","shell.execute_reply":"2023-07-27T16:22:31.799841Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def hgbc(trial):\n    param = {\n        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 15),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'max_iter': trial.suggest_int('max_iter', 50, 200, 10),\n    }\n    model = HistGradientBoostingClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:31.933454Z","iopub.execute_input":"2023-07-27T16:22:31.933891Z","iopub.status.idle":"2023-07-27T16:22:31.941049Z","shell.execute_reply.started":"2023-07-27T16:22:31.933855Z","shell.execute_reply":"2023-07-27T16:22:31.939867Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def bagged_dt(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 400, 600, 20),\n        'max_samples': trial.suggest_float('max_samples', 1e-2, 1.0),\n        'max_features': trial.suggest_float('max_features', 1e-2, 1.0),\n        'bootstrap': trial.suggest_categorical('bootstrap', [False, True]),\n        'bootstrap_features': trial.suggest_categorical('bootstrap_features', [False, True]),\n    }\n    model = BaggingClassifier(**param, base_estimator=DecisionTreeClassifier(), random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:32.047823Z","iopub.execute_input":"2023-07-27T16:22:32.048765Z","iopub.status.idle":"2023-07-27T16:22:32.056434Z","shell.execute_reply.started":"2023-07-27T16:22:32.048728Z","shell.execute_reply":"2023-07-27T16:22:32.055159Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def rf(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 300, 500, 20),\n        'max_depth': trial.suggest_int('max_depth', 5, 25),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'max_features': trial.suggest_int('max_features', 1, 56),\n        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n    }\n    model = RandomForestClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:33.222206Z","iopub.execute_input":"2023-07-27T16:22:33.222626Z","iopub.status.idle":"2023-07-27T16:22:33.231769Z","shell.execute_reply.started":"2023-07-27T16:22:33.222593Z","shell.execute_reply":"2023-07-27T16:22:33.230601Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def adaboost(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 400, 500, 20),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.0001, 1),\n        'base_estimator': DecisionTreeClassifier(max_depth=trial.suggest_int('max_depth', 1, 20)),\n    }\n    model = AdaBoostClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:30:17.465065Z","iopub.execute_input":"2023-07-27T16:30:17.465494Z","iopub.status.idle":"2023-07-27T16:30:17.473759Z","shell.execute_reply.started":"2023-07-27T16:30:17.465463Z","shell.execute_reply":"2023-07-27T16:30:17.472310Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def gradient(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 10, 500, 20),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.0001, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'subsample': trial.suggest_float('subsample', 0.3, 1.0),\n    }\n    model = GradientBoostingClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:32:29.844801Z","iopub.execute_input":"2023-07-27T16:32:29.845266Z","iopub.status.idle":"2023-07-27T16:32:29.853630Z","shell.execute_reply.started":"2023-07-27T16:32:29.845233Z","shell.execute_reply":"2023-07-27T16:32:29.852612Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n\nstudy1 = optuna.create_study(direction='minimize', study_name=\"AdaBoost\")\nn_trials = 75\nstudy1.optimize(adaboost, n_trials=n_trials)\nprint('Best trial:', study1.best_trial.params)\nprint('Best values:', study1.best_value)\n\nend = time.time()\nprint('It has taken {:.5f} seconds to search for the best Hyperparameter'.format(end-start))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:32:50.493243Z","iopub.execute_input":"2023-07-27T16:32:50.493667Z","iopub.status.idle":"2023-07-27T17:55:51.599392Z","shell.execute_reply.started":"2023-07-27T16:32:50.493635Z","shell.execute_reply":"2023-07-27T17:55:51.598442Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"[I 2023-07-27 16:32:50,496] A new study created in memory with name: AdaBoost\n[I 2023-07-27 16:33:44,383] Trial 0 finished with value: 0.48218780977894904 and parameters: {'n_estimators': 500, 'learning_rate': 0.19791672901865642, 'max_depth': 2}. Best is trial 0 with value: 0.48218780977894904.\n[I 2023-07-27 16:35:38,994] Trial 1 finished with value: 0.4459853856889787 and parameters: {'n_estimators': 480, 'learning_rate': 0.46509851982752176, 'max_depth': 7}. Best is trial 1 with value: 0.4459853856889787.\n[I 2023-07-27 16:37:17,403] Trial 2 finished with value: 0.02547033861937087 and parameters: {'n_estimators': 420, 'learning_rate': 0.8637383219017932, 'max_depth': 6}. Best is trial 2 with value: 0.02547033861937087.\n[I 2023-07-27 16:37:17,733] Trial 3 finished with value: 1.3285629599538031 and parameters: {'n_estimators': 420, 'learning_rate': 0.9130909295284324, 'max_depth': 13}. Best is trial 2 with value: 0.02547033861937087.\n[I 2023-07-27 16:37:18,064] Trial 4 finished with value: 1.3285629599538031 and parameters: {'n_estimators': 500, 'learning_rate': 0.6851674476540242, 'max_depth': 19}. Best is trial 2 with value: 0.02547033861937087.\n[I 2023-07-27 16:37:18,394] Trial 5 finished with value: 1.3285629599538031 and parameters: {'n_estimators': 500, 'learning_rate': 0.6700360667336521, 'max_depth': 13}. Best is trial 2 with value: 0.02547033861937087.\n[I 2023-07-27 16:39:16,511] Trial 6 finished with value: 0.13525965240068 and parameters: {'n_estimators': 500, 'learning_rate': 0.5275151034029463, 'max_depth': 6}. Best is trial 2 with value: 0.02547033861937087.\n[I 2023-07-27 16:40:28,336] Trial 7 finished with value: 0.13168293502646378 and parameters: {'n_estimators': 500, 'learning_rate': 0.6553795825985554, 'max_depth': 3}. Best is trial 2 with value: 0.02547033861937087.\n[I 2023-07-27 16:41:39,507] Trial 8 finished with value: 0.04755059413778825 and parameters: {'n_estimators': 400, 'learning_rate': 0.3855694605840007, 'max_depth': 4}. Best is trial 2 with value: 0.02547033861937087.\n[I 2023-07-27 16:41:39,842] Trial 9 finished with value: 1.3285629599538031 and parameters: {'n_estimators': 460, 'learning_rate': 0.9838203987359062, 'max_depth': 13}. Best is trial 2 with value: 0.02547033861937087.\n[I 2023-07-27 16:41:40,300] Trial 10 finished with value: 1.2756332092072784 and parameters: {'n_estimators': 440, 'learning_rate': 0.05743480566931736, 'max_depth': 9}. Best is trial 2 with value: 0.02547033861937087.\n[I 2023-07-27 16:43:04,200] Trial 11 finished with value: 0.1085546974928284 and parameters: {'n_estimators': 400, 'learning_rate': 0.33755369670051116, 'max_depth': 5}. Best is trial 2 with value: 0.02547033861937087.\n[I 2023-07-27 16:43:31,787] Trial 12 finished with value: 0.6487291925448156 and parameters: {'n_estimators': 400, 'learning_rate': 0.35012364406645136, 'max_depth': 1}. Best is trial 2 with value: 0.02547033861937087.\n[I 2023-07-27 16:43:44,357] Trial 13 finished with value: 1.1175627439926314 and parameters: {'n_estimators': 420, 'learning_rate': 0.8232897910643457, 'max_depth': 9}. Best is trial 2 with value: 0.02547033861937087.\n[I 2023-07-27 16:45:12,234] Trial 14 finished with value: 0.013929510456805622 and parameters: {'n_estimators': 420, 'learning_rate': 0.816551698788605, 'max_depth': 5}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 16:45:58,952] Trial 15 finished with value: 0.5060391556909102 and parameters: {'n_estimators': 440, 'learning_rate': 0.8145327048106437, 'max_depth': 8}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 16:45:59,319] Trial 16 finished with value: 1.3285629599538031 and parameters: {'n_estimators': 420, 'learning_rate': 0.9821740048597964, 'max_depth': 20}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 16:45:59,896] Trial 17 finished with value: 1.254665976996227 and parameters: {'n_estimators': 460, 'learning_rate': 0.8201198491369176, 'max_depth': 11}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 16:47:32,193] Trial 18 finished with value: 0.02235857876392212 and parameters: {'n_estimators': 440, 'learning_rate': 0.7578196288232968, 'max_depth': 5}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 16:47:32,554] Trial 19 finished with value: 1.3285629599538031 and parameters: {'n_estimators': 440, 'learning_rate': 0.7417113351692037, 'max_depth': 17}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 16:48:54,904] Trial 20 finished with value: 0.01473426970660319 and parameters: {'n_estimators': 460, 'learning_rate': 0.564047290739017, 'max_depth': 4}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 16:50:17,342] Trial 21 finished with value: 0.015156779586019001 and parameters: {'n_estimators': 460, 'learning_rate': 0.6294103570847965, 'max_depth': 4}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 16:50:50,466] Trial 22 finished with value: 0.6514569837185828 and parameters: {'n_estimators': 480, 'learning_rate': 0.5312539786715313, 'max_depth': 1}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 16:51:56,802] Trial 23 finished with value: 0.1300980438021488 and parameters: {'n_estimators': 460, 'learning_rate': 0.5866799791074748, 'max_depth': 3}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 16:53:23,020] Trial 24 finished with value: 0.01922206170569673 and parameters: {'n_estimators': 480, 'learning_rate': 0.5943760074280479, 'max_depth': 4}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 16:53:39,958] Trial 25 finished with value: 1.2298816460564916 and parameters: {'n_estimators': 460, 'learning_rate': 0.7477527372220487, 'max_depth': 11}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 16:55:26,501] Trial 26 finished with value: 0.4116669334426259 and parameters: {'n_estimators': 480, 'learning_rate': 0.6035264844676201, 'max_depth': 7}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 16:56:32,855] Trial 27 finished with value: 0.1378650856126637 and parameters: {'n_estimators': 460, 'learning_rate': 0.48906898734277104, 'max_depth': 3}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 16:58:05,035] Trial 28 finished with value: 0.029050568553280642 and parameters: {'n_estimators': 440, 'learning_rate': 0.7131498104038236, 'max_depth': 5}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 16:58:57,167] Trial 29 finished with value: 0.4716549456051024 and parameters: {'n_estimators': 480, 'learning_rate': 0.633534446008388, 'max_depth': 2}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 16:59:40,433] Trial 30 finished with value: 1.2026235899295634 and parameters: {'n_estimators': 460, 'learning_rate': 0.42183707608996673, 'max_depth': 9}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:01:06,690] Trial 31 finished with value: 0.015688163381993338 and parameters: {'n_estimators': 480, 'learning_rate': 0.5798289953735918, 'max_depth': 4}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:01:59,141] Trial 32 finished with value: 0.474589233799822 and parameters: {'n_estimators': 480, 'learning_rate': 0.5509824073033028, 'max_depth': 2}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:03:53,782] Trial 33 finished with value: 0.4237504290269321 and parameters: {'n_estimators': 480, 'learning_rate': 0.45798302610175, 'max_depth': 7}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:05:15,976] Trial 34 finished with value: 0.015751084340555922 and parameters: {'n_estimators': 460, 'learning_rate': 0.6440022296623681, 'max_depth': 4}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:06:55,946] Trial 35 finished with value: 0.1155876709957614 and parameters: {'n_estimators': 420, 'learning_rate': 0.566180730651966, 'max_depth': 6}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:07:29,621] Trial 36 finished with value: 0.6504392030485038 and parameters: {'n_estimators': 480, 'learning_rate': 0.688550913904709, 'max_depth': 1}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:08:51,062] Trial 37 finished with value: 0.3267022292839959 and parameters: {'n_estimators': 440, 'learning_rate': 0.8855184062921587, 'max_depth': 7}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:09:57,588] Trial 38 finished with value: 0.14240080152126375 and parameters: {'n_estimators': 460, 'learning_rate': 0.4654975906027662, 'max_depth': 3}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:11:42,889] Trial 39 finished with value: 0.027078300944934224 and parameters: {'n_estimators': 500, 'learning_rate': 0.6442946777945773, 'max_depth': 5}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:11:43,252] Trial 40 finished with value: 1.3285629599538031 and parameters: {'n_estimators': 480, 'learning_rate': 0.5199752835634794, 'max_depth': 16}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:13:06,249] Trial 41 finished with value: 0.020961814872066324 and parameters: {'n_estimators': 460, 'learning_rate': 0.6275461669272859, 'max_depth': 4}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:14:29,076] Trial 42 finished with value: 0.018804408938672863 and parameters: {'n_estimators': 460, 'learning_rate': 0.6379258249124728, 'max_depth': 4}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:16:17,721] Trial 43 finished with value: 0.07405294436343171 and parameters: {'n_estimators': 460, 'learning_rate': 0.7102078472181094, 'max_depth': 6}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:17:05,213] Trial 44 finished with value: 0.47342242506243776 and parameters: {'n_estimators': 440, 'learning_rate': 0.678517293689209, 'max_depth': 2}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:18:27,599] Trial 45 finished with value: 0.020042957897665657 and parameters: {'n_estimators': 460, 'learning_rate': 0.5559863844231592, 'max_depth': 4}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:19:55,324] Trial 46 finished with value: 0.4252332723393245 and parameters: {'n_estimators': 500, 'learning_rate': 0.7841176154876921, 'max_depth': 8}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:20:53,327] Trial 47 finished with value: 0.13051505352229142 and parameters: {'n_estimators': 400, 'learning_rate': 0.6839267928995807, 'max_depth': 3}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:22:20,924] Trial 48 finished with value: 0.04649659372029629 and parameters: {'n_estimators': 420, 'learning_rate': 0.5100053706001985, 'max_depth': 5}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:24:04,041] Trial 49 finished with value: 0.017169239638163657 and parameters: {'n_estimators': 440, 'learning_rate': 0.8649585663774221, 'max_depth': 6}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:25:26,200] Trial 50 finished with value: 0.4937838475588521 and parameters: {'n_estimators': 420, 'learning_rate': 0.6134261301306841, 'max_depth': 8}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:27:09,325] Trial 51 finished with value: 0.02167625633940456 and parameters: {'n_estimators': 440, 'learning_rate': 0.8500418289182416, 'max_depth': 6}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:28:52,941] Trial 52 finished with value: 0.01540872933870625 and parameters: {'n_estimators': 440, 'learning_rate': 0.9308646962073065, 'max_depth': 6}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:30:08,452] Trial 53 finished with value: 0.016044480142142097 and parameters: {'n_estimators': 420, 'learning_rate': 0.9441406163831373, 'max_depth': 4}. Best is trial 14 with value: 0.013929510456805622.\n[I 2023-07-27 17:31:41,242] Trial 54 finished with value: 0.012323704858146874 and parameters: {'n_estimators': 440, 'learning_rate': 0.9041677153091496, 'max_depth': 5}. Best is trial 54 with value: 0.012323704858146874.\n[I 2023-07-27 17:33:13,776] Trial 55 finished with value: 0.012175924493378815 and parameters: {'n_estimators': 440, 'learning_rate': 0.9171643818328405, 'max_depth': 5}. Best is trial 55 with value: 0.012175924493378815.\n[I 2023-07-27 17:34:57,488] Trial 56 finished with value: 0.01604084771939331 and parameters: {'n_estimators': 440, 'learning_rate': 0.9187116801692335, 'max_depth': 6}. Best is trial 55 with value: 0.012175924493378815.\n[I 2023-07-27 17:34:57,902] Trial 57 finished with value: 1.2673281457313172 and parameters: {'n_estimators': 440, 'learning_rate': 0.9878333309271753, 'max_depth': 10}. Best is trial 55 with value: 0.012175924493378815.\n[I 2023-07-27 17:36:39,536] Trial 58 finished with value: 0.3260093100371133 and parameters: {'n_estimators': 440, 'learning_rate': 0.9416833435455161, 'max_depth': 7}. Best is trial 55 with value: 0.012175924493378815.\n[I 2023-07-27 17:38:07,571] Trial 59 finished with value: 0.010945529042251084 and parameters: {'n_estimators': 420, 'learning_rate': 0.9022203254728052, 'max_depth': 5}. Best is trial 59 with value: 0.010945529042251084.\n[I 2023-07-27 17:39:31,337] Trial 60 finished with value: 0.024371913094087337 and parameters: {'n_estimators': 400, 'learning_rate': 0.7964369721458252, 'max_depth': 5}. Best is trial 59 with value: 0.010945529042251084.\n[I 2023-07-27 17:40:32,313] Trial 61 finished with value: 0.11800511786600046 and parameters: {'n_estimators': 420, 'learning_rate': 0.902709749567136, 'max_depth': 3}. Best is trial 59 with value: 0.010945529042251084.\n[I 2023-07-27 17:43:28,045] Trial 63 finished with value: 0.021406170717144457 and parameters: {'n_estimators': 420, 'learning_rate': 0.8465723089868175, 'max_depth': 5}. Best is trial 62 with value: 0.010726526175646109.\n[I 2023-07-27 17:44:13,681] Trial 64 finished with value: 0.4712245233054759 and parameters: {'n_estimators': 420, 'learning_rate': 0.8858252251725595, 'max_depth': 2}. Best is trial 62 with value: 0.010726526175646109.\n[I 2023-07-27 17:45:15,314] Trial 65 finished with value: 0.3343917754513511 and parameters: {'n_estimators': 420, 'learning_rate': 0.8340004939469239, 'max_depth': 7}. Best is trial 62 with value: 0.010726526175646109.\n[I 2023-07-27 17:46:43,053] Trial 66 finished with value: 0.013231784675126732 and parameters: {'n_estimators': 420, 'learning_rate': 0.7816821324908327, 'max_depth': 5}. Best is trial 62 with value: 0.010726526175646109.\n[I 2023-07-27 17:46:43,422] Trial 67 finished with value: 1.3285629599538031 and parameters: {'n_estimators': 400, 'learning_rate': 0.7709676123311242, 'max_depth': 15}. Best is trial 62 with value: 0.010726526175646109.\n[I 2023-07-27 17:47:41,047] Trial 68 finished with value: 0.4684532968700168 and parameters: {'n_estimators': 420, 'learning_rate': 0.7920646433912082, 'max_depth': 8}. Best is trial 62 with value: 0.010726526175646109.\n[I 2023-07-27 17:49:04,598] Trial 69 finished with value: 0.013670809207165438 and parameters: {'n_estimators': 400, 'learning_rate': 0.8242801755265258, 'max_depth': 5}. Best is trial 62 with value: 0.010726526175646109.\n[I 2023-07-27 17:50:28,138] Trial 70 finished with value: 0.013693279989562176 and parameters: {'n_estimators': 400, 'learning_rate': 0.8255853336046055, 'max_depth': 5}. Best is trial 62 with value: 0.010726526175646109.\n[I 2023-07-27 17:51:51,542] Trial 71 finished with value: 0.015552504136965236 and parameters: {'n_estimators': 400, 'learning_rate': 0.8213897711747902, 'max_depth': 5}. Best is trial 62 with value: 0.010726526175646109.\n[I 2023-07-27 17:52:49,497] Trial 72 finished with value: 0.11834285120139425 and parameters: {'n_estimators': 400, 'learning_rate': 0.8697229080895932, 'max_depth': 3}. Best is trial 62 with value: 0.010726526175646109.\n[I 2023-07-27 17:54:13,251] Trial 73 finished with value: 0.016874936996282282 and parameters: {'n_estimators': 400, 'learning_rate': 0.811270284862073, 'max_depth': 5}. Best is trial 62 with value: 0.010726526175646109.\n[I 2023-07-27 17:55:51,593] Trial 74 finished with value: 0.022981970124225776 and parameters: {'n_estimators': 420, 'learning_rate': 0.8530619059449437, 'max_depth': 6}. Best is trial 62 with value: 0.010726526175646109.\n","output_type":"stream"},{"name":"stdout","text":"Best trial: {'n_estimators': 420, 'learning_rate': 0.842243708967194, 'max_depth': 5}\nBest values: 0.010726526175646109\nIt has taken 4981.09945 seconds to search for the best Hyperparameter\n","output_type":"stream"}]},{"cell_type":"code","source":"xgb_model = xgboost.XGBClassifier(n_estimators=200, reg_lambda=0.15325900166549988, reg_alpha=0.0044700650580230235, \n                              colsample_bytree=0.3, subsample=1.0, learning_rate=0.09975673376458177, \n                              max_depth=11, min_child_weight=2, random_state=seed).fit(X_train, y_train)\nxgb = xgb_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:30.183146Z","iopub.execute_input":"2023-07-27T01:21:30.183543Z","iopub.status.idle":"2023-07-27T01:21:30.479940Z","shell.execute_reply.started":"2023-07-27T01:21:30.183505Z","shell.execute_reply":"2023-07-27T01:21:30.479081Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"lgbm_model = lgb.LGBMClassifier(n_estimators=200, reg_alpha=0.0016725623110267532, reg_lambda=0.0038043774323061946, \n                                 colsample_bytree=0.3, subsample=0.4, learning_rate=0.09367295744238123, max_depth=11, \n                                 num_leaves=50, min_child_samples=26, random_state=seed).fit(X_train, y_train)\nlgbm = lgbm_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:30.481599Z","iopub.execute_input":"2023-07-27T01:21:30.482132Z","iopub.status.idle":"2023-07-27T01:21:31.440791Z","shell.execute_reply.started":"2023-07-27T01:21:30.482102Z","shell.execute_reply":"2023-07-27T01:21:31.439809Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"cat_model = CatBoostClassifier(n_estimators=70, reg_lambda=0.01606738047167, colsample_bylevel=0.3, \n                              subsample=0.7, learning_rate=0.0865881098465479, \n                              max_depth=9, one_hot_max_size=10, random_state=seed, verbose=False).fit(X_train, y_train)\ncat = cat_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:31.441980Z","iopub.execute_input":"2023-07-27T01:21:31.442308Z","iopub.status.idle":"2023-07-27T01:21:33.575379Z","shell.execute_reply.started":"2023-07-27T01:21:31.442279Z","shell.execute_reply":"2023-07-27T01:21:33.574262Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"hgbc_model = HistGradientBoostingClassifier(max_iter=170, max_depth=4, min_samples_leaf=9,\n                                         learning_rate=0.17193627413211837, random_state=seed).fit(X_train, y_train)\nhgbc = hgbc_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:33.578048Z","iopub.execute_input":"2023-07-27T01:21:33.578480Z","iopub.status.idle":"2023-07-27T01:21:34.169979Z","shell.execute_reply.started":"2023-07-27T01:21:33.578441Z","shell.execute_reply":"2023-07-27T01:21:34.168935Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"dt_model = BaggedClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=500, max_samples=0.994711990802652,\n                           max_features=0.7844039008030275, bootstrap=False, bootstrap_features=True, random_state=seed).fit(X_train, y_train)\ndt = dt_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T05:35:34.376409Z","iopub.execute_input":"2023-07-27T05:35:34.376827Z","iopub.status.idle":"2023-07-27T05:35:34.416296Z","shell.execute_reply.started":"2023-07-27T05:35:34.376794Z","shell.execute_reply":"2023-07-27T05:35:34.414768Z"},"trusted":true},"execution_count":100,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[100], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dt_model \u001b[38;5;241m=\u001b[39m \u001b[43mBaggedClassifier\u001b[49m(base_estimator\u001b[38;5;241m=\u001b[39mDecisionTreeClassifier(), n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, max_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.994711990802652\u001b[39m,\n\u001b[1;32m      2\u001b[0m                            max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7844039008030275\u001b[39m, bootstrap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, bootstrap_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mseed)\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      3\u001b[0m dt \u001b[38;5;241m=\u001b[39m dt_model\u001b[38;5;241m.\u001b[39mpredict_proba(test\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m:])\n","\u001b[0;31mNameError\u001b[0m: name 'BaggedClassifier' is not defined"],"ename":"NameError","evalue":"name 'BaggedClassifier' is not defined","output_type":"error"}]},{"cell_type":"code","source":"rf_model = RandomForestClassifier(n_estimators=420, max_depth=13, min_samples_split=3, \n                                  min_samples_leaf=1, max_features=9, bootstrap=False, random_state=seed).fit(X_train, y_train)\nrf = rf_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:13.478497Z","iopub.execute_input":"2023-07-27T16:22:13.479049Z","iopub.status.idle":"2023-07-27T16:22:14.031895Z","shell.execute_reply.started":"2023-07-27T16:22:13.479002Z","shell.execute_reply":"2023-07-27T16:22:14.030282Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m \u001b[43mRandomForestClassifier\u001b[49m(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m420\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, \n\u001b[1;32m      2\u001b[0m                                   min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, bootstrap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mseed)\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      3\u001b[0m rf \u001b[38;5;241m=\u001b[39m rf_model\u001b[38;5;241m.\u001b[39mpredict_proba(test\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m:])\n","\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"],"ename":"NameError","evalue":"name 'RandomForestClassifier' is not defined","output_type":"error"}]},{"cell_type":"code","source":"def catboost_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 150, 10),\n        'reg_lambda': trial.suggest_loguniform('lambda', 1e-3, 0.1),\n        'colsample_bylevel': trial.suggest_categorical('colsample_bylevel', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'one_hot_max_size': trial.suggest_int('one_hot_max_size', 2, 10),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=CatBoostClassifier(**param, random_state=seed, verbose=False)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:34.171606Z","iopub.execute_input":"2023-07-27T01:21:34.172019Z","iopub.status.idle":"2023-07-27T01:21:34.179600Z","shell.execute_reply.started":"2023-07-27T01:21:34.171982Z","shell.execute_reply":"2023-07-27T01:21:34.178556Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"def xgb_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 0.1),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 0.1),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=xgboost.XGBClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:34.181055Z","iopub.execute_input":"2023-07-27T01:21:34.181561Z","iopub.status.idle":"2023-07-27T01:21:34.194131Z","shell.execute_reply.started":"2023-07-27T01:21:34.181523Z","shell.execute_reply":"2023-07-27T01:21:34.193168Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"def hgbc_meta(trial):\n    param = {\n        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 15),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'max_iter': trial.suggest_int('max_iter', 50, 200, 10),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=HistGradientBoostingClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:34.195918Z","iopub.execute_input":"2023-07-27T01:21:34.196350Z","iopub.status.idle":"2023-07-27T01:21:34.204872Z","shell.execute_reply.started":"2023-07-27T01:21:34.196312Z","shell.execute_reply":"2023-07-27T01:21:34.203891Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"def lgbm_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 0.1),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 0.1),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'num_leaves' : trial.suggest_int('num_leaves', 10, 50),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 50),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=lgb.LGBMClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:34.206567Z","iopub.execute_input":"2023-07-27T01:21:34.206954Z","iopub.status.idle":"2023-07-27T01:21:34.219218Z","shell.execute_reply.started":"2023-07-27T01:21:34.206920Z","shell.execute_reply":"2023-07-27T01:21:34.218354Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"stacking_cat_model = CatBoostClassifier(n_estimators=150, reg_lambda=0.05055956136270572, colsample_bylevel=0.6, \n                                        subsample=0.5, learning_rate=0.08699165501504001, max_depth=7, \n                                        one_hot_max_size=8, random_state=seed, verbose=False).fit(X_train, y_train)\nstacking_cat = stacking_cat_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:34.222864Z","iopub.execute_input":"2023-07-27T01:21:34.223287Z","iopub.status.idle":"2023-07-27T01:21:36.381200Z","shell.execute_reply.started":"2023-07-27T01:21:34.223239Z","shell.execute_reply":"2023-07-27T01:21:36.380243Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"stacking_xgb_model = xgboost.XGBClassifier(n_estimators=160, reg_lambda=0.030554982480056614, alpha=0.022993963306149747, \n                                           colsample_bytree=0.4, subsample=0.6, learning_rate=0.08378145372235492, \n                                           max_depth=17, min_child_weight=1, random_state=seed).fit(X_train, y_train)\nstacking_xgb = stacking_xgb_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:36.382748Z","iopub.execute_input":"2023-07-27T01:21:36.383146Z","iopub.status.idle":"2023-07-27T01:21:36.840304Z","shell.execute_reply.started":"2023-07-27T01:21:36.383109Z","shell.execute_reply":"2023-07-27T01:21:36.839433Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"stacking_lgbm_model = lgb.LGBMClassifier(n_estimators=130, reg_alpha=0.017987440901161444, reg_lambda=0.0010110144342120994, \n                                colsample_bytree=0.8, subsample=0.5, learning_rate=0.08786840365732179, \n                                max_depth=5, num_leaves=10, min_child_samples=48, random_state=seed).fit(X_train, y_train)\nstacking_lgbm = stacking_lgbm_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:36.841544Z","iopub.execute_input":"2023-07-27T01:21:36.841945Z","iopub.status.idle":"2023-07-27T01:21:37.193776Z","shell.execute_reply.started":"2023-07-27T01:21:36.841909Z","shell.execute_reply":"2023-07-27T01:21:37.192892Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"stacking_hgbc_model = HistGradientBoostingClassifier(learning_rate=0.9112141545526848, max_depth=5, min_samples_leaf=18, \n                                                     max_iter=160, random_state=seed).fit(X_train, y_train)\nstacking_hgbc = stacking_hgbc_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:37.195119Z","iopub.execute_input":"2023-07-27T01:21:37.195427Z","iopub.status.idle":"2023-07-27T01:21:37.472940Z","shell.execute_reply.started":"2023-07-27T01:21:37.195401Z","shell.execute_reply":"2023-07-27T01:21:37.472011Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import get_scorer_names","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:37.474519Z","iopub.execute_input":"2023-07-27T01:21:37.474915Z","iopub.status.idle":"2023-07-27T01:21:37.479716Z","shell.execute_reply.started":"2023-07-27T01:21:37.474878Z","shell.execute_reply":"2023-07-27T01:21:37.478667Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"print('CatBoostClassifier CV: ', CV(cat_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:37.481054Z","iopub.execute_input":"2023-07-27T01:21:37.481346Z","iopub.status.idle":"2023-07-27T01:21:58.393922Z","shell.execute_reply.started":"2023-07-27T01:21:37.481320Z","shell.execute_reply":"2023-07-27T01:21:58.392982Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"CatBoostClassifier CV:  0.03187018798730954\n","output_type":"stream"}]},{"cell_type":"code","source":"print('XGB Classifier CV: ', CV(xgb_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:58.398844Z","iopub.execute_input":"2023-07-27T01:21:58.399150Z","iopub.status.idle":"2023-07-27T01:22:02.234473Z","shell.execute_reply.started":"2023-07-27T01:21:58.399125Z","shell.execute_reply":"2023-07-27T01:22:02.233459Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"XGB Classifier CV:  0.039632181376836065\n","output_type":"stream"}]},{"cell_type":"code","source":"print('HGBC Classifier CV: ', CV(hgbc_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:22:02.235847Z","iopub.execute_input":"2023-07-27T01:22:02.236138Z","iopub.status.idle":"2023-07-27T01:22:07.647631Z","shell.execute_reply.started":"2023-07-27T01:22:02.236113Z","shell.execute_reply":"2023-07-27T01:22:07.646421Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"HGBC Classifier CV:  0.033823382091336264\n","output_type":"stream"}]},{"cell_type":"code","source":"print('LGBM Classifier CV: ', CV(lgbm_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:22:07.648936Z","iopub.execute_input":"2023-07-27T01:22:07.649328Z","iopub.status.idle":"2023-07-27T01:22:15.987765Z","shell.execute_reply.started":"2023-07-27T01:22:07.649297Z","shell.execute_reply":"2023-07-27T01:22:15.986772Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"LGBM Classifier CV:  0.025306527724138474\n","output_type":"stream"}]},{"cell_type":"code","source":"print('CatBoostClassifier Stacking CV: ', CV(stacking_cat_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:22:15.988809Z","iopub.execute_input":"2023-07-27T01:22:15.989101Z","iopub.status.idle":"2023-07-27T01:22:37.844159Z","shell.execute_reply.started":"2023-07-27T01:22:15.989075Z","shell.execute_reply":"2023-07-27T01:22:37.843447Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"CatBoostClassifier Stacking CV:  0.039181187006573734\n","output_type":"stream"}]},{"cell_type":"code","source":"print('XGB Classifier Stacking CV: ', CV(stacking_xgb_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:22:37.845380Z","iopub.execute_input":"2023-07-27T01:22:37.845961Z","iopub.status.idle":"2023-07-27T01:22:42.060985Z","shell.execute_reply.started":"2023-07-27T01:22:37.845931Z","shell.execute_reply":"2023-07-27T01:22:42.060258Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"XGB Classifier Stacking CV:  0.04641075838489262\n","output_type":"stream"}]},{"cell_type":"code","source":"print('LGBM Classifier Stacking CV: ', CV(stacking_lgbm_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:22:42.062078Z","iopub.execute_input":"2023-07-27T01:22:42.062572Z","iopub.status.idle":"2023-07-27T01:22:45.455758Z","shell.execute_reply.started":"2023-07-27T01:22:42.062544Z","shell.execute_reply":"2023-07-27T01:22:45.454095Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"LGBM Classifier Stacking CV:  0.046191199858464496\n","output_type":"stream"}]},{"cell_type":"code","source":"print('HGBC Classifier Stacking CV: ', CV(stacking_hgbc_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:22:45.457324Z","iopub.execute_input":"2023-07-27T01:22:45.457643Z","iopub.status.idle":"2023-07-27T01:22:47.969855Z","shell.execute_reply.started":"2023-07-27T01:22:45.457615Z","shell.execute_reply":"2023-07-27T01:22:47.968868Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"HGBC Classifier Stacking CV:  0.06376106326829557\n","output_type":"stream"}]},{"cell_type":"code","source":"#final.iloc[:, 1], final.iloc[:, -1] = stacking_cat_model.predict_proba(test.iloc[:, 1:])[:, 0], stacking_cat_model.predict_proba(test.iloc[:, 1:])[:, 1]\nfinal.iloc[:, 1] = cat[:, 0]\nfinal.iloc[:, -1] = cat[:, 1]\nfinal.to_csv('submission.csv', index=False)\nsubmission = pd.read_csv('submission.csv')\nsubmission","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:06:38.301329Z","iopub.execute_input":"2023-07-26T22:06:38.301836Z","iopub.status.idle":"2023-07-26T22:06:38.328866Z","shell.execute_reply.started":"2023-07-26T22:06:38.301791Z","shell.execute_reply":"2023-07-26T22:06:38.327618Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"             Id   class_0   class_1\n0  00eed32682bb  0.977403  0.022597\n1  010ebe33f668  0.977403  0.022597\n2  02fa521e1838  0.977403  0.022597\n3  040e15f562a2  0.977403  0.022597\n4  046e85c7cc7f  0.977403  0.022597","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>class_0</th>\n      <th>class_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00eed32682bb</td>\n      <td>0.977403</td>\n      <td>0.022597</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>010ebe33f668</td>\n      <td>0.977403</td>\n      <td>0.022597</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>02fa521e1838</td>\n      <td>0.977403</td>\n      <td>0.022597</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>040e15f562a2</td>\n      <td>0.977403</td>\n      <td>0.022597</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>046e85c7cc7f</td>\n      <td>0.977403</td>\n      <td>0.022597</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}