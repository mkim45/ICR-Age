{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nimport numpy as np\nimport pandas as pd\nimport warnings\ndef ignore_warn(*args,**kwargs):\n    pass\nwarnings.warn = ignore_warn\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport optuna\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score, KFold, train_test_split\nfrom sklearn.metrics import f1_score\nimport xgboost as xgboost\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, HistGradientBoostingClassifier, BaggingClassifier, StackingClassifier, VotingClassifier, GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.experimental import enable_hist_gradient_boosting  \nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.impute import KNNImputer","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:03:21.666354Z","iopub.execute_input":"2023-07-27T19:03:21.667350Z","iopub.status.idle":"2023-07-27T19:03:21.678172Z","shell.execute_reply.started":"2023-07-27T19:03:21.667304Z","shell.execute_reply":"2023-07-27T19:03:21.676982Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\ntest = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\nfinal = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.341364Z","iopub.execute_input":"2023-07-27T16:22:30.341742Z","iopub.status.idle":"2023-07-27T16:22:30.397262Z","shell.execute_reply.started":"2023-07-27T16:22:30.341708Z","shell.execute_reply":"2023-07-27T16:22:30.395913Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\ntrain.loc[:, 'EJ'] = encoder.fit_transform(train.loc[:, 'EJ'])\ntest.loc[:, 'EJ'] = encoder.fit_transform(test.loc[:, 'EJ'])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.399021Z","iopub.execute_input":"2023-07-27T16:22:30.399768Z","iopub.status.idle":"2023-07-27T16:22:30.414320Z","shell.execute_reply.started":"2023-07-27T16:22:30.399732Z","shell.execute_reply":"2023-07-27T16:22:30.412691Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"column_names = train.columns\nimputer = KNNImputer(n_neighbors = 10)\ntrain_no_id = imputer.fit_transform(train.drop(['Id'], axis = 1))\ntrain_no_id = pd.DataFrame(train_no_id)\ntrain = pd.concat([train['Id'], train_no_id], axis = 1)\ntrain.columns = column_names","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.417926Z","iopub.execute_input":"2023-07-27T16:22:30.418492Z","iopub.status.idle":"2023-07-27T16:22:30.486598Z","shell.execute_reply.started":"2023-07-27T16:22:30.418435Z","shell.execute_reply":"2023-07-27T16:22:30.484668Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#train.isna().sum().sort_values(ascending = False)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.488809Z","iopub.execute_input":"2023-07-27T16:22:30.489338Z","iopub.status.idle":"2023-07-27T16:22:30.506614Z","shell.execute_reply.started":"2023-07-27T16:22:30.489217Z","shell.execute_reply":"2023-07-27T16:22:30.498491Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\nseed = 617\nzero, one = np.bincount(train.loc[:, 'Class'])\none_df = train.iloc[(train.loc[:, 'Class'] == 1).tolist(), :] \nzero_df = train.iloc[(train.loc[:, 'Class'] == 0).tolist(), :]\nzero_df = zero_df.sample(n=one, random_state=seed)\noversampled_df = pd.concat([train.iloc[(train.loc[:, 'Class'] == 0).tolist(), :], one_df, one_df, one_df, one_df])\noversampled_df = oversampled_df.sample(frac=1, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.508578Z","iopub.execute_input":"2023-07-27T16:22:30.509195Z","iopub.status.idle":"2023-07-27T16:22:30.532060Z","shell.execute_reply.started":"2023-07-27T16:22:30.509131Z","shell.execute_reply":"2023-07-27T16:22:30.530387Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\ndef balanced_log_loss(y_true, y_pred):\n    N_0 = np.sum(1 - y_true)\n    N_1 = np.sum(y_true)\n    w_0 = 1 / N_0\n    w_1 = 1 / N_1\n    p_1 = np.clip(y_pred[:, 1], 1e-15, 1-1e-15)\n    p_0 = 1 - p_1\n    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\n    log_loss_1 = -np.sum(y_true * np.log(p_1))\n    balanced_log_loss = (w_0 * log_loss_0 + w_1 * log_loss_1) / 2\n    return balanced_log_loss","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.534128Z","iopub.execute_input":"2023-07-27T16:22:30.535029Z","iopub.status.idle":"2023-07-27T16:22:30.549707Z","shell.execute_reply.started":"2023-07-27T16:22:30.534985Z","shell.execute_reply":"2023-07-27T16:22:30.548130Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\nn_folds = 10\ndef CV(model, data, loss_function):\n    skf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n    kfold = skf.split(data.iloc[:, 1:-1], data.iloc[:, -1])\n    losses = []\n    for (train_id, val_id) in kfold:\n        x_train = data.iloc[train_id, 1:-1]\n        y_train = data.iloc[train_id, -1]\n        x_val = data.iloc[val_id, 1:-1]\n        y_val = data.iloc[val_id, -1]\n        model.fit(x_train, y_train)\n        pred_val = model.predict_proba(x_val)\n        loss = loss_function(y_val, pred_val)\n        losses.append(loss)\n    return np.sum(losses) / n_folds","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.551722Z","iopub.execute_input":"2023-07-27T16:22:30.553025Z","iopub.status.idle":"2023-07-27T16:22:30.568058Z","shell.execute_reply.started":"2023-07-27T16:22:30.552981Z","shell.execute_reply":"2023-07-27T16:22:30.566279Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_train = oversampled_df.drop(columns=['Class', 'Id'])\ny_train = oversampled_df['Class']","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.569904Z","iopub.execute_input":"2023-07-27T16:22:30.570693Z","iopub.status.idle":"2023-07-27T16:22:30.583119Z","shell.execute_reply.started":"2023-07-27T16:22:30.570650Z","shell.execute_reply":"2023-07-27T16:22:30.581887Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.587195Z","iopub.execute_input":"2023-07-27T16:22:30.587549Z","iopub.status.idle":"2023-07-27T16:22:30.597557Z","shell.execute_reply.started":"2023-07-27T16:22:30.587521Z","shell.execute_reply":"2023-07-27T16:22:30.596522Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def xgb(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),\n    }\n    model = xgb.XGBClassifier(**param, random_state = seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:30.599169Z","iopub.execute_input":"2023-07-27T16:22:30.601055Z","iopub.status.idle":"2023-07-27T16:22:30.617509Z","shell.execute_reply.started":"2023-07-27T16:22:30.601005Z","shell.execute_reply":"2023-07-27T16:22:30.616470Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def lgbm(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'num_leaves' : trial.suggest_int('num_leaves', 10, 50),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 50),\n    }\n    model = lgb.LGBMClassifier(**param, random_state = seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:31.665421Z","iopub.execute_input":"2023-07-27T16:22:31.666104Z","iopub.status.idle":"2023-07-27T16:22:31.674720Z","shell.execute_reply.started":"2023-07-27T16:22:31.666071Z","shell.execute_reply":"2023-07-27T16:22:31.673789Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def catboost(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 150, 10),\n        'reg_lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'colsample_bylevel': trial.suggest_categorical('colsample_bylevel', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'one_hot_max_size': trial.suggest_int('one_hot_max_size', 2, 10),\n    }\n    model = CatBoostClassifier(**param, random_seed=seed, verbose=False)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:31.790674Z","iopub.execute_input":"2023-07-27T16:22:31.791513Z","iopub.status.idle":"2023-07-27T16:22:31.800676Z","shell.execute_reply.started":"2023-07-27T16:22:31.791465Z","shell.execute_reply":"2023-07-27T16:22:31.799841Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def hgbc(trial):\n    param = {\n        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 15),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'max_iter': trial.suggest_int('max_iter', 50, 200, 10),\n    }\n    model = HistGradientBoostingClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:31.933454Z","iopub.execute_input":"2023-07-27T16:22:31.933891Z","iopub.status.idle":"2023-07-27T16:22:31.941049Z","shell.execute_reply.started":"2023-07-27T16:22:31.933855Z","shell.execute_reply":"2023-07-27T16:22:31.939867Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def bagged_dt(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 400, 600, 20),\n        'max_samples': trial.suggest_float('max_samples', 1e-2, 1.0),\n        'max_features': trial.suggest_float('max_features', 1e-2, 1.0),\n        'bootstrap': trial.suggest_categorical('bootstrap', [False, True]),\n        'bootstrap_features': trial.suggest_categorical('bootstrap_features', [False, True]),\n    }\n    model = BaggingClassifier(**param, base_estimator=DecisionTreeClassifier(), random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:32.047823Z","iopub.execute_input":"2023-07-27T16:22:32.048765Z","iopub.status.idle":"2023-07-27T16:22:32.056434Z","shell.execute_reply.started":"2023-07-27T16:22:32.048728Z","shell.execute_reply":"2023-07-27T16:22:32.055159Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def rf(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 300, 500, 20),\n        'max_depth': trial.suggest_int('max_depth', 5, 25),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'max_features': trial.suggest_int('max_features', 1, 56),\n        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n    }\n    model = RandomForestClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:33.222206Z","iopub.execute_input":"2023-07-27T16:22:33.222626Z","iopub.status.idle":"2023-07-27T16:22:33.231769Z","shell.execute_reply.started":"2023-07-27T16:22:33.222593Z","shell.execute_reply":"2023-07-27T16:22:33.230601Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def adaboost(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 400, 500, 20),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.0001, 1),\n        'base_estimator': DecisionTreeClassifier(max_depth=trial.suggest_int('max_depth', 1, 20)),\n    }\n    model = AdaBoostClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:30:17.465065Z","iopub.execute_input":"2023-07-27T16:30:17.465494Z","iopub.status.idle":"2023-07-27T16:30:17.473759Z","shell.execute_reply.started":"2023-07-27T16:30:17.465463Z","shell.execute_reply":"2023-07-27T16:30:17.472310Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def gradient(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 10, 500, 20),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.0001, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'subsample': trial.suggest_float('subsample', 0.3, 1.0),\n    }\n    model = GradientBoostingClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:32:29.844801Z","iopub.execute_input":"2023-07-27T16:32:29.845266Z","iopub.status.idle":"2023-07-27T16:32:29.853630Z","shell.execute_reply.started":"2023-07-27T16:32:29.845233Z","shell.execute_reply":"2023-07-27T16:32:29.852612Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n\nstudy1 = optuna.create_study(direction='minimize', study_name=\"GradientBoost\")\nn_trials = 75\nstudy1.optimize(gradient, n_trials=n_trials)\nprint('Best trial:', study1.best_trial.params)\nprint('Best values:', study1.best_value)\n\nend = time.time()\nprint('It has taken {:.5f} seconds to search for the best Hyperparameter'.format(end-start))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T19:03:24.733234Z","iopub.execute_input":"2023-07-27T19:03:24.733631Z","iopub.status.idle":"2023-07-27T19:38:53.764741Z","shell.execute_reply.started":"2023-07-27T19:03:24.733600Z","shell.execute_reply":"2023-07-27T19:38:53.763662Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"[I 2023-07-27 19:03:24,736] A new study created in memory with name: GradientBoost\n[I 2023-07-27 19:04:05,215] Trial 0 finished with value: 0.14713156158443152 and parameters: {'n_estimators': 410, 'learning_rate': 0.007766491017101594, 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 20, 'subsample': 0.510926795863775}. Best is trial 0 with value: 0.14713156158443152.\n[I 2023-07-27 19:06:08,904] Trial 1 finished with value: 0.05498565520656702 and parameters: {'n_estimators': 410, 'learning_rate': 0.016083554634466653, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.8101817694133795}. Best is trial 1 with value: 0.05498565520656702.\n[I 2023-07-27 19:06:30,180] Trial 2 finished with value: 0.5326156821052395 and parameters: {'n_estimators': 350, 'learning_rate': 0.0010407764075513993, 'max_depth': 20, 'min_samples_split': 15, 'min_samples_leaf': 16, 'subsample': 0.3109205349427021}. Best is trial 1 with value: 0.05498565520656702.\n[I 2023-07-27 19:08:00,691] Trial 3 finished with value: 0.13167962359460872 and parameters: {'n_estimators': 370, 'learning_rate': 0.006810747147870023, 'max_depth': 15, 'min_samples_split': 11, 'min_samples_leaf': 14, 'subsample': 0.950499587252897}. Best is trial 1 with value: 0.05498565520656702.\n[I 2023-07-27 19:08:23,799] Trial 4 finished with value: 0.19909886926167586 and parameters: {'n_estimators': 310, 'learning_rate': 0.009652366894325113, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5791167859595536}. Best is trial 1 with value: 0.05498565520656702.\n[I 2023-07-27 19:09:50,408] Trial 5 finished with value: 0.4974425864894809 and parameters: {'n_estimators': 390, 'learning_rate': 0.0008444546545450452, 'max_depth': 13, 'min_samples_split': 11, 'min_samples_leaf': 4, 'subsample': 0.6441071822880503}. Best is trial 1 with value: 0.05498565520656702.\n[I 2023-07-27 19:10:35,006] Trial 6 finished with value: 0.5834008397236943 and parameters: {'n_estimators': 250, 'learning_rate': 0.0007506973908199785, 'max_depth': 13, 'min_samples_split': 10, 'min_samples_leaf': 15, 'subsample': 0.7581972290489345}. Best is trial 1 with value: 0.05498565520656702.\n[I 2023-07-27 19:10:47,707] Trial 7 finished with value: 0.0560732815246884 and parameters: {'n_estimators': 170, 'learning_rate': 0.05826552587019143, 'max_depth': 4, 'min_samples_split': 13, 'min_samples_leaf': 15, 'subsample': 0.470988143896409}. Best is trial 1 with value: 0.05498565520656702.\n[I 2023-07-27 19:11:07,673] Trial 8 finished with value: 0.08439549025811542 and parameters: {'n_estimators': 170, 'learning_rate': 0.02871557484851138, 'max_depth': 10, 'min_samples_split': 17, 'min_samples_leaf': 3, 'subsample': 0.38011003155088724}. Best is trial 1 with value: 0.05498565520656702.\n[I 2023-07-27 19:12:06,672] Trial 9 finished with value: 0.26068385796088717 and parameters: {'n_estimators': 310, 'learning_rate': 0.003735702536289983, 'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 6, 'subsample': 0.7676895939144369}. Best is trial 1 with value: 0.05498565520656702.\n[I 2023-07-27 19:12:16,486] Trial 10 finished with value: 0.0673360966308324 and parameters: {'n_estimators': 30, 'learning_rate': 0.48119959517137695, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 8, 'subsample': 0.9754536019236146}. Best is trial 1 with value: 0.05498565520656702.\n[I 2023-07-27 19:12:24,664] Trial 11 finished with value: 0.08248731411711087 and parameters: {'n_estimators': 130, 'learning_rate': 0.06987232795852034, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 11, 'subsample': 0.46525880216001575}. Best is trial 1 with value: 0.05498565520656702.\n[I 2023-07-27 19:13:42,359] Trial 12 finished with value: 0.06526714858664828 and parameters: {'n_estimators': 470, 'learning_rate': 0.05700787675549286, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 10, 'subsample': 0.731685600611854}. Best is trial 1 with value: 0.05498565520656702.\n[I 2023-07-27 19:14:11,154] Trial 13 finished with value: 0.6762069238779691 and parameters: {'n_estimators': 190, 'learning_rate': 0.00015902573179156062, 'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 19, 'subsample': 0.8442061864532432}. Best is trial 1 with value: 0.05498565520656702.\n[I 2023-07-27 19:14:22,692] Trial 14 finished with value: 0.07122394479759629 and parameters: {'n_estimators': 70, 'learning_rate': 0.17948767526421844, 'max_depth': 17, 'min_samples_split': 19, 'min_samples_leaf': 12, 'subsample': 0.574464521928505}. Best is trial 1 with value: 0.05498565520656702.\n[I 2023-07-27 19:14:38,198] Trial 15 finished with value: 1.7454585808672818 and parameters: {'n_estimators': 250, 'learning_rate': 0.7752622690074847, 'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 6, 'subsample': 0.4376039742645852}. Best is trial 1 with value: 0.05498565520656702.\n[I 2023-07-27 19:17:16,579] Trial 20 finished with value: 0.0664472163261241 and parameters: {'n_estimators': 230, 'learning_rate': 0.018899915130532432, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.8066699785472694}. Best is trial 17 with value: 0.04257149823946408.\n[I 2023-07-27 19:17:37,775] Trial 21 finished with value: 0.04688660124571962 and parameters: {'n_estimators': 130, 'learning_rate': 0.09774183246837273, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 18, 'subsample': 0.9998525688500295}. Best is trial 17 with value: 0.04257149823946408.\n[I 2023-07-27 19:17:56,673] Trial 22 finished with value: 0.0456691722102003 and parameters: {'n_estimators': 90, 'learning_rate': 0.09339262851987441, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 17, 'subsample': 0.9999309238607765}. Best is trial 17 with value: 0.04257149823946408.\n[I 2023-07-27 19:18:14,494] Trial 23 finished with value: 0.04492656849125939 and parameters: {'n_estimators': 110, 'learning_rate': 0.11268877266628402, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 18, 'subsample': 0.9936277345542882}. Best is trial 17 with value: 0.04257149823946408.\n[I 2023-07-27 19:18:28,514] Trial 24 finished with value: 0.06336115346222179 and parameters: {'n_estimators': 70, 'learning_rate': 0.362289818141922, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 18, 'subsample': 0.9200527590478074}. Best is trial 17 with value: 0.04257149823946408.\n[I 2023-07-27 19:18:36,336] Trial 25 finished with value: 0.0842721934325464 and parameters: {'n_estimators': 90, 'learning_rate': 0.8710608192172481, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 16, 'subsample': 0.9287662239610349}. Best is trial 17 with value: 0.04257149823946408.\n[I 2023-07-27 19:18:57,119] Trial 26 finished with value: 0.04515465427055286 and parameters: {'n_estimators': 130, 'learning_rate': 0.12306748561534864, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 20, 'subsample': 0.9904299339489634}. Best is trial 17 with value: 0.04257149823946408.\n[I 2023-07-27 19:19:13,735] Trial 27 finished with value: 0.054410634017279705 and parameters: {'n_estimators': 130, 'learning_rate': 0.35642425986718845, 'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 20, 'subsample': 0.9043490308800373}. Best is trial 17 with value: 0.04257149823946408.\n[I 2023-07-27 19:19:39,002] Trial 28 finished with value: 0.04813021290675199 and parameters: {'n_estimators': 190, 'learning_rate': 0.15267598855905756, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 20, 'subsample': 0.9515389129423163}. Best is trial 17 with value: 0.04257149823946408.\n[I 2023-07-27 19:19:44,200] Trial 29 finished with value: 0.255854527744835 and parameters: {'n_estimators': 30, 'learning_rate': 0.04401381018475628, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 13, 'subsample': 0.8835255956173125}. Best is trial 17 with value: 0.04257149823946408.\n[I 2023-07-27 19:20:15,827] Trial 30 finished with value: 0.046212685618705944 and parameters: {'n_estimators': 150, 'learning_rate': 0.09631870424482113, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 19, 'subsample': 0.9443061371799831}. Best is trial 17 with value: 0.04257149823946408.\n[I 2023-07-27 19:20:33,335] Trial 31 finished with value: 0.042272604685617644 and parameters: {'n_estimators': 90, 'learning_rate': 0.1186374370652166, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 17, 'subsample': 0.9645010590647618}. Best is trial 31 with value: 0.042272604685617644.\n[I 2023-07-27 19:20:40,215] Trial 32 finished with value: 0.06307709623329007 and parameters: {'n_estimators': 50, 'learning_rate': 0.14177411837080375, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 18, 'subsample': 0.96957678507048}. Best is trial 31 with value: 0.042272604685617644.\n[I 2023-07-27 19:20:59,109] Trial 33 finished with value: 0.0742066609085327 and parameters: {'n_estimators': 110, 'learning_rate': 0.29135339903072366, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 16, 'subsample': 0.9086833640080366}. Best is trial 31 with value: 0.042272604685617644.\n[I 2023-07-27 19:21:12,130] Trial 34 finished with value: 0.05212473589795097 and parameters: {'n_estimators': 210, 'learning_rate': 0.5271335396212139, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 20, 'subsample': 0.9946942799835322}. Best is trial 31 with value: 0.042272604685617644.\n[I 2023-07-27 19:21:17,122] Trial 35 finished with value: 0.2474008983202718 and parameters: {'n_estimators': 50, 'learning_rate': 0.045007761058612844, 'max_depth': 3, 'min_samples_split': 12, 'min_samples_leaf': 14, 'subsample': 0.846419064911382}. Best is trial 31 with value: 0.042272604685617644.\n[I 2023-07-27 19:22:03,093] Trial 36 finished with value: 0.065356661149674 and parameters: {'n_estimators': 290, 'learning_rate': 0.11848670407743102, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 17, 'subsample': 0.9503618142401701}. Best is trial 31 with value: 0.042272604685617644.\n[I 2023-07-27 19:22:24,658] Trial 37 finished with value: 0.06875812663155403 and parameters: {'n_estimators': 150, 'learning_rate': 0.271371260913008, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 15, 'subsample': 0.9307603507947675}. Best is trial 31 with value: 0.042272604685617644.\n[I 2023-07-27 19:22:37,707] Trial 38 finished with value: 0.04939840188974523 and parameters: {'n_estimators': 90, 'learning_rate': 0.16556820255691956, 'max_depth': 5, 'min_samples_split': 11, 'min_samples_leaf': 19, 'subsample': 0.8705007426713703}. Best is trial 31 with value: 0.042272604685617644.\n[I 2023-07-27 19:22:49,517] Trial 39 finished with value: 0.3114908050792915 and parameters: {'n_estimators': 110, 'learning_rate': 0.013907810022116024, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 14, 'subsample': 0.9586109473666286}. Best is trial 31 with value: 0.042272604685617644.\n[I 2023-07-27 19:23:22,522] Trial 40 finished with value: 0.0519018404132953 and parameters: {'n_estimators': 170, 'learning_rate': 0.03704421410027024, 'max_depth': 12, 'min_samples_split': 12, 'min_samples_leaf': 16, 'subsample': 0.8240222225762885}. Best is trial 31 with value: 0.042272604685617644.\n[I 2023-07-27 19:23:24,446] Trial 41 finished with value: 0.3574262145606828 and parameters: {'n_estimators': 10, 'learning_rate': 0.08058263912328212, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 17, 'subsample': 0.9955797108805986}. Best is trial 31 with value: 0.042272604685617644.\n[I 2023-07-27 19:23:39,417] Trial 42 finished with value: 0.05852723291442811 and parameters: {'n_estimators': 70, 'learning_rate': 0.08024170546558623, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 18, 'subsample': 0.9949796968573479}. Best is trial 31 with value: 0.042272604685617644.\n[I 2023-07-27 19:23:59,119] Trial 43 finished with value: 0.04178679839127935 and parameters: {'n_estimators': 150, 'learning_rate': 0.12898051861821774, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 15, 'subsample': 0.9092871654703928}. Best is trial 43 with value: 0.04178679839127935.\n[I 2023-07-27 19:24:13,423] Trial 44 finished with value: 0.06457473826714612 and parameters: {'n_estimators': 110, 'learning_rate': 0.0600418917286213, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 12, 'subsample': 0.9009748972798313}. Best is trial 43 with value: 0.04178679839127935.\n[I 2023-07-27 19:24:33,193] Trial 45 finished with value: 0.051989115080401105 and parameters: {'n_estimators': 150, 'learning_rate': 0.2288218213476895, 'max_depth': 4, 'min_samples_split': 11, 'min_samples_leaf': 14, 'subsample': 0.9263119090342405}. Best is trial 43 with value: 0.04178679839127935.\n[I 2023-07-27 19:25:11,607] Trial 46 finished with value: 0.06389708538389842 and parameters: {'n_estimators': 210, 'learning_rate': 0.13756947384750448, 'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 15, 'subsample': 0.964857867304155}. Best is trial 43 with value: 0.04178679839127935.\n[I 2023-07-27 19:25:26,692] Trial 47 finished with value: 0.07544221434157819 and parameters: {'n_estimators': 130, 'learning_rate': 0.3914492523812893, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 19, 'subsample': 0.8760049511091184}. Best is trial 43 with value: 0.04178679839127935.\n[I 2023-07-27 19:25:32,192] Trial 48 finished with value: 0.05523503591985388 and parameters: {'n_estimators': 50, 'learning_rate': 0.6063520025302728, 'max_depth': 3, 'min_samples_split': 13, 'min_samples_leaf': 13, 'subsample': 0.9645768793580836}. Best is trial 43 with value: 0.04178679839127935.\n[I 2023-07-27 19:26:02,119] Trial 49 finished with value: 0.03958453923730886 and parameters: {'n_estimators': 170, 'learning_rate': 0.05893342084840253, 'max_depth': 6, 'min_samples_split': 16, 'min_samples_leaf': 11, 'subsample': 0.9112739951878389}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:26:45,013] Trial 50 finished with value: 0.04698613282929806 and parameters: {'n_estimators': 270, 'learning_rate': 0.02788911621366997, 'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 11, 'subsample': 0.809065083813558}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:27:10,059] Trial 51 finished with value: 0.04298543349006068 and parameters: {'n_estimators': 190, 'learning_rate': 0.06319935708491309, 'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 10, 'subsample': 0.9169180644700636}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:27:34,511] Trial 52 finished with value: 0.04328826951959095 and parameters: {'n_estimators': 190, 'learning_rate': 0.06986432085688143, 'max_depth': 4, 'min_samples_split': 18, 'min_samples_leaf': 10, 'subsample': 0.8894557894630684}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:27:58,236] Trial 53 finished with value: 0.04104568451190207 and parameters: {'n_estimators': 190, 'learning_rate': 0.06446927519828431, 'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 10, 'subsample': 0.8544004901458087}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:28:20,793] Trial 54 finished with value: 0.07518636507820915 and parameters: {'n_estimators': 230, 'learning_rate': 0.040127204599416044, 'max_depth': 3, 'min_samples_split': 20, 'min_samples_leaf': 9, 'subsample': 0.849137633270865}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:28:40,448] Trial 55 finished with value: 0.13779632783837756 and parameters: {'n_estimators': 170, 'learning_rate': 0.018766762946321323, 'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 9, 'subsample': 0.7811989276115823}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:29:19,168] Trial 56 finished with value: 0.04594725945898865 and parameters: {'n_estimators': 210, 'learning_rate': 0.051580208152021884, 'max_depth': 7, 'min_samples_split': 19, 'min_samples_leaf': 12, 'subsample': 0.8610087561662253}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:29:46,555] Trial 57 finished with value: 0.06133392128046049 and parameters: {'n_estimators': 350, 'learning_rate': 0.1912447658320627, 'max_depth': 6, 'min_samples_split': 16, 'min_samples_leaf': 8, 'subsample': 0.9041556152329845}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:30:17,093] Trial 58 finished with value: 0.039719763963619543 and parameters: {'n_estimators': 230, 'learning_rate': 0.059500070856928995, 'max_depth': 4, 'min_samples_split': 18, 'min_samples_leaf': 10, 'subsample': 0.92343459799282}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:31:10,264] Trial 59 finished with value: 0.04980557745305334 and parameters: {'n_estimators': 230, 'learning_rate': 0.033591469346770736, 'max_depth': 15, 'min_samples_split': 18, 'min_samples_leaf': 11, 'subsample': 0.8365962742761706}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:33:12,444] Trial 62 finished with value: 0.04521397898973829 and parameters: {'n_estimators': 250, 'learning_rate': 0.10531968156466247, 'max_depth': 3, 'min_samples_split': 19, 'min_samples_leaf': 8, 'subsample': 0.9354138407778246}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:33:39,590] Trial 63 finished with value: 0.04663207372333385 and parameters: {'n_estimators': 170, 'learning_rate': 0.07292558830810983, 'max_depth': 5, 'min_samples_split': 18, 'min_samples_leaf': 11, 'subsample': 0.9403208110540278}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:34:04,727] Trial 64 finished with value: 0.04518645791780941 and parameters: {'n_estimators': 150, 'learning_rate': 0.05356450940329418, 'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 12, 'subsample': 0.8654215796407354}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:34:32,444] Trial 65 finished with value: 0.05912112004107587 and parameters: {'n_estimators': 210, 'learning_rate': 0.1971527258111787, 'max_depth': 4, 'min_samples_split': 19, 'min_samples_leaf': 7, 'subsample': 0.9058700469080855}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:35:31,665] Trial 66 finished with value: 0.06511743066336229 and parameters: {'n_estimators': 430, 'learning_rate': 0.08656495949856172, 'max_depth': 5, 'min_samples_split': 16, 'min_samples_leaf': 10, 'subsample': 0.9698824209978234}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:35:50,089] Trial 67 finished with value: 0.04346488882751705 and parameters: {'n_estimators': 190, 'learning_rate': 0.1327204830440603, 'max_depth': 3, 'min_samples_split': 17, 'min_samples_leaf': 9, 'subsample': 0.8218606866344884}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:36:32,845] Trial 68 finished with value: 0.04312482089200527 and parameters: {'n_estimators': 250, 'learning_rate': 0.05265603059733294, 'max_depth': 6, 'min_samples_split': 18, 'min_samples_leaf': 13, 'subsample': 0.8928423481063146}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:36:54,468] Trial 69 finished with value: 0.0760079179248968 and parameters: {'n_estimators': 230, 'learning_rate': 0.25993844427344526, 'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 11, 'subsample': 0.9214234256123042}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:37:23,752] Trial 70 finished with value: 0.050302710631188165 and parameters: {'n_estimators': 170, 'learning_rate': 0.11776247584765884, 'max_depth': 7, 'min_samples_split': 19, 'min_samples_leaf': 12, 'subsample': 0.7895042210059108}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:37:48,871] Trial 71 finished with value: 0.04053749881431594 and parameters: {'n_estimators': 190, 'learning_rate': 0.07192545543650553, 'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 10, 'subsample': 0.918134505428054}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:38:09,198] Trial 72 finished with value: 0.04555136256128779 and parameters: {'n_estimators': 150, 'learning_rate': 0.16454084956020226, 'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 9, 'subsample': 0.9461163596070453}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:38:29,182] Trial 73 finished with value: 0.040369983548185565 and parameters: {'n_estimators': 130, 'learning_rate': 0.09256888507325003, 'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 10, 'subsample': 0.8775946857901762}. Best is trial 49 with value: 0.03958453923730886.\n[I 2023-07-27 19:38:53,759] Trial 74 finished with value: 0.04526618003258006 and parameters: {'n_estimators': 190, 'learning_rate': 0.09259387123875217, 'max_depth': 4, 'min_samples_split': 19, 'min_samples_leaf': 5, 'subsample': 0.8841226845207786}. Best is trial 49 with value: 0.03958453923730886.\n","output_type":"stream"},{"name":"stdout","text":"Best trial: {'n_estimators': 170, 'learning_rate': 0.05893342084840253, 'max_depth': 6, 'min_samples_split': 16, 'min_samples_leaf': 11, 'subsample': 0.9112739951878389}\nBest values: 0.03958453923730886\nIt has taken 2129.02435 seconds to search for the best Hyperparameter\n","output_type":"stream"}]},{"cell_type":"code","source":"xgb_model = xgboost.XGBClassifier(n_estimators=200, reg_lambda=0.15325900166549988, reg_alpha=0.0044700650580230235, \n                              colsample_bytree=0.3, subsample=1.0, learning_rate=0.09975673376458177, \n                              max_depth=11, min_child_weight=2, random_state=seed).fit(X_train, y_train)\nxgb = xgb_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:30.183146Z","iopub.execute_input":"2023-07-27T01:21:30.183543Z","iopub.status.idle":"2023-07-27T01:21:30.479940Z","shell.execute_reply.started":"2023-07-27T01:21:30.183505Z","shell.execute_reply":"2023-07-27T01:21:30.479081Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"lgbm_model = lgb.LGBMClassifier(n_estimators=200, reg_alpha=0.0016725623110267532, reg_lambda=0.0038043774323061946, \n                                 colsample_bytree=0.3, subsample=0.4, learning_rate=0.09367295744238123, max_depth=11, \n                                 num_leaves=50, min_child_samples=26, random_state=seed).fit(X_train, y_train)\nlgbm = lgbm_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:30.481599Z","iopub.execute_input":"2023-07-27T01:21:30.482132Z","iopub.status.idle":"2023-07-27T01:21:31.440791Z","shell.execute_reply.started":"2023-07-27T01:21:30.482102Z","shell.execute_reply":"2023-07-27T01:21:31.439809Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"cat_model = CatBoostClassifier(n_estimators=70, reg_lambda=0.01606738047167, colsample_bylevel=0.3, \n                              subsample=0.7, learning_rate=0.0865881098465479, \n                              max_depth=9, one_hot_max_size=10, random_state=seed, verbose=False).fit(X_train, y_train)\ncat = cat_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:31.441980Z","iopub.execute_input":"2023-07-27T01:21:31.442308Z","iopub.status.idle":"2023-07-27T01:21:33.575379Z","shell.execute_reply.started":"2023-07-27T01:21:31.442279Z","shell.execute_reply":"2023-07-27T01:21:33.574262Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"hgbc_model = HistGradientBoostingClassifier(max_iter=170, max_depth=4, min_samples_leaf=9,\n                                         learning_rate=0.17193627413211837, random_state=seed).fit(X_train, y_train)\nhgbc = hgbc_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:33.578048Z","iopub.execute_input":"2023-07-27T01:21:33.578480Z","iopub.status.idle":"2023-07-27T01:21:34.169979Z","shell.execute_reply.started":"2023-07-27T01:21:33.578441Z","shell.execute_reply":"2023-07-27T01:21:34.168935Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"dt_model = BaggedClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=500, max_samples=0.994711990802652,\n                           max_features=0.7844039008030275, bootstrap=False, bootstrap_features=True, random_state=seed).fit(X_train, y_train)\ndt = dt_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T05:35:34.376409Z","iopub.execute_input":"2023-07-27T05:35:34.376827Z","iopub.status.idle":"2023-07-27T05:35:34.416296Z","shell.execute_reply.started":"2023-07-27T05:35:34.376794Z","shell.execute_reply":"2023-07-27T05:35:34.414768Z"},"trusted":true},"execution_count":100,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[100], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dt_model \u001b[38;5;241m=\u001b[39m \u001b[43mBaggedClassifier\u001b[49m(base_estimator\u001b[38;5;241m=\u001b[39mDecisionTreeClassifier(), n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, max_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.994711990802652\u001b[39m,\n\u001b[1;32m      2\u001b[0m                            max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7844039008030275\u001b[39m, bootstrap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, bootstrap_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mseed)\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      3\u001b[0m dt \u001b[38;5;241m=\u001b[39m dt_model\u001b[38;5;241m.\u001b[39mpredict_proba(test\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m:])\n","\u001b[0;31mNameError\u001b[0m: name 'BaggedClassifier' is not defined"],"ename":"NameError","evalue":"name 'BaggedClassifier' is not defined","output_type":"error"}]},{"cell_type":"code","source":"rf_model = RandomForestClassifier(n_estimators=420, max_depth=13, min_samples_split=3, \n                                  min_samples_leaf=1, max_features=9, bootstrap=False, random_state=seed).fit(X_train, y_train)\nrf = rf_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T16:22:13.478497Z","iopub.execute_input":"2023-07-27T16:22:13.479049Z","iopub.status.idle":"2023-07-27T16:22:14.031895Z","shell.execute_reply.started":"2023-07-27T16:22:13.479002Z","shell.execute_reply":"2023-07-27T16:22:14.030282Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m \u001b[43mRandomForestClassifier\u001b[49m(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m420\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, \n\u001b[1;32m      2\u001b[0m                                   min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, bootstrap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mseed)\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      3\u001b[0m rf \u001b[38;5;241m=\u001b[39m rf_model\u001b[38;5;241m.\u001b[39mpredict_proba(test\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m:])\n","\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"],"ename":"NameError","evalue":"name 'RandomForestClassifier' is not defined","output_type":"error"}]},{"cell_type":"code","source":"def catboost_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 150, 10),\n        'reg_lambda': trial.suggest_loguniform('lambda', 1e-3, 0.1),\n        'colsample_bylevel': trial.suggest_categorical('colsample_bylevel', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'one_hot_max_size': trial.suggest_int('one_hot_max_size', 2, 10),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=CatBoostClassifier(**param, random_state=seed, verbose=False)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:34.171606Z","iopub.execute_input":"2023-07-27T01:21:34.172019Z","iopub.status.idle":"2023-07-27T01:21:34.179600Z","shell.execute_reply.started":"2023-07-27T01:21:34.171982Z","shell.execute_reply":"2023-07-27T01:21:34.178556Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"def xgb_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 0.1),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 0.1),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=xgboost.XGBClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:34.181055Z","iopub.execute_input":"2023-07-27T01:21:34.181561Z","iopub.status.idle":"2023-07-27T01:21:34.194131Z","shell.execute_reply.started":"2023-07-27T01:21:34.181523Z","shell.execute_reply":"2023-07-27T01:21:34.193168Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"def hgbc_meta(trial):\n    param = {\n        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 15),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'max_iter': trial.suggest_int('max_iter', 50, 200, 10),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=HistGradientBoostingClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:34.195918Z","iopub.execute_input":"2023-07-27T01:21:34.196350Z","iopub.status.idle":"2023-07-27T01:21:34.204872Z","shell.execute_reply.started":"2023-07-27T01:21:34.196312Z","shell.execute_reply":"2023-07-27T01:21:34.203891Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"def lgbm_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 0.1),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 0.1),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'num_leaves' : trial.suggest_int('num_leaves', 10, 50),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 50),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=lgb.LGBMClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:34.206567Z","iopub.execute_input":"2023-07-27T01:21:34.206954Z","iopub.status.idle":"2023-07-27T01:21:34.219218Z","shell.execute_reply.started":"2023-07-27T01:21:34.206920Z","shell.execute_reply":"2023-07-27T01:21:34.218354Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"stacking_cat_model = CatBoostClassifier(n_estimators=150, reg_lambda=0.05055956136270572, colsample_bylevel=0.6, \n                                        subsample=0.5, learning_rate=0.08699165501504001, max_depth=7, \n                                        one_hot_max_size=8, random_state=seed, verbose=False).fit(X_train, y_train)\nstacking_cat = stacking_cat_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:34.222864Z","iopub.execute_input":"2023-07-27T01:21:34.223287Z","iopub.status.idle":"2023-07-27T01:21:36.381200Z","shell.execute_reply.started":"2023-07-27T01:21:34.223239Z","shell.execute_reply":"2023-07-27T01:21:36.380243Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"stacking_xgb_model = xgboost.XGBClassifier(n_estimators=160, reg_lambda=0.030554982480056614, alpha=0.022993963306149747, \n                                           colsample_bytree=0.4, subsample=0.6, learning_rate=0.08378145372235492, \n                                           max_depth=17, min_child_weight=1, random_state=seed).fit(X_train, y_train)\nstacking_xgb = stacking_xgb_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:36.382748Z","iopub.execute_input":"2023-07-27T01:21:36.383146Z","iopub.status.idle":"2023-07-27T01:21:36.840304Z","shell.execute_reply.started":"2023-07-27T01:21:36.383109Z","shell.execute_reply":"2023-07-27T01:21:36.839433Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"stacking_lgbm_model = lgb.LGBMClassifier(n_estimators=130, reg_alpha=0.017987440901161444, reg_lambda=0.0010110144342120994, \n                                colsample_bytree=0.8, subsample=0.5, learning_rate=0.08786840365732179, \n                                max_depth=5, num_leaves=10, min_child_samples=48, random_state=seed).fit(X_train, y_train)\nstacking_lgbm = stacking_lgbm_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:36.841544Z","iopub.execute_input":"2023-07-27T01:21:36.841945Z","iopub.status.idle":"2023-07-27T01:21:37.193776Z","shell.execute_reply.started":"2023-07-27T01:21:36.841909Z","shell.execute_reply":"2023-07-27T01:21:37.192892Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"stacking_hgbc_model = HistGradientBoostingClassifier(learning_rate=0.9112141545526848, max_depth=5, min_samples_leaf=18, \n                                                     max_iter=160, random_state=seed).fit(X_train, y_train)\nstacking_hgbc = stacking_hgbc_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:37.195119Z","iopub.execute_input":"2023-07-27T01:21:37.195427Z","iopub.status.idle":"2023-07-27T01:21:37.472940Z","shell.execute_reply.started":"2023-07-27T01:21:37.195401Z","shell.execute_reply":"2023-07-27T01:21:37.472011Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import get_scorer_names","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:37.474519Z","iopub.execute_input":"2023-07-27T01:21:37.474915Z","iopub.status.idle":"2023-07-27T01:21:37.479716Z","shell.execute_reply.started":"2023-07-27T01:21:37.474878Z","shell.execute_reply":"2023-07-27T01:21:37.478667Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"print('CatBoostClassifier CV: ', CV(cat_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:37.481054Z","iopub.execute_input":"2023-07-27T01:21:37.481346Z","iopub.status.idle":"2023-07-27T01:21:58.393922Z","shell.execute_reply.started":"2023-07-27T01:21:37.481320Z","shell.execute_reply":"2023-07-27T01:21:58.392982Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"CatBoostClassifier CV:  0.03187018798730954\n","output_type":"stream"}]},{"cell_type":"code","source":"print('XGB Classifier CV: ', CV(xgb_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:21:58.398844Z","iopub.execute_input":"2023-07-27T01:21:58.399150Z","iopub.status.idle":"2023-07-27T01:22:02.234473Z","shell.execute_reply.started":"2023-07-27T01:21:58.399125Z","shell.execute_reply":"2023-07-27T01:22:02.233459Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"XGB Classifier CV:  0.039632181376836065\n","output_type":"stream"}]},{"cell_type":"code","source":"print('HGBC Classifier CV: ', CV(hgbc_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:22:02.235847Z","iopub.execute_input":"2023-07-27T01:22:02.236138Z","iopub.status.idle":"2023-07-27T01:22:07.647631Z","shell.execute_reply.started":"2023-07-27T01:22:02.236113Z","shell.execute_reply":"2023-07-27T01:22:07.646421Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"HGBC Classifier CV:  0.033823382091336264\n","output_type":"stream"}]},{"cell_type":"code","source":"print('LGBM Classifier CV: ', CV(lgbm_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:22:07.648936Z","iopub.execute_input":"2023-07-27T01:22:07.649328Z","iopub.status.idle":"2023-07-27T01:22:15.987765Z","shell.execute_reply.started":"2023-07-27T01:22:07.649297Z","shell.execute_reply":"2023-07-27T01:22:15.986772Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"LGBM Classifier CV:  0.025306527724138474\n","output_type":"stream"}]},{"cell_type":"code","source":"print('CatBoostClassifier Stacking CV: ', CV(stacking_cat_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:22:15.988809Z","iopub.execute_input":"2023-07-27T01:22:15.989101Z","iopub.status.idle":"2023-07-27T01:22:37.844159Z","shell.execute_reply.started":"2023-07-27T01:22:15.989075Z","shell.execute_reply":"2023-07-27T01:22:37.843447Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"CatBoostClassifier Stacking CV:  0.039181187006573734\n","output_type":"stream"}]},{"cell_type":"code","source":"print('XGB Classifier Stacking CV: ', CV(stacking_xgb_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:22:37.845380Z","iopub.execute_input":"2023-07-27T01:22:37.845961Z","iopub.status.idle":"2023-07-27T01:22:42.060985Z","shell.execute_reply.started":"2023-07-27T01:22:37.845931Z","shell.execute_reply":"2023-07-27T01:22:42.060258Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"XGB Classifier Stacking CV:  0.04641075838489262\n","output_type":"stream"}]},{"cell_type":"code","source":"print('LGBM Classifier Stacking CV: ', CV(stacking_lgbm_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:22:42.062078Z","iopub.execute_input":"2023-07-27T01:22:42.062572Z","iopub.status.idle":"2023-07-27T01:22:45.455758Z","shell.execute_reply.started":"2023-07-27T01:22:42.062544Z","shell.execute_reply":"2023-07-27T01:22:45.454095Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"LGBM Classifier Stacking CV:  0.046191199858464496\n","output_type":"stream"}]},{"cell_type":"code","source":"print('HGBC Classifier Stacking CV: ', CV(stacking_hgbc_model, oversampled_df, balanced_log_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-27T01:22:45.457324Z","iopub.execute_input":"2023-07-27T01:22:45.457643Z","iopub.status.idle":"2023-07-27T01:22:47.969855Z","shell.execute_reply.started":"2023-07-27T01:22:45.457615Z","shell.execute_reply":"2023-07-27T01:22:47.968868Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"HGBC Classifier Stacking CV:  0.06376106326829557\n","output_type":"stream"}]},{"cell_type":"code","source":"def round_up_down(num):\n    round_num = round(num)  \n    result = 1 if rounded_number >= 0.5 else 0  \n    return result","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#final.iloc[:, 1], final.iloc[:, -1] = stacking_cat_model.predict_proba(test.iloc[:, 1:])[:, 0], stacking_cat_model.predict_proba(test.iloc[:, 1:])[:, 1]\nfinal.iloc[:, 1] = ((lgbm[:, 0] + xgb[:, 0])/2).apply(lambda x: round_up_down(x))\nfinal.iloc[:, -1] = ((lgbm[:, 1] + xgb[:, 0])/2).apply(lambda x: round_up_down(x))\nfinal.to_csv('submission.csv', index=False)\nsubmission = pd.read_csv('submission.csv')\nsubmission","metadata":{"execution":{"iopub.status.busy":"2023-07-26T22:06:38.301329Z","iopub.execute_input":"2023-07-26T22:06:38.301836Z","iopub.status.idle":"2023-07-26T22:06:38.328866Z","shell.execute_reply.started":"2023-07-26T22:06:38.301791Z","shell.execute_reply":"2023-07-26T22:06:38.327618Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"             Id   class_0   class_1\n0  00eed32682bb  0.977403  0.022597\n1  010ebe33f668  0.977403  0.022597\n2  02fa521e1838  0.977403  0.022597\n3  040e15f562a2  0.977403  0.022597\n4  046e85c7cc7f  0.977403  0.022597","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>class_0</th>\n      <th>class_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00eed32682bb</td>\n      <td>0.977403</td>\n      <td>0.022597</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>010ebe33f668</td>\n      <td>0.977403</td>\n      <td>0.022597</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>02fa521e1838</td>\n      <td>0.977403</td>\n      <td>0.022597</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>040e15f562a2</td>\n      <td>0.977403</td>\n      <td>0.022597</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>046e85c7cc7f</td>\n      <td>0.977403</td>\n      <td>0.022597</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}