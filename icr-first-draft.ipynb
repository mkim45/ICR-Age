{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nimport numpy as np\nimport pandas as pd\nimport warnings\ndef ignore_warn(*args,**kwargs):\n    pass\nwarnings.warn = ignore_warn\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport optuna\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score, KFold, train_test_split\nfrom sklearn.metrics import f1_score\nimport xgboost as xgboost\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.experimental import enable_hist_gradient_boosting  \nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.ensemble import StackingClassifier, VotingClassifier","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:27:00.983741Z","iopub.execute_input":"2023-07-25T22:27:00.984466Z","iopub.status.idle":"2023-07-25T22:27:00.994426Z","shell.execute_reply.started":"2023-07-25T22:27:00.984422Z","shell.execute_reply":"2023-07-25T22:27:00.993158Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\ntest = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\nfinal = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:21:52.628610Z","iopub.execute_input":"2023-07-25T22:21:52.629071Z","iopub.status.idle":"2023-07-25T22:21:52.681851Z","shell.execute_reply.started":"2023-07-25T22:21:52.629033Z","shell.execute_reply":"2023-07-25T22:21:52.680627Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\ntrain.loc[:, 'EJ'] = encoder.fit_transform(train.loc[:, 'EJ'])\ntest.loc[:, 'EJ'] = encoder.fit_transform(test.loc[:, 'EJ'])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:25:26.052076Z","iopub.execute_input":"2023-07-25T22:25:26.052467Z","iopub.status.idle":"2023-07-25T22:25:26.060437Z","shell.execute_reply.started":"2023-07-25T22:25:26.052438Z","shell.execute_reply":"2023-07-25T22:25:26.059070Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\nseed = 617\nzero, one = np.bincount(train.loc[:, 'Class'])\none_df = train.iloc[(train.loc[:, 'Class'] == 1).tolist(), :] \nzero_df = train.iloc[(train.loc[:, 'Class'] == 0).tolist(), :]\nzero_df = zero_df.sample(n=one, random_state=seed)\noversampled_df = pd.concat([train.iloc[(train.loc[:, 'Class'] == 0).tolist(), :], one_df, one_df, one_df, one_df])\noversampled_df = oversampled_df.sample(frac=1, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:25:26.529964Z","iopub.execute_input":"2023-07-25T22:25:26.530356Z","iopub.status.idle":"2023-07-25T22:25:26.548502Z","shell.execute_reply.started":"2023-07-25T22:25:26.530327Z","shell.execute_reply":"2023-07-25T22:25:26.547354Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\ndef balanced_log_loss(y_true, y_pred):\n    N_0 = np.sum(1 - y_true)\n    N_1 = np.sum(y_true)\n    w_0 = 1 / N_0\n    w_1 = 1 / N_1\n    p_1 = np.clip(y_pred[:, 1], 1e-15, 1-1e-15)\n    p_0 = 1 - p_1\n    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\n    log_loss_1 = -np.sum(y_true * np.log(p_1))\n    balanced_log_loss = (w_0 * log_loss_0 + w_1 * log_loss_1) / 2\n    return balanced_log_loss","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:25:28.107673Z","iopub.execute_input":"2023-07-25T22:25:28.108067Z","iopub.status.idle":"2023-07-25T22:25:28.115586Z","shell.execute_reply.started":"2023-07-25T22:25:28.108037Z","shell.execute_reply":"2023-07-25T22:25:28.114445Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\nn_folds = 10\ndef CV(model, data, loss_function):\n    skf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n    kfold = skf.split(data.iloc[:,1:-1], data.iloc[:, -1])\n    losses = []\n    for (train_id, val_id) in kfold:\n        x_train = data.iloc[train_id, 1:-1]\n        y_train = data.iloc[train_id, -1]\n        x_val = data.iloc[val_id, 1:-1]\n        y_val = data.iloc[val_id, -1]\n        model.fit(x_train, y_train)\n        pred_val = model.predict_proba(x_val)\n        loss = loss_function(y_val, pred_val)\n        losses.append(loss)\n    return np.sum(losses) / n_folds","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:25:29.392045Z","iopub.execute_input":"2023-07-25T22:25:29.392412Z","iopub.status.idle":"2023-07-25T22:25:29.401031Z","shell.execute_reply.started":"2023-07-25T22:25:29.392385Z","shell.execute_reply":"2023-07-25T22:25:29.399871Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"X_train = oversampled_df.drop(columns=['Class', 'Id'])\ny_train = oversampled_df['Class']","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:26:09.947296Z","iopub.execute_input":"2023-07-25T22:26:09.947699Z","iopub.status.idle":"2023-07-25T22:26:09.954714Z","shell.execute_reply.started":"2023-07-25T22:26:09.947666Z","shell.execute_reply":"2023-07-25T22:26:09.953526Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:27:03.805676Z","iopub.execute_input":"2023-07-25T22:27:03.806062Z","iopub.status.idle":"2023-07-25T22:27:03.816183Z","shell.execute_reply.started":"2023-07-25T22:27:03.806033Z","shell.execute_reply":"2023-07-25T22:27:03.815245Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def xgb(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),\n    }\n    model = xgb.XGBClassifier(**param, random_state = seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:27:07.350322Z","iopub.execute_input":"2023-07-25T22:27:07.350738Z","iopub.status.idle":"2023-07-25T22:27:07.362961Z","shell.execute_reply.started":"2023-07-25T22:27:07.350704Z","shell.execute_reply":"2023-07-25T22:27:07.361742Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def lgbm(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'num_leaves' : trial.suggest_int('num_leaves', 10, 50),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 50),\n    }\n    model = lgb.LGBMClassifier(**param, random_state = seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:27:07.565917Z","iopub.execute_input":"2023-07-25T22:27:07.566283Z","iopub.status.idle":"2023-07-25T22:27:07.575495Z","shell.execute_reply.started":"2023-07-25T22:27:07.566254Z","shell.execute_reply":"2023-07-25T22:27:07.574228Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def catboost(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 150, 10),\n        'reg_lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'colsample_bylevel': trial.suggest_categorical('colsample_bylevel', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'one_hot_max_size': trial.suggest_int('one_hot_max_size', 2, 10),\n    }\n    model = CatBoostClassifier(**param, random_seed=seed, verbose=False)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:27:07.803364Z","iopub.execute_input":"2023-07-25T22:27:07.803763Z","iopub.status.idle":"2023-07-25T22:27:07.812294Z","shell.execute_reply.started":"2023-07-25T22:27:07.803729Z","shell.execute_reply":"2023-07-25T22:27:07.811126Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def hgbc(trial):\n    param = {\n        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 15),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'max_iter': trial.suggest_int('max_iter', 50, 200, 10),\n    }\n    model = HistGradientBoostingClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:27:08.242148Z","iopub.execute_input":"2023-07-25T22:27:08.242534Z","iopub.status.idle":"2023-07-25T22:27:08.250174Z","shell.execute_reply.started":"2023-07-25T22:27:08.242505Z","shell.execute_reply":"2023-07-25T22:27:08.248999Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n\nstudy1 = optuna.create_study(direction='minimize', study_name=\"HGBC Stacking\")\nn_trials = 20\nstudy1.optimize(hgbc_meta, n_trials=n_trials)\nprint('Best trial:', study1.best_trial.params)\nprint('Best values:', study1.best_value)\n\nend = time.time()\nprint('It has taken {:.5f} seconds to search for the best Hyperparameter'.format(end-start))","metadata":{"execution":{"iopub.status.busy":"2023-07-25T19:17:30.901149Z","iopub.execute_input":"2023-07-25T19:17:30.901677Z","iopub.status.idle":"2023-07-25T20:38:57.772860Z","shell.execute_reply.started":"2023-07-25T19:17:30.901639Z","shell.execute_reply":"2023-07-25T20:38:57.771663Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"[I 2023-07-25 19:17:30,904] A new study created in memory with name: HGBC Stacking\n[I 2023-07-25 19:21:36,040] Trial 0 finished with value: 6.029513174380477e-06 and parameters: {'learning_rate': 0.32692462939369205, 'max_depth': 3, 'min_samples_leaf': 20, 'max_iter': 90}. Best is trial 0 with value: 6.029513174380477e-06.\n[I 2023-07-25 19:25:41,047] Trial 1 finished with value: 1.03449858669573e-06 and parameters: {'learning_rate': 0.5369990408748471, 'max_depth': 12, 'min_samples_leaf': 13, 'max_iter': 60}. Best is trial 1 with value: 1.03449858669573e-06.\n[I 2023-07-25 19:29:45,151] Trial 2 finished with value: 1.2410381928629268e-06 and parameters: {'learning_rate': 0.7658491467039173, 'max_depth': 13, 'min_samples_leaf': 14, 'max_iter': 50}. Best is trial 1 with value: 1.03449858669573e-06.\n[I 2023-07-25 19:33:51,452] Trial 3 finished with value: 6.657535677619918e-07 and parameters: {'learning_rate': 0.9112141545526848, 'max_depth': 5, 'min_samples_leaf': 18, 'max_iter': 160}. Best is trial 3 with value: 6.657535677619918e-07.\n[I 2023-07-25 19:37:56,823] Trial 4 finished with value: 5.262731646947573e-06 and parameters: {'learning_rate': 0.1513345911740949, 'max_depth': 15, 'min_samples_leaf': 14, 'max_iter': 190}. Best is trial 3 with value: 6.657535677619918e-07.\n[I 2023-07-25 19:42:00,943] Trial 5 finished with value: 1.2332963378628778e-06 and parameters: {'learning_rate': 0.5905141568724148, 'max_depth': 8, 'min_samples_leaf': 19, 'max_iter': 70}. Best is trial 3 with value: 6.657535677619918e-07.\n[I 2023-07-25 19:46:05,303] Trial 6 finished with value: 1.6519068469822116e-06 and parameters: {'learning_rate': 0.5533889092325838, 'max_depth': 13, 'min_samples_leaf': 7, 'max_iter': 190}. Best is trial 3 with value: 6.657535677619918e-07.\n[I 2023-07-25 19:50:12,693] Trial 7 finished with value: 0.00015211076482826296 and parameters: {'learning_rate': 0.06121725815176468, 'max_depth': 14, 'min_samples_leaf': 16, 'max_iter': 180}. Best is trial 3 with value: 6.657535677619918e-07.\n[I 2023-07-25 19:54:16,192] Trial 8 finished with value: 1.146575186744875e-06 and parameters: {'learning_rate': 0.7857116618628147, 'max_depth': 8, 'min_samples_leaf': 1, 'max_iter': 170}. Best is trial 3 with value: 6.657535677619918e-07.\n[I 2023-07-25 19:58:18,419] Trial 9 finished with value: 5.620619763873056e-06 and parameters: {'learning_rate': 0.5197324148231286, 'max_depth': 6, 'min_samples_leaf': 5, 'max_iter': 90}. Best is trial 3 with value: 6.657535677619918e-07.\n[I 2023-07-25 20:02:23,428] Trial 10 finished with value: 1.5578483912792615e-06 and parameters: {'learning_rate': 0.9327495604481091, 'max_depth': 3, 'min_samples_leaf': 10, 'max_iter': 140}. Best is trial 3 with value: 6.657535677619918e-07.\n[I 2023-07-25 20:06:28,624] Trial 11 finished with value: 1.4388867514019478e-06 and parameters: {'learning_rate': 0.3472499197731682, 'max_depth': 11, 'min_samples_leaf': 16, 'max_iter': 140}. Best is trial 3 with value: 6.657535677619918e-07.\n[I 2023-07-25 20:10:31,138] Trial 12 finished with value: 1.8291122349284897e-06 and parameters: {'learning_rate': 0.933459798683977, 'max_depth': 10, 'min_samples_leaf': 11, 'max_iter': 120}. Best is trial 3 with value: 6.657535677619918e-07.\n[I 2023-07-25 20:14:35,913] Trial 13 finished with value: 7.645475813659844e-07 and parameters: {'learning_rate': 0.7063169577843993, 'max_depth': 6, 'min_samples_leaf': 17, 'max_iter': 160}. Best is trial 3 with value: 6.657535677619918e-07.\n[I 2023-07-25 20:18:39,317] Trial 14 finished with value: 9.014325236800117e-07 and parameters: {'learning_rate': 0.9991811729093386, 'max_depth': 5, 'min_samples_leaf': 18, 'max_iter': 160}. Best is trial 3 with value: 6.657535677619918e-07.\n[I 2023-07-25 20:22:43,761] Trial 15 finished with value: 9.228138666990207e-07 and parameters: {'learning_rate': 0.7435681833277593, 'max_depth': 6, 'min_samples_leaf': 17, 'max_iter': 150}. Best is trial 3 with value: 6.657535677619918e-07.\n[I 2023-07-25 20:26:48,509] Trial 16 finished with value: 8.087850289251835e-07 and parameters: {'learning_rate': 0.6983751937186886, 'max_depth': 5, 'min_samples_leaf': 20, 'max_iter': 120}. Best is trial 3 with value: 6.657535677619918e-07.\n[I 2023-07-25 20:30:50,944] Trial 17 finished with value: 1.0528535657204792e-06 and parameters: {'learning_rate': 0.8631257847951147, 'max_depth': 8, 'min_samples_leaf': 11, 'max_iter': 200}. Best is trial 3 with value: 6.657535677619918e-07.\n[I 2023-07-25 20:34:56,280] Trial 18 finished with value: 1.091654063232584e-06 and parameters: {'learning_rate': 0.6358516019206839, 'max_depth': 5, 'min_samples_leaf': 15, 'max_iter': 170}. Best is trial 3 with value: 6.657535677619918e-07.\n[I 2023-07-25 20:38:57,767] Trial 19 finished with value: 7.088797253122467e-07 and parameters: {'learning_rate': 0.8280649015537039, 'max_depth': 6, 'min_samples_leaf': 18, 'max_iter': 100}. Best is trial 3 with value: 6.657535677619918e-07.\n","output_type":"stream"},{"name":"stdout","text":"Best trial: {'learning_rate': 0.9112141545526848, 'max_depth': 5, 'min_samples_leaf': 18, 'max_iter': 160}\nBest values: 6.657535677619918e-07\nIt has taken 4886.86456 seconds to search for the best Hyperparameter\n","output_type":"stream"}]},{"cell_type":"code","source":"xgb_model = xgboost.XGBClassifier(n_estimators=200, reg_lambda=0.15325900166549988, reg_alpha=0.0044700650580230235, \n                              colsample_bytree=0.3, subsample=1.0, learning_rate=0.09975673376458177, \n                              max_depth=11, min_child_weight=2, random_state=seed).fit(X_train, y_train)\nxgb = xgb_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:27:11.145869Z","iopub.execute_input":"2023-07-25T22:27:11.146240Z","iopub.status.idle":"2023-07-25T22:27:11.545048Z","shell.execute_reply.started":"2023-07-25T22:27:11.146211Z","shell.execute_reply":"2023-07-25T22:27:11.543935Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"lgbm_model = lgb.LGBMClassifier(n_estimators=200, reg_alpha=0.0016725623110267532, reg_lambda=0.0038043774323061946, \n                                 colsample_bytree=0.3, subsample=0.4, learning_rate=0.09367295744238123, max_depth=11, \n                                 num_leaves=50, min_child_samples=26, random_state=seed).fit(X_train, y_train)\nlgbm = lgbm_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:27:11.547268Z","iopub.execute_input":"2023-07-25T22:27:11.547722Z","iopub.status.idle":"2023-07-25T22:27:12.382409Z","shell.execute_reply.started":"2023-07-25T22:27:11.547679Z","shell.execute_reply":"2023-07-25T22:27:12.381227Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"cat_model = CatBoostClassifier(n_estimators=70, reg_lambda=0.01606738047167, colsample_bylevel=0.3, \n                              subsample=0.7, learning_rate=0.0865881098465479, \n                              max_depth=9, one_hot_max_size=10, random_state=seed, verbose=False).fit(X_train, y_train)\ncat = cat_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:27:12.384145Z","iopub.execute_input":"2023-07-25T22:27:12.384480Z","iopub.status.idle":"2023-07-25T22:27:14.540275Z","shell.execute_reply.started":"2023-07-25T22:27:12.384452Z","shell.execute_reply":"2023-07-25T22:27:14.539219Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"hgbc_model = HistGradientBoostingClassifier(max_iter=170, max_depth=4, min_samples_leaf=9,\n                                         learning_rate=0.17193627413211837, random_state=seed).fit(X_train, y_train)\nhgbc = hgbc_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:27:14.542655Z","iopub.execute_input":"2023-07-25T22:27:14.543094Z","iopub.status.idle":"2023-07-25T22:27:15.133973Z","shell.execute_reply.started":"2023-07-25T22:27:14.543054Z","shell.execute_reply":"2023-07-25T22:27:15.132882Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def catboost_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 150, 10),\n        'reg_lambda': trial.suggest_loguniform('lambda', 1e-3, 0.1),\n        'colsample_bylevel': trial.suggest_categorical('colsample_bylevel', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'one_hot_max_size': trial.suggest_int('one_hot_max_size', 2, 10),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=CatBoostClassifier(**param, random_state=seed, verbose=False)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:27:15.135502Z","iopub.execute_input":"2023-07-25T22:27:15.135961Z","iopub.status.idle":"2023-07-25T22:27:15.147473Z","shell.execute_reply.started":"2023-07-25T22:27:15.135921Z","shell.execute_reply":"2023-07-25T22:27:15.146246Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def xgb_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 0.1),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 0.1),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=xgboost.XGBClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:27:15.149498Z","iopub.execute_input":"2023-07-25T22:27:15.150320Z","iopub.status.idle":"2023-07-25T22:27:15.169026Z","shell.execute_reply.started":"2023-07-25T22:27:15.150284Z","shell.execute_reply":"2023-07-25T22:27:15.168007Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def hgbc_meta(trial):\n    param = {\n        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 15),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'max_iter': trial.suggest_int('max_iter', 50, 200, 10),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=HistGradientBoostingClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:27:15.170340Z","iopub.execute_input":"2023-07-25T22:27:15.170792Z","iopub.status.idle":"2023-07-25T22:27:15.182053Z","shell.execute_reply.started":"2023-07-25T22:27:15.170752Z","shell.execute_reply":"2023-07-25T22:27:15.181008Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"def lgbm_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 0.1),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 0.1),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'num_leaves' : trial.suggest_int('num_leaves', 10, 50),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 50),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=lgb.LGBMClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:27:15.183385Z","iopub.execute_input":"2023-07-25T22:27:15.183841Z","iopub.status.idle":"2023-07-25T22:27:15.200419Z","shell.execute_reply.started":"2023-07-25T22:27:15.183802Z","shell.execute_reply":"2023-07-25T22:27:15.199540Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"stacking_cat_model = CatBoostClassifier(n_estimators=150, reg_lambda=0.05055956136270572, colsample_bylevel=0.6, \n                                        subsample=0.5, learning_rate=0.08699165501504001, max_depth=7, \n                                        one_hot_max_size=8, random_state=seed, verbose=False).fit(X_train, y_train)\nstacking_cat = stacking_cat_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:27:16.456689Z","iopub.execute_input":"2023-07-25T22:27:16.458003Z","iopub.status.idle":"2023-07-25T22:27:18.798558Z","shell.execute_reply.started":"2023-07-25T22:27:16.457955Z","shell.execute_reply":"2023-07-25T22:27:18.797453Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"stacking_xgb_model = xgboost.XGBClassifier(n_estimators=160, reg_lambda=0.030554982480056614, alpha=0.022993963306149747, \n                                           colsample_bytree=0.4, subsample=0.6, learning_rate=0.08378145372235492, \n                                           max_depth=17, min_child_weight=1, random_state=seed).fit(X_train, y_train)\nstacking_xgb = stacking_xgb_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:27:18.800315Z","iopub.execute_input":"2023-07-25T22:27:18.800640Z","iopub.status.idle":"2023-07-25T22:27:19.257493Z","shell.execute_reply.started":"2023-07-25T22:27:18.800595Z","shell.execute_reply":"2023-07-25T22:27:19.256232Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"stacking_lgbm_model = lgb.LGBMClassifier(n_estimators=130, reg_alpha=0.017987440901161444, reg_lambda=0.0010110144342120994, \n                                colsample_bytree=0.8, subsample=0.5, learning_rate=0.08786840365732179, \n                                max_depth=5, num_leaves=10, min_child_samples=48, random_state=seed).fit(X_train, y_train)\nstacking_lgbm = stacking_lgbm_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:27:19.258969Z","iopub.execute_input":"2023-07-25T22:27:19.259310Z","iopub.status.idle":"2023-07-25T22:27:19.644732Z","shell.execute_reply.started":"2023-07-25T22:27:19.259278Z","shell.execute_reply":"2023-07-25T22:27:19.643514Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"stacking_hgbc_model = HistGradientBoostingClassifier(learning_rate=0.9112141545526848, max_depth=5, min_samples_leaf=18, \n                                                     max_iter=160, random_state=seed).fit(X_train, y_train)\nstacking_hgbc = stacking_hgbc_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:27:19.647321Z","iopub.execute_input":"2023-07-25T22:27:19.648024Z","iopub.status.idle":"2023-07-25T22:27:19.913171Z","shell.execute_reply.started":"2023-07-25T22:27:19.647977Z","shell.execute_reply":"2023-07-25T22:27:19.911921Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"print('CatBoostClassifier Test: ', balanced_log_loss(y_val, cat_model.predict_proba(X_val)))\nprint('CatBoostClassifier Train: ', balanced_log_loss(y_train, cat_model.predict_proba(X_train)))","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:28:53.290842Z","iopub.execute_input":"2023-07-25T22:28:53.291228Z","iopub.status.idle":"2023-07-25T22:28:53.309827Z","shell.execute_reply.started":"2023-07-25T22:28:53.291193Z","shell.execute_reply":"2023-07-25T22:28:53.308693Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"CatBoostClassifier Test:  0.08204810646853498\nCatBoostClassifier Train:  0.00028839071566176165\n","output_type":"stream"}]},{"cell_type":"code","source":"print('XGB Classifier Test: ', balanced_log_loss(y_val, xgb_model.predict_proba(X_val)))\nprint('XGB Classifier Train: ', balanced_log_loss(y_train, xgb_model.predict_proba(X_train)))","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:29:16.994648Z","iopub.execute_input":"2023-07-25T22:29:16.995047Z","iopub.status.idle":"2023-07-25T22:29:17.019178Z","shell.execute_reply.started":"2023-07-25T22:29:16.995016Z","shell.execute_reply":"2023-07-25T22:29:17.017843Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"XGB Classifier Test:  0.10446782370665725\nXGB Classifier Train:  0.008267367107665851\n","output_type":"stream"}]},{"cell_type":"code","source":"print('HGBC Classifier Test: ', balanced_log_loss(y_val, hgbc_model.predict_proba(X_val)))\nprint('HGBC Classifier Train: ', balanced_log_loss(y_train, hgbc_model.predict_proba(X_train)))","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:29:37.693165Z","iopub.execute_input":"2023-07-25T22:29:37.693553Z","iopub.status.idle":"2023-07-25T22:29:37.730320Z","shell.execute_reply.started":"2023-07-25T22:29:37.693522Z","shell.execute_reply":"2023-07-25T22:29:37.729054Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"HGBC Classifier Test:  0.14238860386815336\nHGBC Classifier Train:  5.0620314684123985e-06\n","output_type":"stream"}]},{"cell_type":"code","source":"print('LGBM Classifier Test: ', balanced_log_loss(y_val, lgbm_model.predict_proba(X_val)))\nprint('LGBM Classifier Train: ', balanced_log_loss(y_train, lgbm_model.predict_proba(X_train)))","metadata":{"execution":{"iopub.status.busy":"2023-07-25T22:29:59.211760Z","iopub.execute_input":"2023-07-25T22:29:59.212143Z","iopub.status.idle":"2023-07-25T22:29:59.233837Z","shell.execute_reply.started":"2023-07-25T22:29:59.212114Z","shell.execute_reply":"2023-07-25T22:29:59.232562Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"LGBM Classifier Test:  0.11273080892259844\nLGBM Classifier Train:  9.993240084942319e-05\n","output_type":"stream"}]},{"cell_type":"code","source":"final.iloc[:, 1] = (xgb[:, 0] + lgbm[:, 0] + hgbc[:, 0] + cat[:, 0]) / 4\nfinal.iloc[:, -1] = (xgb[:, 1] + lgbm[:, 1] + hgbc[:, 1] + cat[:, 1]) / 4\nfinal.to_csv('submission.csv', index=False)\nsubmission = pd.read_csv('submission.csv')\nsubmission","metadata":{"execution":{"iopub.status.busy":"2023-07-24T22:45:48.465085Z","iopub.execute_input":"2023-07-24T22:45:48.465566Z","iopub.status.idle":"2023-07-24T22:45:48.494445Z","shell.execute_reply.started":"2023-07-24T22:45:48.465521Z","shell.execute_reply":"2023-07-24T22:45:48.493214Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"             Id   class_0   class_1\n0  00eed32682bb  0.964072  0.035928\n1  010ebe33f668  0.964072  0.035928\n2  02fa521e1838  0.964072  0.035928\n3  040e15f562a2  0.964072  0.035928\n4  046e85c7cc7f  0.964072  0.035928","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>class_0</th>\n      <th>class_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00eed32682bb</td>\n      <td>0.964072</td>\n      <td>0.035928</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>010ebe33f668</td>\n      <td>0.964072</td>\n      <td>0.035928</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>02fa521e1838</td>\n      <td>0.964072</td>\n      <td>0.035928</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>040e15f562a2</td>\n      <td>0.964072</td>\n      <td>0.035928</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>046e85c7cc7f</td>\n      <td>0.964072</td>\n      <td>0.035928</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}