{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nimport numpy as np\nimport pandas as pd\nimport warnings\ndef ignore_warn(*args,**kwargs):\n    pass\nwarnings.warn = ignore_warn\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport optuna\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.metrics import f1_score\nimport xgboost as xgboost\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.experimental import enable_hist_gradient_boosting  \nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.ensemble import StackingClassifier, VotingClassifier","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:42:19.431154Z","iopub.execute_input":"2023-07-25T15:42:19.432498Z","iopub.status.idle":"2023-07-25T15:42:22.867472Z","shell.execute_reply.started":"2023-07-25T15:42:19.432433Z","shell.execute_reply":"2023-07-25T15:42:22.865896Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\ntest = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\nfinal = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:42:22.870121Z","iopub.execute_input":"2023-07-25T15:42:22.870576Z","iopub.status.idle":"2023-07-25T15:42:22.920601Z","shell.execute_reply.started":"2023-07-25T15:42:22.870541Z","shell.execute_reply":"2023-07-25T15:42:22.919375Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\ntrain.loc[:, 'EJ'] = encoder.fit_transform(train.loc[:, 'EJ'])\ntest.loc[:, 'EJ'] = encoder.fit_transform(test.loc[:, 'EJ'])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:42:22.922453Z","iopub.execute_input":"2023-07-25T15:42:22.922831Z","iopub.status.idle":"2023-07-25T15:42:22.935683Z","shell.execute_reply.started":"2023-07-25T15:42:22.922797Z","shell.execute_reply":"2023-07-25T15:42:22.934426Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\nseed = 617\nzero, one = np.bincount(train.loc[:, 'Class'])\none_df = train.iloc[(train.loc[:, 'Class'] == 1).tolist(), :] \nzero_df = train.iloc[(train.loc[:, 'Class'] == 0).tolist(), :]\nzero_df = zero_df.sample(n=one, random_state=seed)\noversampled_df = pd.concat([train.iloc[(train.loc[:, 'Class'] == 0).tolist(), :], one_df, one_df, one_df, one_df])\noversampled_df = oversampled_df.sample(frac=1, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:42:23.180722Z","iopub.execute_input":"2023-07-25T15:42:23.181789Z","iopub.status.idle":"2023-07-25T15:42:23.204434Z","shell.execute_reply.started":"2023-07-25T15:42:23.181748Z","shell.execute_reply":"2023-07-25T15:42:23.203187Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\ndef balanced_log_loss(y_true, y_pred):\n    N_0 = np.sum(1 - y_true)\n    N_1 = np.sum(y_true)\n    w_0 = 1 / N_0\n    w_1 = 1 / N_1\n    p_1 = np.clip(y_pred[:, 1], 1e-15, 1-1e-15)\n    p_0 = 1 - p_1\n    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\n    log_loss_1 = -np.sum(y_true * np.log(p_1))\n    balanced_log_loss = (w_0 * log_loss_0 + w_1 * log_loss_1) / 2\n    return balanced_log_loss","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:42:24.591311Z","iopub.execute_input":"2023-07-25T15:42:24.591756Z","iopub.status.idle":"2023-07-25T15:42:24.600247Z","shell.execute_reply.started":"2023-07-25T15:42:24.591716Z","shell.execute_reply":"2023-07-25T15:42:24.598840Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# taken directly from https://www.kaggle.com/code/chensilin/icr-eda-lightgbm-xgboost-optuna/input\nn_folds = 10\ndef CV(model, data, loss_function):\n    skf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n    kfold = skf.split(data.iloc[:,1:-1], data.iloc[:, -1])\n    losses = []\n    for (train_id, val_id) in kfold:\n        x_train = data.iloc[train_id, 1:-1]\n        y_train = data.iloc[train_id, -1]\n        x_val = data.iloc[val_id, 1:-1]\n        y_val = data.iloc[val_id, -1]\n        model.fit(x_train, y_train)\n        pred_val = model.predict_proba(x_val)\n        loss = loss_function(y_val, pred_val)\n        losses.append(loss)\n    return np.sum(losses) / n_folds","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:42:24.819192Z","iopub.execute_input":"2023-07-25T15:42:24.819700Z","iopub.status.idle":"2023-07-25T15:42:24.829395Z","shell.execute_reply.started":"2023-07-25T15:42:24.819659Z","shell.execute_reply":"2023-07-25T15:42:24.828146Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X_train = oversampled_df.drop(columns=['Class', 'Id'])\ny_train = oversampled_df['Class']","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:42:26.725573Z","iopub.execute_input":"2023-07-25T15:42:26.726096Z","iopub.status.idle":"2023-07-25T15:42:26.737138Z","shell.execute_reply.started":"2023-07-25T15:42:26.726054Z","shell.execute_reply":"2023-07-25T15:42:26.735538Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def xgb(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),\n    }\n    model = xgb.XGBClassifier(**param, random_state = seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:43:34.087505Z","iopub.execute_input":"2023-07-25T15:43:34.087923Z","iopub.status.idle":"2023-07-25T15:43:34.097847Z","shell.execute_reply.started":"2023-07-25T15:43:34.087885Z","shell.execute_reply":"2023-07-25T15:43:34.096525Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def lgbm(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'num_leaves' : trial.suggest_int('num_leaves', 10, 50),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 50),\n    }\n    model = lgb.LGBMClassifier(**param, random_state = seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:43:34.376047Z","iopub.execute_input":"2023-07-25T15:43:34.376506Z","iopub.status.idle":"2023-07-25T15:43:34.386515Z","shell.execute_reply.started":"2023-07-25T15:43:34.376470Z","shell.execute_reply":"2023-07-25T15:43:34.384976Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def catboost(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 150, 10),\n        'reg_lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'colsample_bylevel': trial.suggest_categorical('colsample_bylevel', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'one_hot_max_size': trial.suggest_int('one_hot_max_size', 2, 10),\n    }\n    model = CatBoostClassifier(**param, random_seed=seed, verbose=False)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:43:34.817788Z","iopub.execute_input":"2023-07-25T15:43:34.818256Z","iopub.status.idle":"2023-07-25T15:43:34.827966Z","shell.execute_reply.started":"2023-07-25T15:43:34.818220Z","shell.execute_reply":"2023-07-25T15:43:34.826518Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def hgbc(trial):\n    param = {\n        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 15),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'max_iter': trial.suggest_int('max_iter', 50, 200, 10),\n    }\n    model = HistGradientBoostingClassifier(**param, random_state=seed)\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:43:35.193714Z","iopub.execute_input":"2023-07-25T15:43:35.194154Z","iopub.status.idle":"2023-07-25T15:43:35.204415Z","shell.execute_reply.started":"2023-07-25T15:43:35.194121Z","shell.execute_reply":"2023-07-25T15:43:35.202804Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#start = time.time()\n\n#study1 = optuna.create_study(direction='minimize', study_name=\"XGB Stacking\")\n#n_trials = 20\n#study1.optimize(xgb_meta, n_trials=n_trials)\n#print('Best trial:', study1.best_trial.params)\n#print('Best values:', study1.best_value)\n\n#end = time.time()\n#print('It has taken {:.5f} seconds to search for the best Hyperparameter'.format(end-start))","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:44:37.262557Z","iopub.execute_input":"2023-07-25T15:44:37.262962Z","iopub.status.idle":"2023-07-25T17:29:11.444483Z","shell.execute_reply.started":"2023-07-25T15:44:37.262933Z","shell.execute_reply":"2023-07-25T17:29:11.443267Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"[I 2023-07-25 15:44:37,265] A new study created in memory with name: XGB Stacking\n[I 2023-07-25 15:48:59,564] Trial 0 finished with value: 0.21834228635222672 and parameters: {'n_estimators': 80, 'lambda': 0.0016820260633821874, 'alpha': 0.07065278708449077, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.08448857168992331, 'max_depth': 19, 'min_child_weight': 50}. Best is trial 0 with value: 0.21834228635222672.\n[I 2023-07-25 15:53:21,092] Trial 1 finished with value: 0.4120172907932428 and parameters: {'n_estimators': 100, 'lambda': 0.02313646668366546, 'alpha': 0.008929473745786532, 'colsample_bytree': 0.6, 'subsample': 0.4, 'learning_rate': 0.02588929739795205, 'max_depth': 3, 'min_child_weight': 41}. Best is trial 0 with value: 0.21834228635222672.\n[I 2023-07-25 15:57:39,742] Trial 2 finished with value: 0.14403695253685153 and parameters: {'n_estimators': 120, 'lambda': 0.025622051671046798, 'alpha': 0.002654406272266926, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.06795276052600782, 'max_depth': 8, 'min_child_weight': 27}. Best is trial 2 with value: 0.14403695253685153.\n[I 2023-07-25 16:02:05,499] Trial 3 finished with value: 0.2960429861379044 and parameters: {'n_estimators': 100, 'lambda': 0.019055381663449174, 'alpha': 0.09639190153096713, 'colsample_bytree': 0.3, 'subsample': 0.5, 'learning_rate': 0.031188347497057713, 'max_depth': 5, 'min_child_weight': 43}. Best is trial 2 with value: 0.14403695253685153.\n[I 2023-07-25 16:06:31,141] Trial 4 finished with value: 0.09097162981597111 and parameters: {'n_estimators': 50, 'lambda': 0.0023319586109631692, 'alpha': 0.010987412412243762, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.06212353998242524, 'max_depth': 10, 'min_child_weight': 35}. Best is trial 4 with value: 0.09097162981597111.\n[I 2023-07-25 16:10:52,745] Trial 5 finished with value: 0.13189824472740846 and parameters: {'n_estimators': 90, 'lambda': 0.004511080826785824, 'alpha': 0.0018910762406954443, 'colsample_bytree': 0.6, 'subsample': 0.8, 'learning_rate': 0.04371528692247102, 'max_depth': 14, 'min_child_weight': 39}. Best is trial 4 with value: 0.09097162981597111.\n[I 2023-07-25 16:15:10,257] Trial 6 finished with value: 0.08438783549392918 and parameters: {'n_estimators': 180, 'lambda': 0.0020088862194163155, 'alpha': 0.02769077555984759, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.049213515424340264, 'max_depth': 12, 'min_child_weight': 24}. Best is trial 6 with value: 0.08438783549392918.\n[I 2023-07-25 16:19:28,148] Trial 7 finished with value: 0.1388040900720452 and parameters: {'n_estimators': 80, 'lambda': 0.0014563565717123168, 'alpha': 0.016317384430288528, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.055371407970958, 'max_depth': 14, 'min_child_weight': 49}. Best is trial 6 with value: 0.08438783549392918.\n[I 2023-07-25 16:28:07,057] Trial 9 finished with value: 0.09345644659145935 and parameters: {'n_estimators': 130, 'lambda': 0.00740441138649066, 'alpha': 0.0013843838253364818, 'colsample_bytree': 0.6, 'subsample': 0.8, 'learning_rate': 0.025908065777288523, 'max_depth': 12, 'min_child_weight': 29}. Best is trial 6 with value: 0.08438783549392918.\n[I 2023-07-25 16:32:17,278] Trial 10 finished with value: 0.033791914820238744 and parameters: {'n_estimators': 190, 'lambda': 0.06667747810044602, 'alpha': 0.03041554666215642, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.09016391721878789, 'max_depth': 19, 'min_child_weight': 11}. Best is trial 10 with value: 0.033791914820238744.\n[I 2023-07-25 16:36:20,727] Trial 11 finished with value: 0.03733051730912433 and parameters: {'n_estimators': 200, 'lambda': 0.07663201887579253, 'alpha': 0.03247183690454896, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.09464137004256377, 'max_depth': 20, 'min_child_weight': 12}. Best is trial 10 with value: 0.033791914820238744.\n[I 2023-07-25 16:40:25,418] Trial 12 finished with value: 0.023739011662896013 and parameters: {'n_estimators': 200, 'lambda': 0.09820766313655244, 'alpha': 0.03405809263119741, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.09417526972726606, 'max_depth': 19, 'min_child_weight': 8}. Best is trial 12 with value: 0.023739011662896013.\n[I 2023-07-25 16:44:28,293] Trial 13 finished with value: 0.01652182944251437 and parameters: {'n_estimators': 170, 'lambda': 0.09616149775790696, 'alpha': 0.04678617085013365, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.09909173307917896, 'max_depth': 17, 'min_child_weight': 5}. Best is trial 13 with value: 0.01652182944251437.\n[I 2023-07-25 16:48:31,613] Trial 14 finished with value: 0.0031514658112261574 and parameters: {'n_estimators': 170, 'lambda': 0.09388748832915417, 'alpha': 0.05232589819880738, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.0986108528240931, 'max_depth': 17, 'min_child_weight': 1}. Best is trial 14 with value: 0.0031514658112261574.\n[I 2023-07-25 16:52:36,828] Trial 15 finished with value: 0.0030870695304430176 and parameters: {'n_estimators': 160, 'lambda': 0.0458560427983495, 'alpha': 0.06105994741129811, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.0774841469733461, 'max_depth': 16, 'min_child_weight': 1}. Best is trial 15 with value: 0.0030870695304430176.\n[I 2023-07-25 16:56:41,451] Trial 16 finished with value: 0.005962111993375814 and parameters: {'n_estimators': 160, 'lambda': 0.041297217427400106, 'alpha': 0.09327786036502843, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.07747639771542267, 'max_depth': 16, 'min_child_weight': 2}. Best is trial 15 with value: 0.0030870695304430176.\n[I 2023-07-25 17:00:44,903] Trial 17 finished with value: 0.06569749943833596 and parameters: {'n_estimators': 140, 'lambda': 0.05092152994069713, 'alpha': 0.05936117386087485, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.0765483561012458, 'max_depth': 16, 'min_child_weight': 17}. Best is trial 15 with value: 0.0030870695304430176.\n[I 2023-07-25 17:04:49,469] Trial 18 finished with value: 0.0030783176676030463 and parameters: {'n_estimators': 170, 'lambda': 0.03927030775287197, 'alpha': 0.06805044787596475, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.08338579463229089, 'max_depth': 17, 'min_child_weight': 1}. Best is trial 18 with value: 0.0030783176676030463.\n[I 2023-07-25 17:08:52,259] Trial 19 finished with value: 0.07509793935990303 and parameters: {'n_estimators': 150, 'lambda': 0.014486695956225752, 'alpha': 0.09826670279336369, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.07654848440400283, 'max_depth': 10, 'min_child_weight': 19}. Best is trial 18 with value: 0.0030783176676030463.\n[I 2023-07-25 17:12:56,440] Trial 20 finished with value: 0.0571832316183995 and parameters: {'n_estimators': 130, 'lambda': 0.0462086414267006, 'alpha': 0.050895890810499694, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.06695271868482253, 'max_depth': 15, 'min_child_weight': 15}. Best is trial 18 with value: 0.0030783176676030463.\n[I 2023-07-25 17:17:01,194] Trial 21 finished with value: 0.00307858545873986 and parameters: {'n_estimators': 170, 'lambda': 0.03186695953496717, 'alpha': 0.061674648289375536, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.08507840460871578, 'max_depth': 17, 'min_child_weight': 1}. Best is trial 18 with value: 0.0030783176676030463.\n[I 2023-07-25 17:21:04,637] Trial 22 finished with value: 0.02013664950702359 and parameters: {'n_estimators': 180, 'lambda': 0.03216680746630544, 'alpha': 0.06839533241676607, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.08671456406212413, 'max_depth': 18, 'min_child_weight': 6}. Best is trial 18 with value: 0.0030783176676030463.\n[I 2023-07-25 17:25:08,642] Trial 23 finished with value: 0.003047603355757918 and parameters: {'n_estimators': 160, 'lambda': 0.030554982480056614, 'alpha': 0.022993963306149747, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.08378145372235492, 'max_depth': 17, 'min_child_weight': 1}. Best is trial 23 with value: 0.003047603355757918.\n[I 2023-07-25 17:29:11,437] Trial 24 finished with value: 0.03199233789519716 and parameters: {'n_estimators': 180, 'lambda': 0.013357320890920133, 'alpha': 0.01947493458366751, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.08537037749054445, 'max_depth': 20, 'min_child_weight': 9}. Best is trial 23 with value: 0.003047603355757918.\n","output_type":"stream"},{"name":"stdout","text":"Best trial: {'n_estimators': 160, 'lambda': 0.030554982480056614, 'alpha': 0.022993963306149747, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.08378145372235492, 'max_depth': 17, 'min_child_weight': 1}\nBest values: 0.003047603355757918\nIt has taken 6274.17404 seconds to search for the best Hyperparameter\n","output_type":"stream"}]},{"cell_type":"code","source":"xgb_model = xgboost.XGBClassifier(n_estimators=200, reg_lambda=0.15325900166549988, reg_alpha=0.0044700650580230235, \n                              colsample_bytree=0.3, subsample=1.0, learning_rate=0.09975673376458177, \n                              max_depth=11, min_child_weight=2, random_state=seed).fit(X_train, y_train)\nxgb = xgb_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:43:38.058558Z","iopub.execute_input":"2023-07-25T15:43:38.059076Z","iopub.status.idle":"2023-07-25T15:43:38.422968Z","shell.execute_reply.started":"2023-07-25T15:43:38.059034Z","shell.execute_reply":"2023-07-25T15:43:38.421968Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"lgbm_model = lgb.LGBMClassifier(n_estimators=200, reg_alpha=0.0016725623110267532, reg_lambda=0.0038043774323061946, \n                                 colsample_bytree=0.3, subsample=0.4, learning_rate=0.09367295744238123, max_depth=11, \n                                 num_leaves=50, min_child_samples=26, random_state=seed).fit(X_train, y_train)\nlgbm = lgbm_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:43:38.425135Z","iopub.execute_input":"2023-07-25T15:43:38.425854Z","iopub.status.idle":"2023-07-25T15:43:39.837078Z","shell.execute_reply.started":"2023-07-25T15:43:38.425818Z","shell.execute_reply":"2023-07-25T15:43:39.835815Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"cat_model = CatBoostClassifier(n_estimators=70, reg_lambda=0.01606738047167, colsample_bylevel=0.3, \n                              subsample=0.7, learning_rate=0.0865881098465479, \n                              max_depth=9, one_hot_max_size=10, random_state=seed, verbose=False).fit(X_train, y_train)\ncat = cat_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:43:39.839159Z","iopub.execute_input":"2023-07-25T15:43:39.839609Z","iopub.status.idle":"2023-07-25T15:43:42.120455Z","shell.execute_reply.started":"2023-07-25T15:43:39.839574Z","shell.execute_reply":"2023-07-25T15:43:42.118496Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"hgbc_model = HistGradientBoostingClassifier(max_iter=170, max_depth=4, min_samples_leaf=9,\n                                         learning_rate=0.17193627413211837, random_state=seed).fit(X_train, y_train)\nhgbc = hgbc_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:43:42.124961Z","iopub.execute_input":"2023-07-25T15:43:42.125617Z","iopub.status.idle":"2023-07-25T15:43:42.829886Z","shell.execute_reply.started":"2023-07-25T15:43:42.125576Z","shell.execute_reply":"2023-07-25T15:43:42.828407Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def catboost_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 150, 10),\n        'reg_lambda': trial.suggest_loguniform('lambda', 1e-3, 0.1),\n        'colsample_bylevel': trial.suggest_categorical('colsample_bylevel', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'one_hot_max_size': trial.suggest_int('one_hot_max_size', 2, 10),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=CatBoostClassifier(**param, random_state=seed, verbose=False)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:43:42.832695Z","iopub.execute_input":"2023-07-25T15:43:42.833120Z","iopub.status.idle":"2023-07-25T15:43:42.843511Z","shell.execute_reply.started":"2023-07-25T15:43:42.833084Z","shell.execute_reply":"2023-07-25T15:43:42.842330Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def xgb_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 0.1),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 0.1),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=xgboost.XGBClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:44:34.692221Z","iopub.execute_input":"2023-07-25T15:44:34.692662Z","iopub.status.idle":"2023-07-25T15:44:34.702741Z","shell.execute_reply.started":"2023-07-25T15:44:34.692627Z","shell.execute_reply":"2023-07-25T15:44:34.701687Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def hgbc_meta(trial):\n    param = {\n        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 15),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'max_iter': trial.suggest_int('max_iter', 50, 200, 10),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=HistGradientBoostingClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:44:34.901558Z","iopub.execute_input":"2023-07-25T15:44:34.902639Z","iopub.status.idle":"2023-07-25T15:44:34.911649Z","shell.execute_reply.started":"2023-07-25T15:44:34.902600Z","shell.execute_reply":"2023-07-25T15:44:34.910276Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def lgbm_meta(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200, 10),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 0.1),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 0.1),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'num_leaves' : trial.suggest_int('num_leaves', 10, 50),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 50),\n    }\n    model = StackingClassifier(\n        estimators=[(\"catboost\", cat_model), (\"hist_gradient_boosting\", hgbc_model),\n                    (\"lgbm\", lgbm_model), (\"xgboost\", xgb_model)],\n        final_estimator=lgb.LGBMClassifier(**param, random_state=seed)\n    )\n    score = CV(model, oversampled_df, balanced_log_loss)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:44:35.103062Z","iopub.execute_input":"2023-07-25T15:44:35.103506Z","iopub.status.idle":"2023-07-25T15:44:35.117068Z","shell.execute_reply.started":"2023-07-25T15:44:35.103469Z","shell.execute_reply":"2023-07-25T15:44:35.115214Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"stacking_cat_model = CatBoostClassifier(n_estimators=150, reg_lambda=0.05055956136270572, colsample_bylevel=0.6, \n                                        subsample=0.5, learning_rate=0.08699165501504001, max_depth=7, \n                                        one_hot_max_size=8, random_state=seed, verbose=False).fit(X_train, y_train)\nstacking_cat = stacking_cat_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T15:42:30.184538Z","iopub.execute_input":"2023-07-25T15:42:30.184958Z","iopub.status.idle":"2023-07-25T15:42:32.810533Z","shell.execute_reply.started":"2023-07-25T15:42:30.184923Z","shell.execute_reply":"2023-07-25T15:42:32.809293Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"stacking_xgb_model = xgboost.XGBClassifier(n_estimators=160, reg_lambda=0.030554982480056614, alpha=0.022993963306149747, \n                                           colsample_bytree=0.4, subsample=0.6, learning_rate=0.08378145372235492, \n                                           max_depth=17, min_child_weight=1, random_state=seed).fit(X_train, y_train)\nstacking_xgb = stacking_xgb_model.predict_proba(test.iloc[:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T17:47:50.363693Z","iopub.execute_input":"2023-07-25T17:47:50.364161Z","iopub.status.idle":"2023-07-25T17:47:50.894087Z","shell.execute_reply.started":"2023-07-25T17:47:50.364127Z","shell.execute_reply":"2023-07-25T17:47:50.893056Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"final.iloc[:, 1] = (xgb[:, 0] + lgbm[:, 0] + hgbc[:, 0] + cat[:, 0]) / 4\nfinal.iloc[:, -1] = (xgb[:, 1] + lgbm[:, 1] + hgbc[:, 1] + cat[:, 1]) / 4\nfinal.to_csv('submission.csv', index=False)\nsubmission = pd.read_csv('submission.csv')\nsubmission","metadata":{"execution":{"iopub.status.busy":"2023-07-24T22:45:48.465085Z","iopub.execute_input":"2023-07-24T22:45:48.465566Z","iopub.status.idle":"2023-07-24T22:45:48.494445Z","shell.execute_reply.started":"2023-07-24T22:45:48.465521Z","shell.execute_reply":"2023-07-24T22:45:48.493214Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"             Id   class_0   class_1\n0  00eed32682bb  0.964072  0.035928\n1  010ebe33f668  0.964072  0.035928\n2  02fa521e1838  0.964072  0.035928\n3  040e15f562a2  0.964072  0.035928\n4  046e85c7cc7f  0.964072  0.035928","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>class_0</th>\n      <th>class_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00eed32682bb</td>\n      <td>0.964072</td>\n      <td>0.035928</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>010ebe33f668</td>\n      <td>0.964072</td>\n      <td>0.035928</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>02fa521e1838</td>\n      <td>0.964072</td>\n      <td>0.035928</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>040e15f562a2</td>\n      <td>0.964072</td>\n      <td>0.035928</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>046e85c7cc7f</td>\n      <td>0.964072</td>\n      <td>0.035928</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}