{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f52acf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score,train_test_split, KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error,r2_score,roc_curve,auc,precision_recall_curve, accuracy_score, \\\n",
    "recall_score, precision_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import VotingRegressor, VotingClassifier, StackingRegressor, StackingClassifier, GradientBoostingRegressor,GradientBoostingClassifier, BaggingRegressor,BaggingClassifier,RandomForestRegressor,RandomForestClassifier,AdaBoostRegressor,AdaBoostClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import itertools as it\n",
    "import time as time\n",
    "import xgboost as xgb\n",
    "from pyearth import Earth\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_selection import RFE\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a679850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "greeks = pd.read_csv('greeks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ee99ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to dummy variables\n",
    "train['EJ'] = train['EJ'].apply(lambda x: 0 if x == 'A' else 1)\n",
    "test['EJ'] = test['EJ'].apply(lambda x: 0 if x == 'A' else 1)\n",
    "\n",
    "#Separating train data for predictors and response\n",
    "X_train = train.drop('Class', axis = 1)\n",
    "y_train = train.loc[:, 'Class']\n",
    "\n",
    "#Dropping id column\n",
    "X_train = X_train.drop('Id', axis = 1)\n",
    "test = test.drop('Id', axis = 1)\n",
    "\n",
    "#Creating validation data set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.10, stratify = y_train)\n",
    "\n",
    "#Scaling the train and test data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(test)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_train = pd.DataFrame(X_train_scaled)\n",
    "X_test = pd.DataFrame(X_test_scaled)\n",
    "X_val = pd.DataFrame(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "32712477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SKIP!!!\n",
    "#Using for loop to iterate over potential values of n_neighbors for imputing missing values, using a \n",
    "#CatBoostRegressor() to get train MSE as the parameter to choose best value\n",
    "scores = []\n",
    "val_scores = []\n",
    "for i in range(1, 40):\n",
    "    imputer = KNNImputer(n_neighbors = i)\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    model_test = CatBoostClassifier(verbose = False)\n",
    "    model_test.fit(X_train_imputed, y_train)\n",
    "\n",
    "    true_labels = np.array(y_train)\n",
    "    predicted_probs = np.array(model_test.predict_proba(X_train_imputed))\n",
    "\n",
    "    class_weights = np.mean(true_labels) / np.bincount(true_labels)\n",
    "    logloss_per_class = log_loss(true_labels, predicted_probs, labels=[0, 1], normalize=False)\n",
    "    balanced_logloss = np.sum(logloss_per_class * class_weights)\n",
    "    scores.append(balanced_logloss)\n",
    "    true_labels = np.array(y_val)\n",
    "    predicted_probs = np.array(model_test.predict_proba(X_val))\n",
    "\n",
    "    class_weights = np.mean(true_labels) / np.bincount(true_labels)\n",
    "    logloss_per_class = log_loss(true_labels, predicted_probs, labels=[0, 1], normalize=False)\n",
    "    balanced_logloss = np.sum(logloss_per_class * class_weights)\n",
    "    \n",
    "    val_scores.append(balanced_logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c514c2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff63ba0eba8>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(1, len(scores) + 1)\n",
    "plt.plot(x, scores, label = 'Train Scores')\n",
    "plt.plot(x, val_scores, label = 'Validation Scores')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9be7f0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors = 10)\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_val_imputed = imputer.transform(X_val)\n",
    "X_train = pd.DataFrame(X_train_imputed)\n",
    "X_val = pd.DataFrame(X_val_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df3b43f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial data analysis\n",
    "#print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e403990f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292    0\n",
       "450    0\n",
       "148    0\n",
       "559    1\n",
       "522    0\n",
       "      ..\n",
       "58     0\n",
       "178    0\n",
       "610    0\n",
       "233    0\n",
       "216    0\n",
       "Name: Class, Length: 555, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "525dccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_log_loss(X_train, y_train, X_val, y_val, model_test):\n",
    "    scores = []\n",
    "    true_labels = np.array(y_train)\n",
    "    predicted_probs = np.array(model_test.predict_proba(X_train))\n",
    "    class_weights = np.mean(true_labels) / np.bincount(true_labels)\n",
    "    logloss_per_class = log_loss(true_labels, predicted_probs, labels=[0, 1], normalize=False)\n",
    "    balanced_logloss = np.sum(logloss_per_class * class_weights)\n",
    "    scores.append(balanced_logloss)\n",
    "    true_labels = np.array(y_val)\n",
    "    predicted_probs = np.array(model_test.predict_proba(X_val))\n",
    "    class_weights = np.mean(true_labels) / np.bincount(true_labels)\n",
    "    logloss_per_class = log_loss(true_labels, predicted_probs, labels=[0, 1], normalize=False)\n",
    "    balanced_logloss = np.sum(logloss_per_class * class_weights)\n",
    "    scores.append(balanced_logloss)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "940cee9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are 0.08264023663397657 for train data and 0.9237965382605047 for validation data.\n"
     ]
    }
   ],
   "source": [
    "# With all performance\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "results = balanced_log_loss(X_train, y_train, X_val, y_val, model)\n",
    "print(f'The results are {results[0]} for train data and {results[1]} for validation data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "de07ff91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are 0.08294645924201895 for train data and 0.3432603163684188 for validation data.\n"
     ]
    }
   ],
   "source": [
    "# With 50 variables performance\n",
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, n_features_to_select=50)\n",
    "rfe.fit(X_train, y_train)\n",
    "results = balanced_log_loss(X_train, y_train, X_val, y_val, rfe)\n",
    "print(f'The results are {results[0]} for train data and {results[1]} for validation data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8145790a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are 0.08005792163385073 for train data and 0.32501721659281196 for validation data.\n"
     ]
    }
   ],
   "source": [
    "# With 40 variables performance\n",
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, n_features_to_select=40)\n",
    "rfe.fit(X_train, y_train)\n",
    "results = balanced_log_loss(X_train, y_train, X_val, y_val, rfe)\n",
    "print(f'The results are {results[0]} for train data and {results[1]} for validation data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e226c918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are 0.07577995942699271 for train data and 0.32218710570319986 for validation data.\n"
     ]
    }
   ],
   "source": [
    "# With 30 variables performance\n",
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, n_features_to_select=30)\n",
    "rfe.fit(X_train, y_train)\n",
    "results = balanced_log_loss(X_train, y_train, X_val, y_val, rfe)\n",
    "print(f'The results are {results[0]} for train data and {results[1]} for validation data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a98cbe60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are 0.07242304973221542 for train data and 0.9020813926608242 for validation data.\n"
     ]
    }
   ],
   "source": [
    "# With 20 variables performance\n",
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, n_features_to_select=20)\n",
    "rfe.fit(X_train, y_train)\n",
    "results = balanced_log_loss(X_train, y_train, X_val, y_val, rfe)\n",
    "print(f'The results are {results[0]} for train data and {results[1]} for validation data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e5f37c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are 0.07508378540226826 for train data and 0.8997287742485649 for validation data.\n"
     ]
    }
   ],
   "source": [
    "# With 10 variables performance\n",
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, n_features_to_select=10)\n",
    "rfe.fit(X_train, y_train)\n",
    "results = balanced_log_loss(X_train, y_train, X_val, y_val, rfe)\n",
    "print(f'The results are {results[0]} for train data and {results[1]} for validation data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "79ff1402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Optimal parameter values = {'subsample': 1.0, 'reg_lambda': 10, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.2, 'colsample_bylevel': 0.75}\n",
      "Optimal cross validation log loss =  0.1851785439310943\n",
      "Time taken =  19  minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "param_grid = {'max_depth': [4, 6, 8],\n",
    "              'learning_rate': [0.01, 0.1, 0.2],\n",
    "               'reg_lambda': [0.1, 1, 100],\n",
    "                'n_estimators': [100, 500, 1000],\n",
    "                'subsample': [0.5, 0.75, 1.0],\n",
    "             'reg_lambda': [0, 10, 100],\n",
    "             'colsample_bylevel': [0.5, 0.75, 1.0]}\n",
    "\n",
    "cv = KFold(n_splits = 5,shuffle = True, random_state = 1)\n",
    "optimal_params = RandomizedSearchCV(estimator = CatBoostClassifier(random_state = 1, verbose = False),                                                       \n",
    "                             param_distributions = param_grid, n_iter = 200,\n",
    "                             verbose = 1,random_state = 1,\n",
    "                             n_jobs = -1,\n",
    "                             cv = cv, scoring = 'neg_log_loss')\n",
    "optimal_params.fit(X_train, y_train, early_stopping_rounds = 10)\n",
    "print(\"Optimal parameter values =\", optimal_params.best_params_)\n",
    "print(\"Optimal cross validation log loss = \", -optimal_params.best_score_)\n",
    "print(\"Time taken = \", round((time.time() - start_time)/60), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "24da56de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "[1]\ttraining's binary_logloss: 0.43672\tvalid_1's binary_logloss: 0.44148\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's binary_logloss: 0.412502\tvalid_1's binary_logloss: 0.425692\n",
      "[3]\ttraining's binary_logloss: 0.391769\tvalid_1's binary_logloss: 0.409989\n",
      "[4]\ttraining's binary_logloss: 0.373577\tvalid_1's binary_logloss: 0.393872\n",
      "[5]\ttraining's binary_logloss: 0.356068\tvalid_1's binary_logloss: 0.380561\n",
      "[6]\ttraining's binary_logloss: 0.343455\tvalid_1's binary_logloss: 0.374834\n",
      "[7]\ttraining's binary_logloss: 0.328676\tvalid_1's binary_logloss: 0.363502\n",
      "[8]\ttraining's binary_logloss: 0.315712\tvalid_1's binary_logloss: 0.354828\n",
      "[9]\ttraining's binary_logloss: 0.303533\tvalid_1's binary_logloss: 0.347242\n",
      "[10]\ttraining's binary_logloss: 0.292548\tvalid_1's binary_logloss: 0.33537\n",
      "[11]\ttraining's binary_logloss: 0.282278\tvalid_1's binary_logloss: 0.328692\n",
      "[12]\ttraining's binary_logloss: 0.273901\tvalid_1's binary_logloss: 0.32295\n",
      "[13]\ttraining's binary_logloss: 0.264603\tvalid_1's binary_logloss: 0.314037\n",
      "[14]\ttraining's binary_logloss: 0.256372\tvalid_1's binary_logloss: 0.307476\n",
      "[15]\ttraining's binary_logloss: 0.247624\tvalid_1's binary_logloss: 0.301101\n",
      "[16]\ttraining's binary_logloss: 0.240277\tvalid_1's binary_logloss: 0.295566\n",
      "[17]\ttraining's binary_logloss: 0.233384\tvalid_1's binary_logloss: 0.292087\n",
      "[18]\ttraining's binary_logloss: 0.226142\tvalid_1's binary_logloss: 0.289734\n",
      "[19]\ttraining's binary_logloss: 0.219905\tvalid_1's binary_logloss: 0.286691\n",
      "[20]\ttraining's binary_logloss: 0.213239\tvalid_1's binary_logloss: 0.282234\n",
      "[21]\ttraining's binary_logloss: 0.206653\tvalid_1's binary_logloss: 0.276464\n",
      "[22]\ttraining's binary_logloss: 0.200538\tvalid_1's binary_logloss: 0.273876\n",
      "[23]\ttraining's binary_logloss: 0.195154\tvalid_1's binary_logloss: 0.272514\n",
      "[24]\ttraining's binary_logloss: 0.189476\tvalid_1's binary_logloss: 0.268586\n",
      "[25]\ttraining's binary_logloss: 0.185183\tvalid_1's binary_logloss: 0.264808\n",
      "[26]\ttraining's binary_logloss: 0.180449\tvalid_1's binary_logloss: 0.261061\n",
      "[27]\ttraining's binary_logloss: 0.175421\tvalid_1's binary_logloss: 0.258746\n",
      "[28]\ttraining's binary_logloss: 0.170987\tvalid_1's binary_logloss: 0.256723\n",
      "[29]\ttraining's binary_logloss: 0.166519\tvalid_1's binary_logloss: 0.253619\n",
      "[30]\ttraining's binary_logloss: 0.161942\tvalid_1's binary_logloss: 0.250736\n",
      "[31]\ttraining's binary_logloss: 0.157186\tvalid_1's binary_logloss: 0.248883\n",
      "[32]\ttraining's binary_logloss: 0.15364\tvalid_1's binary_logloss: 0.24505\n",
      "[33]\ttraining's binary_logloss: 0.149599\tvalid_1's binary_logloss: 0.242855\n",
      "[34]\ttraining's binary_logloss: 0.145499\tvalid_1's binary_logloss: 0.241861\n",
      "[35]\ttraining's binary_logloss: 0.142421\tvalid_1's binary_logloss: 0.240458\n",
      "[36]\ttraining's binary_logloss: 0.138842\tvalid_1's binary_logloss: 0.238842\n",
      "[37]\ttraining's binary_logloss: 0.135626\tvalid_1's binary_logloss: 0.236019\n",
      "[38]\ttraining's binary_logloss: 0.132706\tvalid_1's binary_logloss: 0.234081\n",
      "[39]\ttraining's binary_logloss: 0.129553\tvalid_1's binary_logloss: 0.232728\n",
      "[40]\ttraining's binary_logloss: 0.125853\tvalid_1's binary_logloss: 0.231634\n",
      "[41]\ttraining's binary_logloss: 0.123057\tvalid_1's binary_logloss: 0.230868\n",
      "[42]\ttraining's binary_logloss: 0.120286\tvalid_1's binary_logloss: 0.228869\n",
      "[43]\ttraining's binary_logloss: 0.117566\tvalid_1's binary_logloss: 0.227321\n",
      "[44]\ttraining's binary_logloss: 0.115111\tvalid_1's binary_logloss: 0.226862\n",
      "[45]\ttraining's binary_logloss: 0.113402\tvalid_1's binary_logloss: 0.225978\n",
      "[46]\ttraining's binary_logloss: 0.110969\tvalid_1's binary_logloss: 0.226854\n",
      "[47]\ttraining's binary_logloss: 0.108878\tvalid_1's binary_logloss: 0.224501\n",
      "[48]\ttraining's binary_logloss: 0.106209\tvalid_1's binary_logloss: 0.223906\n",
      "[49]\ttraining's binary_logloss: 0.104069\tvalid_1's binary_logloss: 0.225839\n",
      "[50]\ttraining's binary_logloss: 0.101975\tvalid_1's binary_logloss: 0.226774\n",
      "[51]\ttraining's binary_logloss: 0.0997312\tvalid_1's binary_logloss: 0.226637\n",
      "[52]\ttraining's binary_logloss: 0.0981176\tvalid_1's binary_logloss: 0.226605\n",
      "[53]\ttraining's binary_logloss: 0.0957357\tvalid_1's binary_logloss: 0.226646\n",
      "[54]\ttraining's binary_logloss: 0.0935831\tvalid_1's binary_logloss: 0.224933\n",
      "[55]\ttraining's binary_logloss: 0.0915968\tvalid_1's binary_logloss: 0.224997\n",
      "[56]\ttraining's binary_logloss: 0.0896337\tvalid_1's binary_logloss: 0.223678\n",
      "[57]\ttraining's binary_logloss: 0.0879613\tvalid_1's binary_logloss: 0.220649\n",
      "[58]\ttraining's binary_logloss: 0.085963\tvalid_1's binary_logloss: 0.22089\n",
      "[59]\ttraining's binary_logloss: 0.0839762\tvalid_1's binary_logloss: 0.219856\n",
      "[60]\ttraining's binary_logloss: 0.0829583\tvalid_1's binary_logloss: 0.219054\n",
      "[61]\ttraining's binary_logloss: 0.0809952\tvalid_1's binary_logloss: 0.220314\n",
      "[62]\ttraining's binary_logloss: 0.0795351\tvalid_1's binary_logloss: 0.219844\n",
      "[63]\ttraining's binary_logloss: 0.0778128\tvalid_1's binary_logloss: 0.221039\n",
      "[64]\ttraining's binary_logloss: 0.0762896\tvalid_1's binary_logloss: 0.219877\n",
      "[65]\ttraining's binary_logloss: 0.0747395\tvalid_1's binary_logloss: 0.220385\n",
      "[66]\ttraining's binary_logloss: 0.0732245\tvalid_1's binary_logloss: 0.221835\n",
      "[67]\ttraining's binary_logloss: 0.0719563\tvalid_1's binary_logloss: 0.222746\n",
      "[68]\ttraining's binary_logloss: 0.0707164\tvalid_1's binary_logloss: 0.221052\n",
      "[69]\ttraining's binary_logloss: 0.0692543\tvalid_1's binary_logloss: 0.221204\n",
      "[70]\ttraining's binary_logloss: 0.0682842\tvalid_1's binary_logloss: 0.221676\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's binary_logloss: 0.0829583\tvalid_1's binary_logloss: 0.219054\n",
      "Optimal parameter values = {'subsample': 0.5, 'reg_lambda': 0, 'reg_alpha': 0, 'num_leaves': 40, 'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.05, 'colsample_bytree': 0.75}\n",
      "Optimal cross validation log loss =  0.17993056364823096\n",
      "Time taken =  0  minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "param_grid = {'max_depth': [4, 6, 8],\n",
    "              'num_leaves': [20, 31, 40],\n",
    "              'learning_rate': [0.01, 0.05, 0.1],\n",
    "               'reg_lambda':[0, 10, 100],\n",
    "                'n_estimators':[100, 500, 1000],\n",
    "                'reg_alpha': [0, 10, 100],\n",
    "                'subsample': [0.5, 0.75, 1.0],\n",
    "                'colsample_bytree': [0.5, 0.75, 1.0]}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "optimal_params = RandomizedSearchCV(estimator=LGBMClassifier(random_state=1),                                                       \n",
    "                             param_distributions = param_grid, n_iter = 200,\n",
    "                             verbose = 1,\n",
    "                             n_jobs=-1,\n",
    "                             cv = cv, scoring = 'neg_log_loss')\n",
    "optimal_params.fit(X_train, y_train, early_stopping_rounds = 10, eval_metric='logloss', eval_set=[(X_train, y_train), (X_val, y_val)])\n",
    "print(\"Optimal parameter values =\", optimal_params.best_params_)\n",
    "print(\"Optimal cross validation log loss = \", -optimal_params.best_score_)\n",
    "print(\"Time taken = \", round((time.time()-start_time)/60), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d7a09b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "oob_log_loss={}; test_log_loss={}\n",
    "for i in np.linspace(50,500,45,dtype=int):\n",
    "    model = RandomForestClassifier(n_estimators=i, random_state=1,max_features=\"sqrt\",n_jobs=-1,oob_score=True).fit(X_train, y_train)\n",
    "    oob_pred_prob = model.oob_decision_function_[:, 1]  \n",
    "    oob_log_loss[i] = log_loss(y_train, oob_pred_prob)\n",
    "    test_pred_prob = model.predict_proba(X_val)[:, 1] \n",
    "    test_log_loss[i] = log_loss(y_val, test_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a19baec8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'dict_keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-2a8b9693e96a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'font.size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moob_log_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moob_log_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Out of bag accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moob_log_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moob_log_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_log_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_log_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Test data accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/withPyEarth/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/withPyEarth/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1650\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_autoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/withPyEarth/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36madd_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1848\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_line%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/withPyEarth/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1870\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1871\u001b[0m         \"\"\"\n\u001b[0;32m-> 1872\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1873\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/withPyEarth/lib/python3.6/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \"\"\"\n\u001b[1;32m   1026\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/withPyEarth/lib/python3.6/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mrecache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malways\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0mxconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_xunits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xorig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_unmasked_float_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/withPyEarth/lib/python3.6/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_to_unmasked_float_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/withPyEarth/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'dict_keys'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams.update({'font.size': 15})\n",
    "plt.figure(figsize=(8, 6), dpi=80)\n",
    "plt.plot(oob_log_loss.keys(),oob_log_loss.values(),label = 'Out of Bag Log Loss')\n",
    "plt.plot(oob_log_loss.keys(),oob_log_loss.values(),'o',color = 'blue')\n",
    "plt.plot(test_log_loss.keys(),test_log_loss.values(), label = 'Test Data Log Loss')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e81c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': [1000, 1350],\n",
    "          'max_features': list(range(2,8,2)),\n",
    "          'max_depth': [None,15,18],\n",
    "          'max_leaf_nodes':[700,1000,1300],\n",
    "          'bootstrap': [True, False]}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=1)\n",
    "rf_regressor_grid = GridSearchCV(RandomForestRegressor(random_state=1, n_jobs=-1), \n",
    "                                      param_grid =params, cv=cv, n_jobs=-1, verbose=1, scoring='neg_root_mean_squared_error')\n",
    "rf_regressor_grid.fit(combined_train_x, combined_train_y)\n",
    "print('Best Parameters : ',rf_regressor_grid.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
